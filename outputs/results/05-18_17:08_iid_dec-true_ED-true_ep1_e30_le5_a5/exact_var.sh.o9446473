
Experimental details:
    Model     : resnet
    Optimizer : adam
    Learning  : 0.001
    Global Rounds   : 30

    Fraction of users  : 1.0
    Local Batch size   : 256
    Local Epochs       : 5.0

Running model  iid_dec-True_ED-True_pe1.0_a5_e30_le5.0
device:  cuda
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 2.782
Use i.i.d. sampling
sample dataset time: 0.027
user data samples: [10000, 10000, 10000, 10000, 10000]
Namespace(exact_diffusion=True, decentralized=True, edge_prob=1.0, epochs=30, num_users=5, frac=1.0, local_ep=5.0, local_bs=256, lr=0.001, momentum=0.9, num_workers=16, model='resnet', batch_size=256, weight_decay=0.0005, dataset='mnist', backbone='resnet18', num_classes=10, gpu='0', optimizer='adam', save_name_suffix='', iid=1, verbose=0, seed=1, feature_dim=128, temperature=0.5, k=200, ssl_method='simclr', x_noniid=False, dirichlet=False, test_intermediate=False, dir_beta=0.5, imagenet_based_cluster=False, y_partition=False, log_file_name='skew_ssl_comm', num_clusters=1, imagenet100=False, y_partition_skew=True, y_partition_ratio=0.0, x_shift_dirichlet=False, reg_scale=1, load_pretrained_path='', full_size=False, local_rank=0, distributed_training=False, log_directory='comm_scripts', emd=0, dist_url='env://', average_without_bn=False, model_continue_training=0, finetuning_epoch=60, script_name='', x_shift_skew=False, load_dataset_to_memory=False)
output model: save/05-18_17:09_4152430iid_dec-True_ED-True_pe1.0_a5_e30_le5.0
number of users per round: 5
total number of rounds: 6
Training uses 0.8 andd validation 0.8 of the dataset
Training uses 0.8 andd validation 0.8 of the dataset
Training uses 0.8 andd validation 0.8 of the dataset
Training uses 0.8 andd validation 0.8 of the dataset
Training uses 0.8 andd validation 0.8 of the dataset
matrix C  [[1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]]
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
matrix A  [[0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]]
Createda a Communication graph with edges = :  [(0, 1), (0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]
Number of edges:  10
Graph nodes:  [0, 1, 2, 3, 4]
matrix C  [[1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]]
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
matrix A  [[0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]]
Combination matrix A:  [[0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]]

 | Global Training Round : 1 | Model : 05-18_17:09_4152430

Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 0.0 | [0/8000 (0%)]	Loss: 6.156796                         LR: 0.0010  Feat: 0.752 Epoch Time: 8.891 Model Time: 8.257 Data Time: 0.633 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 0.0 | [2560/8000 (32%)]	Loss: 5.683749                         LR: 0.0010  Feat: 0.884 Epoch Time: 10.368 Model Time: 0.051 Data Time: 0.094 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 0.0 | [5120/8000 (65%)]	Loss: 5.471533                         LR: 0.0010  Feat: 0.950 Epoch Time: 11.819 Model Time: 0.050 Data Time: 0.094 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 0.0 | [7680/8000 (97%)]	Loss: 5.418124                         LR: 0.0010  Feat: 0.954 Epoch Time: 13.270 Model Time: 0.050 Data Time: 0.094 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 1.0 | [0/8000 (0%)]	Loss: 5.480686                         LR: 0.0010  Feat: 0.957 Epoch Time: 14.063 Model Time: 0.054 Data Time: 0.614 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 1.0 | [2560/8000 (32%)]	Loss: 5.524838                         LR: 0.0010  Feat: 0.960 Epoch Time: 15.523 Model Time: 0.051 Data Time: 0.094 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 1.0 | [5120/8000 (65%)]	Loss: 5.462189                         LR: 0.0010  Feat: 0.973 Epoch Time: 16.986 Model Time: 0.052 Data Time: 0.095 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 1.0 | [7680/8000 (97%)]	Loss: 5.440617                         LR: 0.0010  Feat: 0.975 Epoch Time: 18.448 Model Time: 0.051 Data Time: 0.095 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 2.0 | [0/8000 (0%)]	Loss: 5.376995                         LR: 0.0010  Feat: 0.976 Epoch Time: 19.231 Model Time: 0.058 Data Time: 0.595 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 2.0 | [2560/8000 (32%)]	Loss: 5.379883                         LR: 0.0010  Feat: 0.970 Epoch Time: 20.697 Model Time: 0.052 Data Time: 0.095 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 2.0 | [5120/8000 (65%)]	Loss: 5.319749                         LR: 0.0010  Feat: 0.979 Epoch Time: 22.162 Model Time: 0.051 Data Time: 0.095 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 2.0 | [7680/8000 (97%)]	Loss: 5.449133                         LR: 0.0010  Feat: 0.984 Epoch Time: 23.626 Model Time: 0.051 Data Time: 0.095 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 3.0 | [0/8000 (0%)]	Loss: 5.224276                         LR: 0.0010  Feat: 0.985 Epoch Time: 24.399 Model Time: 0.056 Data Time: 0.583 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 3.0 | [2560/8000 (32%)]	Loss: 5.387412                         LR: 0.0010  Feat: 0.977 Epoch Time: 25.868 Model Time: 0.053 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 3.0 | [5120/8000 (65%)]	Loss: 5.329482                         LR: 0.0010  Feat: 0.985 Epoch Time: 27.337 Model Time: 0.052 Data Time: 0.095 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 3.0 | [7680/8000 (97%)]	Loss: 5.400664                         LR: 0.0010  Feat: 0.984 Epoch Time: 28.808 Model Time: 0.051 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 4.0 | [0/8000 (0%)]	Loss: 5.312851                         LR: 0.0010  Feat: 0.987 Epoch Time: 29.611 Model Time: 0.054 Data Time: 0.617 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 4.0 | [2560/8000 (32%)]	Loss: 5.284895                         LR: 0.0010  Feat: 0.986 Epoch Time: 31.079 Model Time: 0.051 Data Time: 0.094 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 4.0 | [5120/8000 (65%)]	Loss: 5.283781                         LR: 0.0010  Feat: 0.987 Epoch Time: 32.546 Model Time: 0.051 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 4.0 | [7680/8000 (97%)]	Loss: 5.254240                         LR: 0.0010  Feat: 0.982 Epoch Time: 34.013 Model Time: 0.051 Data Time: 0.096 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.001
Find_phi_psi for agent:  2
Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 0.0 | [0/8000 (0%)]	Loss: 6.106090                         LR: 0.0010  Feat: 0.744 Epoch Time: 0.757 Model Time: 0.057 Data Time: 0.609 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 0.0 | [2560/8000 (32%)]	Loss: 5.723476                         LR: 0.0010  Feat: 0.905 Epoch Time: 2.226 Model Time: 0.051 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 0.0 | [5120/8000 (65%)]	Loss: 5.617901                         LR: 0.0010  Feat: 0.939 Epoch Time: 3.696 Model Time: 0.051 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 0.0 | [7680/8000 (97%)]	Loss: 5.533007                         LR: 0.0010  Feat: 0.934 Epoch Time: 5.165 Model Time: 0.051 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 1.0 | [0/8000 (0%)]	Loss: 5.582250                         LR: 0.0010  Feat: 0.942 Epoch Time: 5.951 Model Time: 0.054 Data Time: 0.596 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 1.0 | [2560/8000 (32%)]	Loss: 5.499986                         LR: 0.0010  Feat: 0.968 Epoch Time: 7.425 Model Time: 0.051 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 1.0 | [5120/8000 (65%)]	Loss: 5.475535                         LR: 0.0010  Feat: 0.974 Epoch Time: 8.898 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 1.0 | [7680/8000 (97%)]	Loss: 5.387370                         LR: 0.0010  Feat: 0.978 Epoch Time: 10.373 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 2.0 | [0/8000 (0%)]	Loss: 5.454195                         LR: 0.0010  Feat: 0.976 Epoch Time: 11.154 Model Time: 0.055 Data Time: 0.592 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 2.0 | [2560/8000 (32%)]	Loss: 5.438658                         LR: 0.0010  Feat: 0.987 Epoch Time: 12.637 Model Time: 0.052 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 2.0 | [5120/8000 (65%)]	Loss: 5.428207                         LR: 0.0010  Feat: 0.983 Epoch Time: 14.116 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 2.0 | [7680/8000 (97%)]	Loss: 5.327285                         LR: 0.0010  Feat: 0.989 Epoch Time: 15.595 Model Time: 0.052 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 3.0 | [0/8000 (0%)]	Loss: 5.354987                         LR: 0.0010  Feat: 0.987 Epoch Time: 16.387 Model Time: 0.055 Data Time: 0.602 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 3.0 | [2560/8000 (32%)]	Loss: 5.417269                         LR: 0.0010  Feat: 0.994 Epoch Time: 17.867 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 3.0 | [5120/8000 (65%)]	Loss: 5.366250                         LR: 0.0010  Feat: 0.992 Epoch Time: 19.347 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 3.0 | [7680/8000 (97%)]	Loss: 5.357536                         LR: 0.0010  Feat: 0.993 Epoch Time: 20.827 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 4.0 | [0/8000 (0%)]	Loss: 5.326417                         LR: 0.0010  Feat: 0.995 Epoch Time: 21.608 Model Time: 0.060 Data Time: 0.588 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 4.0 | [2560/8000 (32%)]	Loss: 5.281960                         LR: 0.0010  Feat: 0.994 Epoch Time: 23.091 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 4.0 | [5120/8000 (65%)]	Loss: 5.341852                         LR: 0.0010  Feat: 0.992 Epoch Time: 24.571 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 4.0 | [7680/8000 (97%)]	Loss: 5.307157                         LR: 0.0010  Feat: 0.997 Epoch Time: 26.052 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.001
Find_phi_psi for agent:  3
Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 0.0 | [0/8000 (0%)]	Loss: 6.137561                         LR: 0.0010  Feat: 0.756 Epoch Time: 0.752 Model Time: 0.057 Data Time: 0.602 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 0.0 | [2560/8000 (32%)]	Loss: 5.688514                         LR: 0.0010  Feat: 0.893 Epoch Time: 2.235 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 0.0 | [5120/8000 (65%)]	Loss: 5.524006                         LR: 0.0010  Feat: 0.944 Epoch Time: 3.716 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 0.0 | [7680/8000 (97%)]	Loss: 5.505008                         LR: 0.0010  Feat: 0.950 Epoch Time: 5.196 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 1.0 | [0/8000 (0%)]	Loss: 5.540977                         LR: 0.0010  Feat: 0.953 Epoch Time: 5.981 Model Time: 0.053 Data Time: 0.598 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 1.0 | [2560/8000 (32%)]	Loss: 5.478874                         LR: 0.0010  Feat: 0.970 Epoch Time: 7.465 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 1.0 | [5120/8000 (65%)]	Loss: 5.502041                         LR: 0.0010  Feat: 0.976 Epoch Time: 8.948 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 1.0 | [7680/8000 (97%)]	Loss: 5.393515                         LR: 0.0010  Feat: 0.973 Epoch Time: 10.434 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 2.0 | [0/8000 (0%)]	Loss: 5.466749                         LR: 0.0010  Feat: 0.967 Epoch Time: 11.217 Model Time: 0.062 Data Time: 0.590 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 2.0 | [2560/8000 (32%)]	Loss: 5.337893                         LR: 0.0010  Feat: 0.981 Epoch Time: 12.715 Model Time: 0.052 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 2.0 | [5120/8000 (65%)]	Loss: 5.381695                         LR: 0.0010  Feat: 0.978 Epoch Time: 14.200 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 2.0 | [7680/8000 (97%)]	Loss: 5.294807                         LR: 0.0010  Feat: 0.987 Epoch Time: 15.687 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 3.0 | [0/8000 (0%)]	Loss: 5.350524                         LR: 0.0010  Feat: 0.985 Epoch Time: 16.474 Model Time: 0.058 Data Time: 0.595 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 3.0 | [2560/8000 (32%)]	Loss: 5.317912                         LR: 0.0010  Feat: 0.983 Epoch Time: 17.962 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 3.0 | [5120/8000 (65%)]	Loss: 5.318600                         LR: 0.0010  Feat: 0.982 Epoch Time: 19.448 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 3.0 | [7680/8000 (97%)]	Loss: 5.348634                         LR: 0.0010  Feat: 0.980 Epoch Time: 20.935 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 4.0 | [0/8000 (0%)]	Loss: 5.363091                         LR: 0.0010  Feat: 0.984 Epoch Time: 21.848 Model Time: 0.059 Data Time: 0.717 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 4.0 | [2560/8000 (32%)]	Loss: 5.299587                         LR: 0.0010  Feat: 0.983 Epoch Time: 23.337 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 4.0 | [5120/8000 (65%)]	Loss: 5.243967                         LR: 0.0010  Feat: 0.987 Epoch Time: 24.825 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 4.0 | [7680/8000 (97%)]	Loss: 5.214766                         LR: 0.0010  Feat: 0.986 Epoch Time: 26.312 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.001
Find_phi_psi for agent:  4
Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 0.0 | [0/8000 (0%)]	Loss: 6.113833                         LR: 0.0010  Feat: 0.762 Epoch Time: 0.875 Model Time: 0.061 Data Time: 0.724 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 0.0 | [2560/8000 (32%)]	Loss: 5.659458                         LR: 0.0010  Feat: 0.892 Epoch Time: 2.364 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 0.0 | [5120/8000 (65%)]	Loss: 5.531029                         LR: 0.0010  Feat: 0.933 Epoch Time: 3.851 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 0.0 | [7680/8000 (97%)]	Loss: 5.564297                         LR: 0.0010  Feat: 0.970 Epoch Time: 5.340 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 1.0 | [0/8000 (0%)]	Loss: 5.497834                         LR: 0.0010  Feat: 0.971 Epoch Time: 6.156 Model Time: 0.058 Data Time: 0.624 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 1.0 | [2560/8000 (32%)]	Loss: 5.453740                         LR: 0.0010  Feat: 0.975 Epoch Time: 7.645 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 1.0 | [5120/8000 (65%)]	Loss: 5.518751                         LR: 0.0010  Feat: 0.974 Epoch Time: 9.133 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 1.0 | [7680/8000 (97%)]	Loss: 5.338030                         LR: 0.0010  Feat: 0.981 Epoch Time: 10.622 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 2.0 | [0/8000 (0%)]	Loss: 5.490265                         LR: 0.0010  Feat: 0.975 Epoch Time: 11.418 Model Time: 0.055 Data Time: 0.605 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 2.0 | [2560/8000 (32%)]	Loss: 5.445077                         LR: 0.0010  Feat: 0.978 Epoch Time: 12.904 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 2.0 | [5120/8000 (65%)]	Loss: 5.317375                         LR: 0.0010  Feat: 0.979 Epoch Time: 14.388 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 2.0 | [7680/8000 (97%)]	Loss: 5.386302                         LR: 0.0010  Feat: 0.981 Epoch Time: 15.874 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 3.0 | [0/8000 (0%)]	Loss: 5.375019                         LR: 0.0010  Feat: 0.981 Epoch Time: 16.793 Model Time: 0.058 Data Time: 0.725 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 3.0 | [2560/8000 (32%)]	Loss: 5.312082                         LR: 0.0010  Feat: 0.986 Epoch Time: 18.284 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 3.0 | [5120/8000 (65%)]	Loss: 5.277603                         LR: 0.0010  Feat: 0.986 Epoch Time: 19.775 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 3.0 | [7680/8000 (97%)]	Loss: 5.224716                         LR: 0.0010  Feat: 0.982 Epoch Time: 21.264 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 4.0 | [0/8000 (0%)]	Loss: 5.298906                         LR: 0.0010  Feat: 0.985 Epoch Time: 22.061 Model Time: 0.054 Data Time: 0.609 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 4.0 | [2560/8000 (32%)]	Loss: 5.278435                         LR: 0.0010  Feat: 0.987 Epoch Time: 23.582 Model Time: 0.052 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 4.0 | [5120/8000 (65%)]	Loss: 5.283765                         LR: 0.0010  Feat: 0.984 Epoch Time: 25.073 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 4.0 | [7680/8000 (97%)]	Loss: 5.325174                         LR: 0.0010  Feat: 0.993 Epoch Time: 26.564 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.001
Find_phi_psi for agent:  1
Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 0.0 | [0/8000 (0%)]	Loss: 6.128836                         LR: 0.0010  Feat: 0.763 Epoch Time: 0.754 Model Time: 0.057 Data Time: 0.603 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 0.0 | [2560/8000 (32%)]	Loss: 5.656107                         LR: 0.0010  Feat: 0.922 Epoch Time: 2.249 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 0.0 | [5120/8000 (65%)]	Loss: 5.601590                         LR: 0.0010  Feat: 0.948 Epoch Time: 3.740 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 0.0 | [7680/8000 (97%)]	Loss: 5.552990                         LR: 0.0010  Feat: 0.968 Epoch Time: 5.230 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 1.0 | [0/8000 (0%)]	Loss: 5.500895                         LR: 0.0010  Feat: 0.970 Epoch Time: 6.012 Model Time: 0.060 Data Time: 0.590 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 1.0 | [2560/8000 (32%)]	Loss: 5.517544                         LR: 0.0010  Feat: 0.980 Epoch Time: 7.505 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 1.0 | [5120/8000 (65%)]	Loss: 5.463591                         LR: 0.0010  Feat: 0.973 Epoch Time: 8.996 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 1.0 | [7680/8000 (97%)]	Loss: 5.454631                         LR: 0.0010  Feat: 0.984 Epoch Time: 10.488 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 2.0 | [0/8000 (0%)]	Loss: 5.459560                         LR: 0.0010  Feat: 0.983 Epoch Time: 11.316 Model Time: 0.055 Data Time: 0.638 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 2.0 | [2560/8000 (32%)]	Loss: 5.323200                         LR: 0.0010  Feat: 0.996 Epoch Time: 12.808 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 2.0 | [5120/8000 (65%)]	Loss: 5.417893                         LR: 0.0010  Feat: 0.990 Epoch Time: 14.298 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 2.0 | [7680/8000 (97%)]	Loss: 5.368576                         LR: 0.0010  Feat: 0.974 Epoch Time: 15.789 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 3.0 | [0/8000 (0%)]	Loss: 5.407617                         LR: 0.0010  Feat: 0.978 Epoch Time: 16.697 Model Time: 0.059 Data Time: 0.712 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 3.0 | [2560/8000 (32%)]	Loss: 5.332002                         LR: 0.0010  Feat: 0.979 Epoch Time: 18.190 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 3.0 | [5120/8000 (65%)]	Loss: 5.372921                         LR: 0.0010  Feat: 0.990 Epoch Time: 19.682 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 3.0 | [7680/8000 (97%)]	Loss: 5.328627                         LR: 0.0010  Feat: 0.989 Epoch Time: 21.174 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 4.0 | [0/8000 (0%)]	Loss: 5.347591                         LR: 0.0010  Feat: 0.984 Epoch Time: 22.098 Model Time: 0.056 Data Time: 0.717 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 4.0 | [2560/8000 (32%)]	Loss: 5.301443                         LR: 0.0010  Feat: 0.991 Epoch Time: 23.598 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 4.0 | [5120/8000 (65%)]	Loss: 5.306657                         LR: 0.0010  Feat: 0.998 Epoch Time: 25.095 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 4.0 | [7680/8000 (97%)]	Loss: 5.271062                         LR: 0.0010  Feat: 0.999 Epoch Time: 26.589 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.001
Find_phi_psi for agent:  0
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked

 | Global Training Round : 2 | Model : 05-18_17:09_4152430

Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 5.0 | [0/8000 (0%)]	Loss: 5.264970                         LR: 0.0003  Feat: 1.991 Epoch Time: 0.846 Model Time: 0.057 Data Time: 0.695 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 5.0 | [2560/8000 (32%)]	Loss: 5.244492                         LR: 0.0003  Feat: 1.964 Epoch Time: 2.343 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 5.0 | [5120/8000 (65%)]	Loss: 5.196609                         LR: 0.0003  Feat: 1.977 Epoch Time: 3.838 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 5.0 | [7680/8000 (97%)]	Loss: 5.252804                         LR: 0.0003  Feat: 1.970 Epoch Time: 5.335 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 6.0 | [0/8000 (0%)]	Loss: 5.253872                         LR: 0.0003  Feat: 1.968 Epoch Time: 6.120 Model Time: 0.061 Data Time: 0.592 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 6.0 | [2560/8000 (32%)]	Loss: 5.201728                         LR: 0.0003  Feat: 1.977 Epoch Time: 7.620 Model Time: 0.056 Data Time: 0.096 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 6.0 | [5120/8000 (65%)]	Loss: 5.279663                         LR: 0.0003  Feat: 1.971 Epoch Time: 9.117 Model Time: 0.054 Data Time: 0.094 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 6.0 | [7680/8000 (97%)]	Loss: 5.178611                         LR: 0.0003  Feat: 1.969 Epoch Time: 10.615 Model Time: 0.054 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 7.0 | [0/8000 (0%)]	Loss: 5.267942                         LR: 0.0003  Feat: 1.970 Epoch Time: 11.424 Model Time: 0.055 Data Time: 0.618 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 7.0 | [2560/8000 (32%)]	Loss: 5.170775                         LR: 0.0003  Feat: 1.961 Epoch Time: 12.920 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 7.0 | [5120/8000 (65%)]	Loss: 5.182239                         LR: 0.0003  Feat: 1.958 Epoch Time: 14.416 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 7.0 | [7680/8000 (97%)]	Loss: 5.208695                         LR: 0.0003  Feat: 1.963 Epoch Time: 15.913 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 8.0 | [0/8000 (0%)]	Loss: 5.189770                         LR: 0.0003  Feat: 1.962 Epoch Time: 16.724 Model Time: 0.054 Data Time: 0.618 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 8.0 | [2560/8000 (32%)]	Loss: 5.184161                         LR: 0.0003  Feat: 1.963 Epoch Time: 18.220 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 8.0 | [5120/8000 (65%)]	Loss: 5.137791                         LR: 0.0003  Feat: 1.958 Epoch Time: 19.717 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 8.0 | [7680/8000 (97%)]	Loss: 5.158172                         LR: 0.0003  Feat: 1.952 Epoch Time: 21.222 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 9.0 | [0/8000 (0%)]	Loss: 5.167084                         LR: 0.0003  Feat: 1.956 Epoch Time: 22.021 Model Time: 0.054 Data Time: 0.606 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 9.0 | [2560/8000 (32%)]	Loss: 5.144540                         LR: 0.0003  Feat: 1.965 Epoch Time: 23.519 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 9.0 | [5120/8000 (65%)]	Loss: 5.161217                         LR: 0.0003  Feat: 1.955 Epoch Time: 25.013 Model Time: 0.052 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 9.0 | [7680/8000 (97%)]	Loss: 5.195385                         LR: 0.0003  Feat: 1.957 Epoch Time: 26.534 Model Time: 0.077 Data Time: 0.099 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  0
Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 5.0 | [0/8000 (0%)]	Loss: 5.327375                         LR: 0.0003  Feat: 2.409 Epoch Time: 0.745 Model Time: 0.057 Data Time: 0.593 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 5.0 | [2560/8000 (32%)]	Loss: 5.331296                         LR: 0.0003  Feat: 2.383 Epoch Time: 2.241 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 5.0 | [5120/8000 (65%)]	Loss: 5.256808                         LR: 0.0003  Feat: 2.382 Epoch Time: 3.738 Model Time: 0.052 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 5.0 | [7680/8000 (97%)]	Loss: 5.270819                         LR: 0.0003  Feat: 2.377 Epoch Time: 5.233 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 6.0 | [0/8000 (0%)]	Loss: 5.227077                         LR: 0.0003  Feat: 2.386 Epoch Time: 6.023 Model Time: 0.056 Data Time: 0.594 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 6.0 | [2560/8000 (32%)]	Loss: 5.280859                         LR: 0.0003  Feat: 2.375 Epoch Time: 7.519 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 6.0 | [5120/8000 (65%)]	Loss: 5.179540                         LR: 0.0003  Feat: 2.367 Epoch Time: 9.015 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 6.0 | [7680/8000 (97%)]	Loss: 5.173204                         LR: 0.0003  Feat: 2.374 Epoch Time: 10.510 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 7.0 | [0/8000 (0%)]	Loss: 5.163851                         LR: 0.0003  Feat: 2.371 Epoch Time: 11.297 Model Time: 0.055 Data Time: 0.593 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 7.0 | [2560/8000 (32%)]	Loss: 5.238578                         LR: 0.0003  Feat: 2.383 Epoch Time: 12.797 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 7.0 | [5120/8000 (65%)]	Loss: 5.231637                         LR: 0.0003  Feat: 2.368 Epoch Time: 14.298 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 7.0 | [7680/8000 (97%)]	Loss: 5.147225                         LR: 0.0003  Feat: 2.363 Epoch Time: 15.799 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 8.0 | [0/8000 (0%)]	Loss: 5.240384                         LR: 0.0003  Feat: 2.361 Epoch Time: 16.598 Model Time: 0.056 Data Time: 0.606 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 8.0 | [2560/8000 (32%)]	Loss: 5.182102                         LR: 0.0003  Feat: 2.369 Epoch Time: 18.100 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 8.0 | [5120/8000 (65%)]	Loss: 5.166053                         LR: 0.0003  Feat: 2.370 Epoch Time: 19.600 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 8.0 | [7680/8000 (97%)]	Loss: 5.161222                         LR: 0.0003  Feat: 2.365 Epoch Time: 21.096 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 9.0 | [0/8000 (0%)]	Loss: 5.121009                         LR: 0.0003  Feat: 2.366 Epoch Time: 21.899 Model Time: 0.058 Data Time: 0.607 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 9.0 | [2560/8000 (32%)]	Loss: 5.109914                         LR: 0.0003  Feat: 2.365 Epoch Time: 23.399 Model Time: 0.053 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 9.0 | [5120/8000 (65%)]	Loss: 5.098876                         LR: 0.0003  Feat: 2.360 Epoch Time: 24.895 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 9.0 | [7680/8000 (97%)]	Loss: 5.146168                         LR: 0.0003  Feat: 2.362 Epoch Time: 26.391 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  2
Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 5.0 | [0/8000 (0%)]	Loss: 5.328853                         LR: 0.0003  Feat: 3.020 Epoch Time: 0.753 Model Time: 0.057 Data Time: 0.601 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 5.0 | [2560/8000 (32%)]	Loss: 5.178181                         LR: 0.0003  Feat: 3.001 Epoch Time: 2.250 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 5.0 | [5120/8000 (65%)]	Loss: 5.271998                         LR: 0.0003  Feat: 2.995 Epoch Time: 3.748 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 5.0 | [7680/8000 (97%)]	Loss: 5.313134                         LR: 0.0003  Feat: 2.998 Epoch Time: 5.246 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 6.0 | [0/8000 (0%)]	Loss: 5.241050                         LR: 0.0003  Feat: 2.997 Epoch Time: 6.065 Model Time: 0.054 Data Time: 0.622 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 6.0 | [2560/8000 (32%)]	Loss: 5.225641                         LR: 0.0003  Feat: 2.987 Epoch Time: 7.559 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 6.0 | [5120/8000 (65%)]	Loss: 5.218826                         LR: 0.0003  Feat: 2.993 Epoch Time: 9.052 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 6.0 | [7680/8000 (97%)]	Loss: 5.195440                         LR: 0.0003  Feat: 2.982 Epoch Time: 10.551 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 7.0 | [0/8000 (0%)]	Loss: 5.222520                         LR: 0.0003  Feat: 2.984 Epoch Time: 11.451 Model Time: 0.057 Data Time: 0.697 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 7.0 | [2560/8000 (32%)]	Loss: 5.178944                         LR: 0.0003  Feat: 2.986 Epoch Time: 12.957 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 7.0 | [5120/8000 (65%)]	Loss: 5.161669                         LR: 0.0003  Feat: 2.988 Epoch Time: 14.450 Model Time: 0.050 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 7.0 | [7680/8000 (97%)]	Loss: 5.215777                         LR: 0.0003  Feat: 2.980 Epoch Time: 15.941 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 8.0 | [0/8000 (0%)]	Loss: 5.190920                         LR: 0.0003  Feat: 2.986 Epoch Time: 16.740 Model Time: 0.054 Data Time: 0.607 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 8.0 | [2560/8000 (32%)]	Loss: 5.233285                         LR: 0.0003  Feat: 2.979 Epoch Time: 18.240 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 8.0 | [5120/8000 (65%)]	Loss: 5.197215                         LR: 0.0003  Feat: 2.983 Epoch Time: 19.743 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 8.0 | [7680/8000 (97%)]	Loss: 5.187031                         LR: 0.0003  Feat: 2.983 Epoch Time: 21.235 Model Time: 0.050 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 9.0 | [0/8000 (0%)]	Loss: 5.194498                         LR: 0.0003  Feat: 2.990 Epoch Time: 22.035 Model Time: 0.055 Data Time: 0.606 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 9.0 | [2560/8000 (32%)]	Loss: 5.158549                         LR: 0.0003  Feat: 2.977 Epoch Time: 23.528 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 9.0 | [5120/8000 (65%)]	Loss: 5.142078                         LR: 0.0003  Feat: 2.977 Epoch Time: 25.021 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 9.0 | [7680/8000 (97%)]	Loss: 5.168511                         LR: 0.0003  Feat: 2.975 Epoch Time: 26.517 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  4
Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 5.0 | [0/8000 (0%)]	Loss: 5.444218                         LR: 0.0003  Feat: 2.715 Epoch Time: 0.784 Model Time: 0.056 Data Time: 0.633 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 5.0 | [2560/8000 (32%)]	Loss: 5.219101                         LR: 0.0003  Feat: 2.678 Epoch Time: 2.279 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 5.0 | [5120/8000 (65%)]	Loss: 5.277464                         LR: 0.0003  Feat: 2.670 Epoch Time: 3.775 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 5.0 | [7680/8000 (97%)]	Loss: 5.268122                         LR: 0.0003  Feat: 2.666 Epoch Time: 5.269 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 6.0 | [0/8000 (0%)]	Loss: 5.214078                         LR: 0.0003  Feat: 2.675 Epoch Time: 6.072 Model Time: 0.055 Data Time: 0.612 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 6.0 | [2560/8000 (32%)]	Loss: 5.165818                         LR: 0.0003  Feat: 2.674 Epoch Time: 7.572 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 6.0 | [5120/8000 (65%)]	Loss: 5.210186                         LR: 0.0003  Feat: 2.673 Epoch Time: 9.073 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 6.0 | [7680/8000 (97%)]	Loss: 5.209161                         LR: 0.0003  Feat: 2.672 Epoch Time: 10.570 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 7.0 | [0/8000 (0%)]	Loss: 5.213848                         LR: 0.0003  Feat: 2.667 Epoch Time: 11.403 Model Time: 0.055 Data Time: 0.637 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 7.0 | [2560/8000 (32%)]	Loss: 5.244761                         LR: 0.0003  Feat: 2.676 Epoch Time: 12.901 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 7.0 | [5120/8000 (65%)]	Loss: 5.151238                         LR: 0.0003  Feat: 2.675 Epoch Time: 14.399 Model Time: 0.054 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 7.0 | [7680/8000 (97%)]	Loss: 5.268322                         LR: 0.0003  Feat: 2.670 Epoch Time: 15.899 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 8.0 | [0/8000 (0%)]	Loss: 5.174480                         LR: 0.0003  Feat: 2.667 Epoch Time: 16.694 Model Time: 0.061 Data Time: 0.597 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 8.0 | [2560/8000 (32%)]	Loss: 5.244058                         LR: 0.0003  Feat: 2.663 Epoch Time: 18.192 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 8.0 | [5120/8000 (65%)]	Loss: 5.225817                         LR: 0.0003  Feat: 2.670 Epoch Time: 19.690 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 8.0 | [7680/8000 (97%)]	Loss: 5.230539                         LR: 0.0003  Feat: 2.659 Epoch Time: 21.188 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 9.0 | [0/8000 (0%)]	Loss: 5.225385                         LR: 0.0003  Feat: 2.670 Epoch Time: 21.987 Model Time: 0.056 Data Time: 0.608 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 9.0 | [2560/8000 (32%)]	Loss: 5.157484                         LR: 0.0003  Feat: 2.661 Epoch Time: 23.484 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 9.0 | [5120/8000 (65%)]	Loss: 5.212217                         LR: 0.0003  Feat: 2.653 Epoch Time: 24.984 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 9.0 | [7680/8000 (97%)]	Loss: 5.177356                         LR: 0.0003  Feat: 2.664 Epoch Time: 26.482 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  3
Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 5.0 | [0/8000 (0%)]	Loss: 5.309612                         LR: 0.0003  Feat: 2.170 Epoch Time: 0.865 Model Time: 0.057 Data Time: 0.714 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 5.0 | [2560/8000 (32%)]	Loss: 5.310187                         LR: 0.0003  Feat: 2.145 Epoch Time: 2.363 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 5.0 | [5120/8000 (65%)]	Loss: 5.258729                         LR: 0.0003  Feat: 2.147 Epoch Time: 3.863 Model Time: 0.052 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 5.0 | [7680/8000 (97%)]	Loss: 5.220620                         LR: 0.0003  Feat: 2.151 Epoch Time: 5.361 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 6.0 | [0/8000 (0%)]	Loss: 5.294488                         LR: 0.0003  Feat: 2.154 Epoch Time: 6.168 Model Time: 0.055 Data Time: 0.614 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 6.0 | [2560/8000 (32%)]	Loss: 5.226723                         LR: 0.0003  Feat: 2.149 Epoch Time: 7.665 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 6.0 | [5120/8000 (65%)]	Loss: 5.231024                         LR: 0.0003  Feat: 2.148 Epoch Time: 9.163 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 6.0 | [7680/8000 (97%)]	Loss: 5.198566                         LR: 0.0003  Feat: 2.143 Epoch Time: 10.661 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 7.0 | [0/8000 (0%)]	Loss: 5.160830                         LR: 0.0003  Feat: 2.138 Epoch Time: 11.490 Model Time: 0.055 Data Time: 0.634 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 7.0 | [2560/8000 (32%)]	Loss: 5.222482                         LR: 0.0003  Feat: 2.146 Epoch Time: 12.986 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 7.0 | [5120/8000 (65%)]	Loss: 5.188632                         LR: 0.0003  Feat: 2.148 Epoch Time: 14.490 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 7.0 | [7680/8000 (97%)]	Loss: 5.127061                         LR: 0.0003  Feat: 2.147 Epoch Time: 15.987 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 8.0 | [0/8000 (0%)]	Loss: 5.188868                         LR: 0.0003  Feat: 2.140 Epoch Time: 16.782 Model Time: 0.054 Data Time: 0.599 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 8.0 | [2560/8000 (32%)]	Loss: 5.226153                         LR: 0.0003  Feat: 2.145 Epoch Time: 18.280 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 8.0 | [5120/8000 (65%)]	Loss: 5.188039                         LR: 0.0003  Feat: 2.137 Epoch Time: 19.777 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 8.0 | [7680/8000 (97%)]	Loss: 5.103180                         LR: 0.0003  Feat: 2.139 Epoch Time: 21.275 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 9.0 | [0/8000 (0%)]	Loss: 5.263854                         LR: 0.0003  Feat: 2.131 Epoch Time: 22.114 Model Time: 0.057 Data Time: 0.644 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 9.0 | [2560/8000 (32%)]	Loss: 5.177185                         LR: 0.0003  Feat: 2.139 Epoch Time: 23.612 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 9.0 | [5120/8000 (65%)]	Loss: 5.207364                         LR: 0.0003  Feat: 2.124 Epoch Time: 25.110 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 9.0 | [7680/8000 (97%)]	Loss: 5.148403                         LR: 0.0003  Feat: 2.128 Epoch Time: 26.607 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  1
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked

 | Global Training Round : 3 | Model : 05-18_17:09_4152430

Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 10.0 | [0/8000 (0%)]	Loss: 5.225484                         LR: 0.0003  Feat: 5.019 Epoch Time: 0.839 Model Time: 0.057 Data Time: 0.688 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 10.0 | [2560/8000 (32%)]	Loss: 5.164673                         LR: 0.0003  Feat: 4.984 Epoch Time: 2.341 Model Time: 0.053 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 10.0 | [5120/8000 (65%)]	Loss: 5.171055                         LR: 0.0003  Feat: 4.972 Epoch Time: 3.837 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 10.0 | [7680/8000 (97%)]	Loss: 5.118945                         LR: 0.0003  Feat: 4.962 Epoch Time: 5.334 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 11.0 | [0/8000 (0%)]	Loss: 5.181221                         LR: 0.0003  Feat: 4.976 Epoch Time: 6.153 Model Time: 0.056 Data Time: 0.624 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 11.0 | [2560/8000 (32%)]	Loss: 5.215140                         LR: 0.0003  Feat: 4.960 Epoch Time: 7.653 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 11.0 | [5120/8000 (65%)]	Loss: 5.149343                         LR: 0.0003  Feat: 4.973 Epoch Time: 9.151 Model Time: 0.052 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 11.0 | [7680/8000 (97%)]	Loss: 5.076933                         LR: 0.0003  Feat: 4.973 Epoch Time: 10.648 Model Time: 0.053 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 12.0 | [0/8000 (0%)]	Loss: 5.209475                         LR: 0.0003  Feat: 4.967 Epoch Time: 11.469 Model Time: 0.055 Data Time: 0.628 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 12.0 | [2560/8000 (32%)]	Loss: 5.117539                         LR: 0.0003  Feat: 4.969 Epoch Time: 12.969 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 12.0 | [5120/8000 (65%)]	Loss: 5.153882                         LR: 0.0003  Feat: 4.960 Epoch Time: 14.468 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 12.0 | [7680/8000 (97%)]	Loss: 5.159034                         LR: 0.0003  Feat: 4.950 Epoch Time: 15.966 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 13.0 | [0/8000 (0%)]	Loss: 5.169742                         LR: 0.0003  Feat: 4.954 Epoch Time: 16.783 Model Time: 0.057 Data Time: 0.624 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 13.0 | [2560/8000 (32%)]	Loss: 5.172280                         LR: 0.0003  Feat: 4.964 Epoch Time: 18.282 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 13.0 | [5120/8000 (65%)]	Loss: 5.178143                         LR: 0.0003  Feat: 4.949 Epoch Time: 19.781 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 13.0 | [7680/8000 (97%)]	Loss: 5.143825                         LR: 0.0003  Feat: 4.949 Epoch Time: 21.280 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 14.0 | [0/8000 (0%)]	Loss: 5.124754                         LR: 0.0003  Feat: 4.951 Epoch Time: 22.250 Model Time: 0.055 Data Time: 0.768 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 14.0 | [2560/8000 (32%)]	Loss: 5.128758                         LR: 0.0003  Feat: 4.943 Epoch Time: 23.749 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 14.0 | [5120/8000 (65%)]	Loss: 5.155310                         LR: 0.0003  Feat: 4.951 Epoch Time: 25.246 Model Time: 0.052 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 14.0 | [7680/8000 (97%)]	Loss: 5.123489                         LR: 0.0003  Feat: 4.939 Epoch Time: 26.744 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  1
Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 10.0 | [0/8000 (0%)]	Loss: 5.260531                         LR: 0.0003  Feat: 6.819 Epoch Time: 0.818 Model Time: 0.056 Data Time: 0.667 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 10.0 | [2560/8000 (32%)]	Loss: 5.247157                         LR: 0.0003  Feat: 6.790 Epoch Time: 2.317 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 10.0 | [5120/8000 (65%)]	Loss: 5.208012                         LR: 0.0003  Feat: 6.791 Epoch Time: 3.814 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 10.0 | [7680/8000 (97%)]	Loss: 5.248856                         LR: 0.0003  Feat: 6.778 Epoch Time: 5.312 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 11.0 | [0/8000 (0%)]	Loss: 5.176865                         LR: 0.0003  Feat: 6.747 Epoch Time: 6.175 Model Time: 0.054 Data Time: 0.671 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 11.0 | [2560/8000 (32%)]	Loss: 5.163618                         LR: 0.0003  Feat: 6.768 Epoch Time: 7.673 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 11.0 | [5120/8000 (65%)]	Loss: 5.171135                         LR: 0.0003  Feat: 6.749 Epoch Time: 9.172 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 11.0 | [7680/8000 (97%)]	Loss: 5.140215                         LR: 0.0003  Feat: 6.746 Epoch Time: 10.671 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 12.0 | [0/8000 (0%)]	Loss: 5.196108                         LR: 0.0003  Feat: 6.742 Epoch Time: 11.513 Model Time: 0.054 Data Time: 0.649 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 12.0 | [2560/8000 (32%)]	Loss: 5.132225                         LR: 0.0003  Feat: 6.746 Epoch Time: 13.012 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 12.0 | [5120/8000 (65%)]	Loss: 5.156053                         LR: 0.0003  Feat: 6.735 Epoch Time: 14.512 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 12.0 | [7680/8000 (97%)]	Loss: 5.156405                         LR: 0.0003  Feat: 6.737 Epoch Time: 16.010 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 13.0 | [0/8000 (0%)]	Loss: 5.122797                         LR: 0.0003  Feat: 6.731 Epoch Time: 16.842 Model Time: 0.055 Data Time: 0.639 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 13.0 | [2560/8000 (32%)]	Loss: 5.162518                         LR: 0.0003  Feat: 6.726 Epoch Time: 18.341 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 13.0 | [5120/8000 (65%)]	Loss: 5.198029                         LR: 0.0003  Feat: 6.728 Epoch Time: 19.840 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 13.0 | [7680/8000 (97%)]	Loss: 5.186613                         LR: 0.0003  Feat: 6.710 Epoch Time: 21.339 Model Time: 0.052 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 14.0 | [0/8000 (0%)]	Loss: 5.119724                         LR: 0.0003  Feat: 6.689 Epoch Time: 22.186 Model Time: 0.055 Data Time: 0.657 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 14.0 | [2560/8000 (32%)]	Loss: 5.099978                         LR: 0.0003  Feat: 6.723 Epoch Time: 23.681 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 14.0 | [5120/8000 (65%)]	Loss: 5.141196                         LR: 0.0003  Feat: 6.710 Epoch Time: 25.177 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 14.0 | [7680/8000 (97%)]	Loss: 5.117957                         LR: 0.0003  Feat: 6.709 Epoch Time: 26.672 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  3
Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 10.0 | [0/8000 (0%)]	Loss: 5.261855                         LR: 0.0003  Feat: 5.844 Epoch Time: 0.785 Model Time: 0.057 Data Time: 0.633 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 10.0 | [2560/8000 (32%)]	Loss: 5.252398                         LR: 0.0003  Feat: 5.813 Epoch Time: 2.287 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 10.0 | [5120/8000 (65%)]	Loss: 5.170914                         LR: 0.0003  Feat: 5.775 Epoch Time: 3.787 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 10.0 | [7680/8000 (97%)]	Loss: 5.122795                         LR: 0.0003  Feat: 5.794 Epoch Time: 5.287 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 11.0 | [0/8000 (0%)]	Loss: 5.185153                         LR: 0.0003  Feat: 5.774 Epoch Time: 6.097 Model Time: 0.060 Data Time: 0.619 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 11.0 | [2560/8000 (32%)]	Loss: 5.139820                         LR: 0.0003  Feat: 5.790 Epoch Time: 7.596 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 11.0 | [5120/8000 (65%)]	Loss: 5.187608                         LR: 0.0003  Feat: 5.774 Epoch Time: 9.093 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 11.0 | [7680/8000 (97%)]	Loss: 5.111401                         LR: 0.0003  Feat: 5.762 Epoch Time: 10.593 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 12.0 | [0/8000 (0%)]	Loss: 5.160939                         LR: 0.0003  Feat: 5.759 Epoch Time: 11.413 Model Time: 0.055 Data Time: 0.628 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 12.0 | [2560/8000 (32%)]	Loss: 5.168569                         LR: 0.0003  Feat: 5.777 Epoch Time: 12.911 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 12.0 | [5120/8000 (65%)]	Loss: 5.175867                         LR: 0.0003  Feat: 5.776 Epoch Time: 14.412 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 12.0 | [7680/8000 (97%)]	Loss: 5.035245                         LR: 0.0003  Feat: 5.764 Epoch Time: 15.911 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 13.0 | [0/8000 (0%)]	Loss: 5.178545                         LR: 0.0003  Feat: 5.757 Epoch Time: 16.706 Model Time: 0.055 Data Time: 0.607 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 13.0 | [2560/8000 (32%)]	Loss: 5.160654                         LR: 0.0003  Feat: 5.757 Epoch Time: 18.205 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 13.0 | [5120/8000 (65%)]	Loss: 5.141458                         LR: 0.0003  Feat: 5.752 Epoch Time: 19.702 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 13.0 | [7680/8000 (97%)]	Loss: 5.121771                         LR: 0.0003  Feat: 5.735 Epoch Time: 21.200 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 14.0 | [0/8000 (0%)]	Loss: 5.143214                         LR: 0.0003  Feat: 5.733 Epoch Time: 21.989 Model Time: 0.056 Data Time: 0.599 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 14.0 | [2560/8000 (32%)]	Loss: 5.195651                         LR: 0.0003  Feat: 5.752 Epoch Time: 23.491 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 14.0 | [5120/8000 (65%)]	Loss: 5.124696                         LR: 0.0003  Feat: 5.746 Epoch Time: 24.991 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 14.0 | [7680/8000 (97%)]	Loss: 5.106956                         LR: 0.0003  Feat: 5.741 Epoch Time: 26.489 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  2
Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 10.0 | [0/8000 (0%)]	Loss: 5.229108                         LR: 0.0003  Feat: 4.370 Epoch Time: 0.754 Model Time: 0.057 Data Time: 0.602 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 10.0 | [2560/8000 (32%)]	Loss: 5.222590                         LR: 0.0003  Feat: 4.349 Epoch Time: 2.253 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 10.0 | [5120/8000 (65%)]	Loss: 5.152175                         LR: 0.0003  Feat: 4.341 Epoch Time: 3.748 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 10.0 | [7680/8000 (97%)]	Loss: 5.220082                         LR: 0.0003  Feat: 4.347 Epoch Time: 5.244 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 11.0 | [0/8000 (0%)]	Loss: 5.167393                         LR: 0.0003  Feat: 4.346 Epoch Time: 6.125 Model Time: 0.056 Data Time: 0.682 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 11.0 | [2560/8000 (32%)]	Loss: 5.182294                         LR: 0.0003  Feat: 4.334 Epoch Time: 7.624 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 11.0 | [5120/8000 (65%)]	Loss: 5.150106                         LR: 0.0003  Feat: 4.327 Epoch Time: 9.121 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 11.0 | [7680/8000 (97%)]	Loss: 5.150143                         LR: 0.0003  Feat: 4.317 Epoch Time: 10.618 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 12.0 | [0/8000 (0%)]	Loss: 5.119071                         LR: 0.0003  Feat: 4.316 Epoch Time: 11.403 Model Time: 0.056 Data Time: 0.593 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 12.0 | [2560/8000 (32%)]	Loss: 5.144135                         LR: 0.0003  Feat: 4.312 Epoch Time: 12.903 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 12.0 | [5120/8000 (65%)]	Loss: 5.128268                         LR: 0.0003  Feat: 4.336 Epoch Time: 14.400 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 12.0 | [7680/8000 (97%)]	Loss: 5.168799                         LR: 0.0003  Feat: 4.318 Epoch Time: 15.896 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 13.0 | [0/8000 (0%)]	Loss: 5.136355                         LR: 0.0003  Feat: 4.317 Epoch Time: 16.684 Model Time: 0.061 Data Time: 0.595 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 13.0 | [2560/8000 (32%)]	Loss: 5.144266                         LR: 0.0003  Feat: 4.315 Epoch Time: 18.183 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 13.0 | [5120/8000 (65%)]	Loss: 5.181175                         LR: 0.0003  Feat: 4.319 Epoch Time: 19.679 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 13.0 | [7680/8000 (97%)]	Loss: 5.152829                         LR: 0.0003  Feat: 4.325 Epoch Time: 21.176 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 14.0 | [0/8000 (0%)]	Loss: 5.138075                         LR: 0.0003  Feat: 4.319 Epoch Time: 21.982 Model Time: 0.055 Data Time: 0.615 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 14.0 | [2560/8000 (32%)]	Loss: 5.183914                         LR: 0.0003  Feat: 4.311 Epoch Time: 23.481 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 14.0 | [5120/8000 (65%)]	Loss: 5.174692                         LR: 0.0003  Feat: 4.313 Epoch Time: 24.977 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 14.0 | [7680/8000 (97%)]	Loss: 5.135304                         LR: 0.0003  Feat: 4.299 Epoch Time: 26.475 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  0
Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 10.0 | [0/8000 (0%)]	Loss: 5.191817                         LR: 0.0003  Feat: 7.964 Epoch Time: 0.758 Model Time: 0.056 Data Time: 0.607 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 10.0 | [2560/8000 (32%)]	Loss: 5.235590                         LR: 0.0003  Feat: 7.935 Epoch Time: 2.256 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 10.0 | [5120/8000 (65%)]	Loss: 5.137963                         LR: 0.0003  Feat: 7.914 Epoch Time: 3.752 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 10.0 | [7680/8000 (97%)]	Loss: 5.203581                         LR: 0.0003  Feat: 7.912 Epoch Time: 5.249 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 11.0 | [0/8000 (0%)]	Loss: 5.194520                         LR: 0.0003  Feat: 7.914 Epoch Time: 6.169 Model Time: 0.055 Data Time: 0.721 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 11.0 | [2560/8000 (32%)]	Loss: 5.219838                         LR: 0.0003  Feat: 7.905 Epoch Time: 7.667 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 11.0 | [5120/8000 (65%)]	Loss: 5.138712                         LR: 0.0003  Feat: 7.878 Epoch Time: 9.164 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 11.0 | [7680/8000 (97%)]	Loss: 5.131267                         LR: 0.0003  Feat: 7.885 Epoch Time: 10.661 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 12.0 | [0/8000 (0%)]	Loss: 5.167016                         LR: 0.0003  Feat: 7.890 Epoch Time: 11.550 Model Time: 0.120 Data Time: 0.636 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 12.0 | [2560/8000 (32%)]	Loss: 5.145971                         LR: 0.0003  Feat: 7.900 Epoch Time: 13.048 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 12.0 | [5120/8000 (65%)]	Loss: 5.143638                         LR: 0.0003  Feat: 7.909 Epoch Time: 14.544 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 12.0 | [7680/8000 (97%)]	Loss: 5.172954                         LR: 0.0003  Feat: 7.883 Epoch Time: 16.042 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 13.0 | [0/8000 (0%)]	Loss: 5.142613                         LR: 0.0003  Feat: 7.873 Epoch Time: 16.866 Model Time: 0.055 Data Time: 0.636 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 13.0 | [2560/8000 (32%)]	Loss: 5.145451                         LR: 0.0003  Feat: 7.881 Epoch Time: 18.364 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 13.0 | [5120/8000 (65%)]	Loss: 5.117937                         LR: 0.0003  Feat: 7.862 Epoch Time: 19.861 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 13.0 | [7680/8000 (97%)]	Loss: 5.174521                         LR: 0.0003  Feat: 7.883 Epoch Time: 21.358 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 14.0 | [0/8000 (0%)]	Loss: 5.169128                         LR: 0.0003  Feat: 7.874 Epoch Time: 22.170 Model Time: 0.056 Data Time: 0.621 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 14.0 | [2560/8000 (32%)]	Loss: 5.178327                         LR: 0.0003  Feat: 7.857 Epoch Time: 23.668 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 14.0 | [5120/8000 (65%)]	Loss: 5.201474                         LR: 0.0003  Feat: 7.856 Epoch Time: 25.162 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 14.0 | [7680/8000 (97%)]	Loss: 5.182410                         LR: 0.0003  Feat: 7.850 Epoch Time: 26.658 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  4
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked

 | Global Training Round : 4 | Model : 05-18_17:09_4152430

Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 15.0 | [0/8000 (0%)]	Loss: 5.246431                         LR: 0.0001  Feat: 11.997 Epoch Time: 0.747 Model Time: 0.057 Data Time: 0.596 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 15.0 | [2560/8000 (32%)]	Loss: 5.204728                         LR: 0.0001  Feat: 12.025 Epoch Time: 2.245 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 15.0 | [5120/8000 (65%)]	Loss: 5.148944                         LR: 0.0001  Feat: 11.980 Epoch Time: 3.741 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 15.0 | [7680/8000 (97%)]	Loss: 5.142422                         LR: 0.0001  Feat: 11.985 Epoch Time: 5.237 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 16.0 | [0/8000 (0%)]	Loss: 5.213126                         LR: 0.0001  Feat: 11.991 Epoch Time: 6.046 Model Time: 0.055 Data Time: 0.618 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 16.0 | [2560/8000 (32%)]	Loss: 5.175133                         LR: 0.0001  Feat: 11.970 Epoch Time: 7.545 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 16.0 | [5120/8000 (65%)]	Loss: 5.194176                         LR: 0.0001  Feat: 11.974 Epoch Time: 9.042 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 16.0 | [7680/8000 (97%)]	Loss: 5.146781                         LR: 0.0001  Feat: 11.950 Epoch Time: 10.539 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 17.0 | [0/8000 (0%)]	Loss: 5.161459                         LR: 0.0001  Feat: 11.951 Epoch Time: 11.343 Model Time: 0.056 Data Time: 0.610 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 17.0 | [2560/8000 (32%)]	Loss: 5.128006                         LR: 0.0001  Feat: 11.958 Epoch Time: 12.843 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 17.0 | [5120/8000 (65%)]	Loss: 5.164212                         LR: 0.0001  Feat: 11.938 Epoch Time: 14.339 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 17.0 | [7680/8000 (97%)]	Loss: 5.157911                         LR: 0.0001  Feat: 11.952 Epoch Time: 15.835 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 18.0 | [0/8000 (0%)]	Loss: 5.159238                         LR: 0.0001  Feat: 11.959 Epoch Time: 16.663 Model Time: 0.055 Data Time: 0.611 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 18.0 | [2560/8000 (32%)]	Loss: 5.165806                         LR: 0.0001  Feat: 11.929 Epoch Time: 18.173 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 18.0 | [5120/8000 (65%)]	Loss: 5.177849                         LR: 0.0001  Feat: 11.951 Epoch Time: 19.668 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 18.0 | [7680/8000 (97%)]	Loss: 5.097296                         LR: 0.0001  Feat: 11.934 Epoch Time: 21.165 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 19.0 | [0/8000 (0%)]	Loss: 5.109709                         LR: 0.0001  Feat: 11.914 Epoch Time: 21.969 Model Time: 0.056 Data Time: 0.608 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 19.0 | [2560/8000 (32%)]	Loss: 5.152244                         LR: 0.0001  Feat: 11.909 Epoch Time: 23.468 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 19.0 | [5120/8000 (65%)]	Loss: 5.156969                         LR: 0.0001  Feat: 11.942 Epoch Time: 24.964 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 19.0 | [7680/8000 (97%)]	Loss: 5.207484                         LR: 0.0001  Feat: 11.941 Epoch Time: 26.459 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  1
Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 15.0 | [0/8000 (0%)]	Loss: 5.169196                         LR: 0.0001  Feat: 10.180 Epoch Time: 0.759 Model Time: 0.058 Data Time: 0.607 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 15.0 | [2560/8000 (32%)]	Loss: 5.186941                         LR: 0.0001  Feat: 10.181 Epoch Time: 2.273 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 15.0 | [5120/8000 (65%)]	Loss: 5.201956                         LR: 0.0001  Feat: 10.148 Epoch Time: 3.769 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 15.0 | [7680/8000 (97%)]	Loss: 5.170740                         LR: 0.0001  Feat: 10.175 Epoch Time: 5.265 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 16.0 | [0/8000 (0%)]	Loss: 5.146877                         LR: 0.0001  Feat: 10.154 Epoch Time: 6.093 Model Time: 0.055 Data Time: 0.636 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 16.0 | [2560/8000 (32%)]	Loss: 5.147622                         LR: 0.0001  Feat: 10.160 Epoch Time: 7.592 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 16.0 | [5120/8000 (65%)]	Loss: 5.120784                         LR: 0.0001  Feat: 10.148 Epoch Time: 9.089 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 16.0 | [7680/8000 (97%)]	Loss: 5.135096                         LR: 0.0001  Feat: 10.135 Epoch Time: 10.587 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 17.0 | [0/8000 (0%)]	Loss: 5.102070                         LR: 0.0001  Feat: 10.144 Epoch Time: 11.380 Model Time: 0.056 Data Time: 0.600 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 17.0 | [2560/8000 (32%)]	Loss: 5.207125                         LR: 0.0001  Feat: 10.143 Epoch Time: 12.879 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 17.0 | [5120/8000 (65%)]	Loss: 5.168303                         LR: 0.0001  Feat: 10.135 Epoch Time: 14.376 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 17.0 | [7680/8000 (97%)]	Loss: 5.147348                         LR: 0.0001  Feat: 10.140 Epoch Time: 15.875 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 18.0 | [0/8000 (0%)]	Loss: 5.170386                         LR: 0.0001  Feat: 10.106 Epoch Time: 16.716 Model Time: 0.057 Data Time: 0.645 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 18.0 | [2560/8000 (32%)]	Loss: 5.164660                         LR: 0.0001  Feat: 10.124 Epoch Time: 18.328 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 18.0 | [5120/8000 (65%)]	Loss: 5.105150                         LR: 0.0001  Feat: 10.123 Epoch Time: 19.825 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 18.0 | [7680/8000 (97%)]	Loss: 5.110123                         LR: 0.0001  Feat: 10.132 Epoch Time: 21.326 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 19.0 | [0/8000 (0%)]	Loss: 5.116695                         LR: 0.0001  Feat: 10.101 Epoch Time: 22.193 Model Time: 0.055 Data Time: 0.641 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 19.0 | [2560/8000 (32%)]	Loss: 5.171227                         LR: 0.0001  Feat: 10.105 Epoch Time: 23.691 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 19.0 | [5120/8000 (65%)]	Loss: 5.132949                         LR: 0.0001  Feat: 10.144 Epoch Time: 25.187 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 19.0 | [7680/8000 (97%)]	Loss: 5.101519                         LR: 0.0001  Feat: 10.133 Epoch Time: 26.686 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  0
Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 15.0 | [0/8000 (0%)]	Loss: 5.181374                         LR: 0.0001  Feat: 16.911 Epoch Time: 0.770 Model Time: 0.058 Data Time: 0.618 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 15.0 | [2560/8000 (32%)]	Loss: 5.213943                         LR: 0.0001  Feat: 16.883 Epoch Time: 2.267 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 15.0 | [5120/8000 (65%)]	Loss: 5.201176                         LR: 0.0001  Feat: 16.890 Epoch Time: 3.762 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 15.0 | [7680/8000 (97%)]	Loss: 5.189045                         LR: 0.0001  Feat: 16.832 Epoch Time: 5.351 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 16.0 | [0/8000 (0%)]	Loss: 5.205081                         LR: 0.0001  Feat: 16.820 Epoch Time: 6.180 Model Time: 0.055 Data Time: 0.635 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 16.0 | [2560/8000 (32%)]	Loss: 5.185122                         LR: 0.0001  Feat: 16.872 Epoch Time: 7.676 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 16.0 | [5120/8000 (65%)]	Loss: 5.139410                         LR: 0.0001  Feat: 16.841 Epoch Time: 9.171 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 16.0 | [7680/8000 (97%)]	Loss: 5.124480                         LR: 0.0001  Feat: 16.786 Epoch Time: 10.666 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 17.0 | [0/8000 (0%)]	Loss: 5.202379                         LR: 0.0001  Feat: 16.807 Epoch Time: 11.480 Model Time: 0.056 Data Time: 0.621 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 17.0 | [2560/8000 (32%)]	Loss: 5.102099                         LR: 0.0001  Feat: 16.858 Epoch Time: 12.978 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 17.0 | [5120/8000 (65%)]	Loss: 5.122149                         LR: 0.0001  Feat: 16.850 Epoch Time: 14.476 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 17.0 | [7680/8000 (97%)]	Loss: 5.169665                         LR: 0.0001  Feat: 16.792 Epoch Time: 15.974 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 18.0 | [0/8000 (0%)]	Loss: 5.098506                         LR: 0.0001  Feat: 16.828 Epoch Time: 16.785 Model Time: 0.056 Data Time: 0.617 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 18.0 | [2560/8000 (32%)]	Loss: 5.216081                         LR: 0.0001  Feat: 16.829 Epoch Time: 18.282 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 18.0 | [5120/8000 (65%)]	Loss: 5.089456                         LR: 0.0001  Feat: 16.826 Epoch Time: 19.779 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 18.0 | [7680/8000 (97%)]	Loss: 5.185517                         LR: 0.0001  Feat: 16.803 Epoch Time: 21.275 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 19.0 | [0/8000 (0%)]	Loss: 5.103352                         LR: 0.0001  Feat: 16.826 Epoch Time: 22.221 Model Time: 0.059 Data Time: 0.738 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 19.0 | [2560/8000 (32%)]	Loss: 5.218842                         LR: 0.0001  Feat: 16.820 Epoch Time: 23.721 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 19.0 | [5120/8000 (65%)]	Loss: 5.161186                         LR: 0.0001  Feat: 16.799 Epoch Time: 25.218 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 19.0 | [7680/8000 (97%)]	Loss: 5.134228                         LR: 0.0001  Feat: 16.816 Epoch Time: 26.716 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  3
Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 15.0 | [0/8000 (0%)]	Loss: 5.181060                         LR: 0.0001  Feat: 14.185 Epoch Time: 0.769 Model Time: 0.057 Data Time: 0.617 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 15.0 | [2560/8000 (32%)]	Loss: 5.203520                         LR: 0.0001  Feat: 14.211 Epoch Time: 2.267 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 15.0 | [5120/8000 (65%)]	Loss: 5.222930                         LR: 0.0001  Feat: 14.197 Epoch Time: 3.764 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 15.0 | [7680/8000 (97%)]	Loss: 5.222258                         LR: 0.0001  Feat: 14.146 Epoch Time: 5.262 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 16.0 | [0/8000 (0%)]	Loss: 5.159984                         LR: 0.0001  Feat: 14.193 Epoch Time: 6.079 Model Time: 0.060 Data Time: 0.621 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 16.0 | [2560/8000 (32%)]	Loss: 5.176838                         LR: 0.0001  Feat: 14.178 Epoch Time: 7.576 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 16.0 | [5120/8000 (65%)]	Loss: 5.133477                         LR: 0.0001  Feat: 14.177 Epoch Time: 9.075 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 16.0 | [7680/8000 (97%)]	Loss: 5.131101                         LR: 0.0001  Feat: 14.159 Epoch Time: 10.571 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 17.0 | [0/8000 (0%)]	Loss: 5.201304                         LR: 0.0001  Feat: 14.187 Epoch Time: 11.388 Model Time: 0.055 Data Time: 0.623 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 17.0 | [2560/8000 (32%)]	Loss: 5.112025                         LR: 0.0001  Feat: 14.205 Epoch Time: 12.893 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 17.0 | [5120/8000 (65%)]	Loss: 5.130383                         LR: 0.0001  Feat: 14.153 Epoch Time: 14.388 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 17.0 | [7680/8000 (97%)]	Loss: 5.168658                         LR: 0.0001  Feat: 14.182 Epoch Time: 15.883 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 18.0 | [0/8000 (0%)]	Loss: 5.126425                         LR: 0.0001  Feat: 14.136 Epoch Time: 16.690 Model Time: 0.058 Data Time: 0.611 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 18.0 | [2560/8000 (32%)]	Loss: 5.142618                         LR: 0.0001  Feat: 14.184 Epoch Time: 18.188 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 18.0 | [5120/8000 (65%)]	Loss: 5.135915                         LR: 0.0001  Feat: 14.135 Epoch Time: 19.684 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 18.0 | [7680/8000 (97%)]	Loss: 5.136369                         LR: 0.0001  Feat: 14.157 Epoch Time: 21.180 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 19.0 | [0/8000 (0%)]	Loss: 5.113303                         LR: 0.0001  Feat: 14.163 Epoch Time: 22.006 Model Time: 0.060 Data Time: 0.633 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 19.0 | [2560/8000 (32%)]	Loss: 5.209973                         LR: 0.0001  Feat: 14.169 Epoch Time: 23.502 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 19.0 | [5120/8000 (65%)]	Loss: 5.217030                         LR: 0.0001  Feat: 14.123 Epoch Time: 25.002 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 19.0 | [7680/8000 (97%)]	Loss: 5.176023                         LR: 0.0001  Feat: 14.161 Epoch Time: 26.500 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  2
Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 15.0 | [0/8000 (0%)]	Loss: 5.241507                         LR: 0.0001  Feat: 20.089 Epoch Time: 0.759 Model Time: 0.062 Data Time: 0.606 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 15.0 | [2560/8000 (32%)]	Loss: 5.246950                         LR: 0.0001  Feat: 20.043 Epoch Time: 2.255 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 15.0 | [5120/8000 (65%)]	Loss: 5.173903                         LR: 0.0001  Feat: 20.051 Epoch Time: 3.750 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 15.0 | [7680/8000 (97%)]	Loss: 5.182009                         LR: 0.0001  Feat: 20.007 Epoch Time: 5.247 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 16.0 | [0/8000 (0%)]	Loss: 5.195346                         LR: 0.0001  Feat: 20.049 Epoch Time: 6.044 Model Time: 0.056 Data Time: 0.605 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 16.0 | [2560/8000 (32%)]	Loss: 5.224298                         LR: 0.0001  Feat: 20.037 Epoch Time: 7.543 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 16.0 | [5120/8000 (65%)]	Loss: 5.173514                         LR: 0.0001  Feat: 20.066 Epoch Time: 9.041 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 16.0 | [7680/8000 (97%)]	Loss: 5.181742                         LR: 0.0001  Feat: 20.051 Epoch Time: 10.536 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 17.0 | [0/8000 (0%)]	Loss: 5.198922                         LR: 0.0001  Feat: 20.010 Epoch Time: 11.373 Model Time: 0.057 Data Time: 0.639 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 17.0 | [2560/8000 (32%)]	Loss: 5.176758                         LR: 0.0001  Feat: 20.030 Epoch Time: 12.868 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 17.0 | [5120/8000 (65%)]	Loss: 5.174529                         LR: 0.0001  Feat: 20.027 Epoch Time: 14.365 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 17.0 | [7680/8000 (97%)]	Loss: 5.178486                         LR: 0.0001  Feat: 20.011 Epoch Time: 15.860 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 18.0 | [0/8000 (0%)]	Loss: 5.172745                         LR: 0.0001  Feat: 20.029 Epoch Time: 16.681 Model Time: 0.055 Data Time: 0.629 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 18.0 | [2560/8000 (32%)]	Loss: 5.143746                         LR: 0.0001  Feat: 19.993 Epoch Time: 18.183 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 18.0 | [5120/8000 (65%)]	Loss: 5.131664                         LR: 0.0001  Feat: 20.050 Epoch Time: 19.684 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 18.0 | [7680/8000 (97%)]	Loss: 5.166794                         LR: 0.0001  Feat: 19.980 Epoch Time: 21.181 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 19.0 | [0/8000 (0%)]	Loss: 5.126655                         LR: 0.0001  Feat: 19.999 Epoch Time: 21.990 Model Time: 0.056 Data Time: 0.614 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 19.0 | [2560/8000 (32%)]	Loss: 5.166555                         LR: 0.0001  Feat: 20.040 Epoch Time: 23.489 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 19.0 | [5120/8000 (65%)]	Loss: 5.194336                         LR: 0.0001  Feat: 19.983 Epoch Time: 24.990 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 19.0 | [7680/8000 (97%)]	Loss: 5.125676                         LR: 0.0001  Feat: 19.992 Epoch Time: 26.488 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  4
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked

 | Global Training Round : 5 | Model : 05-18_17:09_4152430

Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 20.0 | [0/8000 (0%)]	Loss: 5.193033                         LR: 0.0001  Feat: 50.153 Epoch Time: 0.793 Model Time: 0.056 Data Time: 0.642 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 20.0 | [2560/8000 (32%)]	Loss: 5.169940                         LR: 0.0001  Feat: 50.261 Epoch Time: 2.293 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 20.0 | [5120/8000 (65%)]	Loss: 5.164604                         LR: 0.0001  Feat: 50.247 Epoch Time: 3.790 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 20.0 | [7680/8000 (97%)]	Loss: 5.157130                         LR: 0.0001  Feat: 50.198 Epoch Time: 5.287 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 21.0 | [0/8000 (0%)]	Loss: 5.212191                         LR: 0.0001  Feat: 50.139 Epoch Time: 6.096 Model Time: 0.056 Data Time: 0.615 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 21.0 | [2560/8000 (32%)]	Loss: 5.187886                         LR: 0.0001  Feat: 50.330 Epoch Time: 7.595 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 21.0 | [5120/8000 (65%)]	Loss: 5.137716                         LR: 0.0001  Feat: 50.132 Epoch Time: 9.092 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 21.0 | [7680/8000 (97%)]	Loss: 5.204404                         LR: 0.0001  Feat: 50.108 Epoch Time: 10.588 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 22.0 | [0/8000 (0%)]	Loss: 5.179381                         LR: 0.0001  Feat: 50.135 Epoch Time: 11.407 Model Time: 0.055 Data Time: 0.627 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 22.0 | [2560/8000 (32%)]	Loss: 5.127855                         LR: 0.0001  Feat: 50.181 Epoch Time: 12.903 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 22.0 | [5120/8000 (65%)]	Loss: 5.208630                         LR: 0.0001  Feat: 50.196 Epoch Time: 14.400 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 22.0 | [7680/8000 (97%)]	Loss: 5.145321                         LR: 0.0001  Feat: 50.223 Epoch Time: 15.896 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 23.0 | [0/8000 (0%)]	Loss: 5.177711                         LR: 0.0001  Feat: 50.188 Epoch Time: 16.724 Model Time: 0.055 Data Time: 0.636 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 23.0 | [2560/8000 (32%)]	Loss: 5.228258                         LR: 0.0001  Feat: 50.233 Epoch Time: 18.221 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 23.0 | [5120/8000 (65%)]	Loss: 5.142384                         LR: 0.0001  Feat: 50.213 Epoch Time: 19.716 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 23.0 | [7680/8000 (97%)]	Loss: 5.123138                         LR: 0.0001  Feat: 50.102 Epoch Time: 21.211 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 24.0 | [0/8000 (0%)]	Loss: 5.110835                         LR: 0.0001  Feat: 50.169 Epoch Time: 22.018 Model Time: 0.059 Data Time: 0.614 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 24.0 | [2560/8000 (32%)]	Loss: 5.136781                         LR: 0.0001  Feat: 50.128 Epoch Time: 23.514 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 24.0 | [5120/8000 (65%)]	Loss: 5.179612                         LR: 0.0001  Feat: 50.139 Epoch Time: 25.008 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 24.0 | [7680/8000 (97%)]	Loss: 5.134128                         LR: 0.0001  Feat: 50.093 Epoch Time: 26.502 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  4
Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 20.0 | [0/8000 (0%)]	Loss: 5.228636                         LR: 0.0001  Feat: 41.911 Epoch Time: 0.770 Model Time: 0.060 Data Time: 0.619 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 20.0 | [2560/8000 (32%)]	Loss: 5.233746                         LR: 0.0001  Feat: 42.029 Epoch Time: 2.268 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 20.0 | [5120/8000 (65%)]	Loss: 5.220074                         LR: 0.0001  Feat: 41.932 Epoch Time: 3.766 Model Time: 0.055 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 20.0 | [7680/8000 (97%)]	Loss: 5.123581                         LR: 0.0001  Feat: 41.842 Epoch Time: 5.263 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 21.0 | [0/8000 (0%)]	Loss: 5.215719                         LR: 0.0001  Feat: 41.903 Epoch Time: 6.072 Model Time: 0.055 Data Time: 0.616 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 21.0 | [2560/8000 (32%)]	Loss: 5.124458                         LR: 0.0001  Feat: 41.902 Epoch Time: 7.569 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 21.0 | [5120/8000 (65%)]	Loss: 5.256001                         LR: 0.0001  Feat: 41.919 Epoch Time: 9.066 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 21.0 | [7680/8000 (97%)]	Loss: 5.140251                         LR: 0.0001  Feat: 41.883 Epoch Time: 10.562 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 22.0 | [0/8000 (0%)]	Loss: 5.221273                         LR: 0.0001  Feat: 41.930 Epoch Time: 11.380 Model Time: 0.055 Data Time: 0.629 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 22.0 | [2560/8000 (32%)]	Loss: 5.160648                         LR: 0.0001  Feat: 41.998 Epoch Time: 12.883 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 22.0 | [5120/8000 (65%)]	Loss: 5.146759                         LR: 0.0001  Feat: 41.879 Epoch Time: 14.378 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 22.0 | [7680/8000 (97%)]	Loss: 5.134004                         LR: 0.0001  Feat: 41.885 Epoch Time: 15.874 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 23.0 | [0/8000 (0%)]	Loss: 5.136586                         LR: 0.0001  Feat: 41.963 Epoch Time: 16.699 Model Time: 0.054 Data Time: 0.631 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 23.0 | [2560/8000 (32%)]	Loss: 5.181693                         LR: 0.0001  Feat: 41.990 Epoch Time: 18.196 Model Time: 0.052 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 23.0 | [5120/8000 (65%)]	Loss: 5.168143                         LR: 0.0001  Feat: 41.992 Epoch Time: 19.691 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 23.0 | [7680/8000 (97%)]	Loss: 5.131907                         LR: 0.0001  Feat: 41.956 Epoch Time: 21.187 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 24.0 | [0/8000 (0%)]	Loss: 5.126747                         LR: 0.0001  Feat: 42.005 Epoch Time: 21.980 Model Time: 0.056 Data Time: 0.598 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 24.0 | [2560/8000 (32%)]	Loss: 5.190916                         LR: 0.0001  Feat: 41.897 Epoch Time: 23.479 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 24.0 | [5120/8000 (65%)]	Loss: 5.160118                         LR: 0.0001  Feat: 41.971 Epoch Time: 24.977 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 24.0 | [7680/8000 (97%)]	Loss: 5.118699                         LR: 0.0001  Feat: 42.025 Epoch Time: 26.476 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  3
Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 20.0 | [0/8000 (0%)]	Loss: 5.161723                         LR: 0.0001  Feat: 24.688 Epoch Time: 0.782 Model Time: 0.056 Data Time: 0.631 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 20.0 | [2560/8000 (32%)]	Loss: 5.193859                         LR: 0.0001  Feat: 24.631 Epoch Time: 2.280 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 20.0 | [5120/8000 (65%)]	Loss: 5.127070                         LR: 0.0001  Feat: 24.635 Epoch Time: 3.775 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 20.0 | [7680/8000 (97%)]	Loss: 5.147883                         LR: 0.0001  Feat: 24.671 Epoch Time: 5.275 Model Time: 0.054 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 21.0 | [0/8000 (0%)]	Loss: 5.163705                         LR: 0.0001  Feat: 24.603 Epoch Time: 6.077 Model Time: 0.055 Data Time: 0.612 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 21.0 | [2560/8000 (32%)]	Loss: 5.166605                         LR: 0.0001  Feat: 24.618 Epoch Time: 7.575 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 21.0 | [5120/8000 (65%)]	Loss: 5.153828                         LR: 0.0001  Feat: 24.660 Epoch Time: 9.071 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 21.0 | [7680/8000 (97%)]	Loss: 5.171288                         LR: 0.0001  Feat: 24.666 Epoch Time: 10.565 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 22.0 | [0/8000 (0%)]	Loss: 5.127901                         LR: 0.0001  Feat: 24.683 Epoch Time: 11.363 Model Time: 0.055 Data Time: 0.609 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 22.0 | [2560/8000 (32%)]	Loss: 5.198437                         LR: 0.0001  Feat: 24.623 Epoch Time: 12.859 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 22.0 | [5120/8000 (65%)]	Loss: 5.134266                         LR: 0.0001  Feat: 24.655 Epoch Time: 14.358 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 22.0 | [7680/8000 (97%)]	Loss: 5.194964                         LR: 0.0001  Feat: 24.585 Epoch Time: 15.853 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 23.0 | [0/8000 (0%)]	Loss: 5.183714                         LR: 0.0001  Feat: 24.597 Epoch Time: 16.643 Model Time: 0.059 Data Time: 0.597 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 23.0 | [2560/8000 (32%)]	Loss: 5.192540                         LR: 0.0001  Feat: 24.645 Epoch Time: 18.142 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 23.0 | [5120/8000 (65%)]	Loss: 5.166936                         LR: 0.0001  Feat: 24.668 Epoch Time: 19.639 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 23.0 | [7680/8000 (97%)]	Loss: 5.118743                         LR: 0.0001  Feat: 24.574 Epoch Time: 21.193 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 24.0 | [0/8000 (0%)]	Loss: 5.142647                         LR: 0.0001  Feat: 24.636 Epoch Time: 21.984 Model Time: 0.057 Data Time: 0.597 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 24.0 | [2560/8000 (32%)]	Loss: 5.160723                         LR: 0.0001  Feat: 24.642 Epoch Time: 23.483 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 24.0 | [5120/8000 (65%)]	Loss: 5.174379                         LR: 0.0001  Feat: 24.672 Epoch Time: 24.980 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 24.0 | [7680/8000 (97%)]	Loss: 5.089698                         LR: 0.0001  Feat: 24.641 Epoch Time: 26.475 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  0
Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 20.0 | [0/8000 (0%)]	Loss: 5.142741                         LR: 0.0001  Feat: 29.469 Epoch Time: 0.770 Model Time: 0.056 Data Time: 0.619 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 20.0 | [2560/8000 (32%)]	Loss: 5.199528                         LR: 0.0001  Feat: 29.402 Epoch Time: 2.266 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 20.0 | [5120/8000 (65%)]	Loss: 5.157465                         LR: 0.0001  Feat: 29.501 Epoch Time: 3.763 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 20.0 | [7680/8000 (97%)]	Loss: 5.172629                         LR: 0.0001  Feat: 29.493 Epoch Time: 5.260 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 21.0 | [0/8000 (0%)]	Loss: 5.183330                         LR: 0.0001  Feat: 29.376 Epoch Time: 6.058 Model Time: 0.055 Data Time: 0.608 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 21.0 | [2560/8000 (32%)]	Loss: 5.149893                         LR: 0.0001  Feat: 29.335 Epoch Time: 7.556 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 21.0 | [5120/8000 (65%)]	Loss: 5.182435                         LR: 0.0001  Feat: 29.421 Epoch Time: 9.056 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 21.0 | [7680/8000 (97%)]	Loss: 5.171031                         LR: 0.0001  Feat: 29.378 Epoch Time: 10.554 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 22.0 | [0/8000 (0%)]	Loss: 5.172234                         LR: 0.0001  Feat: 29.383 Epoch Time: 11.348 Model Time: 0.058 Data Time: 0.602 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 22.0 | [2560/8000 (32%)]	Loss: 5.200112                         LR: 0.0001  Feat: 29.386 Epoch Time: 12.847 Model Time: 0.052 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 22.0 | [5120/8000 (65%)]	Loss: 5.192528                         LR: 0.0001  Feat: 29.426 Epoch Time: 14.345 Model Time: 0.052 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 22.0 | [7680/8000 (97%)]	Loss: 5.147719                         LR: 0.0001  Feat: 29.429 Epoch Time: 15.843 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 23.0 | [0/8000 (0%)]	Loss: 5.118805                         LR: 0.0001  Feat: 29.459 Epoch Time: 16.657 Model Time: 0.055 Data Time: 0.621 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 23.0 | [2560/8000 (32%)]	Loss: 5.081245                         LR: 0.0001  Feat: 29.400 Epoch Time: 18.158 Model Time: 0.051 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 23.0 | [5120/8000 (65%)]	Loss: 5.165329                         LR: 0.0001  Feat: 29.383 Epoch Time: 19.654 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 23.0 | [7680/8000 (97%)]	Loss: 5.169725                         LR: 0.0001  Feat: 29.342 Epoch Time: 21.151 Model Time: 0.052 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 24.0 | [0/8000 (0%)]	Loss: 5.203557                         LR: 0.0001  Feat: 29.333 Epoch Time: 21.960 Model Time: 0.059 Data Time: 0.617 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 24.0 | [2560/8000 (32%)]	Loss: 5.123462                         LR: 0.0001  Feat: 29.299 Epoch Time: 23.461 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 24.0 | [5120/8000 (65%)]	Loss: 5.178585                         LR: 0.0001  Feat: 29.308 Epoch Time: 24.957 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 24.0 | [7680/8000 (97%)]	Loss: 5.192479                         LR: 0.0001  Feat: 29.330 Epoch Time: 26.455 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  1
Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 20.0 | [0/8000 (0%)]	Loss: 5.163846                         LR: 0.0001  Feat: 35.120 Epoch Time: 0.760 Model Time: 0.056 Data Time: 0.610 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 20.0 | [2560/8000 (32%)]	Loss: 5.136827                         LR: 0.0001  Feat: 35.137 Epoch Time: 2.261 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 20.0 | [5120/8000 (65%)]	Loss: 5.166966                         LR: 0.0001  Feat: 35.140 Epoch Time: 3.757 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 20.0 | [7680/8000 (97%)]	Loss: 5.126044                         LR: 0.0001  Feat: 35.092 Epoch Time: 5.252 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 21.0 | [0/8000 (0%)]	Loss: 5.231949                         LR: 0.0001  Feat: 35.134 Epoch Time: 6.068 Model Time: 0.055 Data Time: 0.623 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 21.0 | [2560/8000 (32%)]	Loss: 5.155423                         LR: 0.0001  Feat: 35.066 Epoch Time: 7.566 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 21.0 | [5120/8000 (65%)]	Loss: 5.147301                         LR: 0.0001  Feat: 35.088 Epoch Time: 9.063 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 21.0 | [7680/8000 (97%)]	Loss: 5.181062                         LR: 0.0001  Feat: 35.122 Epoch Time: 10.561 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 22.0 | [0/8000 (0%)]	Loss: 5.190704                         LR: 0.0001  Feat: 35.046 Epoch Time: 11.348 Model Time: 0.057 Data Time: 0.596 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 22.0 | [2560/8000 (32%)]	Loss: 5.166139                         LR: 0.0001  Feat: 35.089 Epoch Time: 12.846 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 22.0 | [5120/8000 (65%)]	Loss: 5.197475                         LR: 0.0001  Feat: 35.116 Epoch Time: 14.342 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 22.0 | [7680/8000 (97%)]	Loss: 5.188777                         LR: 0.0001  Feat: 35.140 Epoch Time: 15.840 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 23.0 | [0/8000 (0%)]	Loss: 5.115799                         LR: 0.0001  Feat: 35.121 Epoch Time: 16.639 Model Time: 0.056 Data Time: 0.606 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 23.0 | [2560/8000 (32%)]	Loss: 5.136610                         LR: 0.0001  Feat: 35.060 Epoch Time: 18.135 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 23.0 | [5120/8000 (65%)]	Loss: 5.176388                         LR: 0.0001  Feat: 35.058 Epoch Time: 19.631 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 23.0 | [7680/8000 (97%)]	Loss: 5.188922                         LR: 0.0001  Feat: 35.099 Epoch Time: 21.127 Model Time: 0.052 Data Time: 0.097 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 24.0 | [0/8000 (0%)]	Loss: 5.221515                         LR: 0.0001  Feat: 35.055 Epoch Time: 21.941 Model Time: 0.056 Data Time: 0.621 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 24.0 | [2560/8000 (32%)]	Loss: 5.218956                         LR: 0.0001  Feat: 35.080 Epoch Time: 23.438 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 24.0 | [5120/8000 (65%)]	Loss: 5.153027                         LR: 0.0001  Feat: 35.138 Epoch Time: 24.936 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 24.0 | [7680/8000 (97%)]	Loss: 5.130033                         LR: 0.0001  Feat: 35.154 Epoch Time: 26.432 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  2
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked

 | Global Training Round : 6 | Model : 05-18_17:09_4152430

Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 25.0 | [0/8000 (0%)]	Loss: 5.142958                         LR: 0.0000  Feat: 72.958 Epoch Time: 0.772 Model Time: 0.057 Data Time: 0.622 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 25.0 | [2560/8000 (32%)]	Loss: 5.206500                         LR: 0.0000  Feat: 72.880 Epoch Time: 2.271 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 25.0 | [5120/8000 (65%)]	Loss: 5.196574                         LR: 0.0000  Feat: 72.661 Epoch Time: 3.769 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 25.0 | [7680/8000 (97%)]	Loss: 5.172184                         LR: 0.0000  Feat: 72.705 Epoch Time: 5.265 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 26.0 | [0/8000 (0%)]	Loss: 5.221012                         LR: 0.0000  Feat: 72.845 Epoch Time: 6.080 Model Time: 0.055 Data Time: 0.621 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 26.0 | [2560/8000 (32%)]	Loss: 5.140950                         LR: 0.0000  Feat: 72.768 Epoch Time: 7.576 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 26.0 | [5120/8000 (65%)]	Loss: 5.159694                         LR: 0.0000  Feat: 72.840 Epoch Time: 9.071 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 26.0 | [7680/8000 (97%)]	Loss: 5.216043                         LR: 0.0000  Feat: 72.660 Epoch Time: 10.568 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 27.0 | [0/8000 (0%)]	Loss: 5.149157                         LR: 0.0000  Feat: 72.907 Epoch Time: 11.379 Model Time: 0.054 Data Time: 0.620 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 27.0 | [2560/8000 (32%)]	Loss: 5.144388                         LR: 0.0000  Feat: 72.841 Epoch Time: 12.876 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 27.0 | [5120/8000 (65%)]	Loss: 5.236480                         LR: 0.0000  Feat: 72.702 Epoch Time: 14.371 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 27.0 | [7680/8000 (97%)]	Loss: 5.119879                         LR: 0.0000  Feat: 72.735 Epoch Time: 15.869 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 28.0 | [0/8000 (0%)]	Loss: 5.155213                         LR: 0.0000  Feat: 72.748 Epoch Time: 16.685 Model Time: 0.055 Data Time: 0.621 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 28.0 | [2560/8000 (32%)]	Loss: 5.174392                         LR: 0.0000  Feat: 72.787 Epoch Time: 18.183 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 28.0 | [5120/8000 (65%)]	Loss: 5.196822                         LR: 0.0000  Feat: 72.723 Epoch Time: 19.680 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 28.0 | [7680/8000 (97%)]	Loss: 5.158852                         LR: 0.0000  Feat: 72.807 Epoch Time: 21.176 Model Time: 0.052 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 29.0 | [0/8000 (0%)]	Loss: 5.204898                         LR: 0.0000  Feat: 72.637 Epoch Time: 21.982 Model Time: 0.057 Data Time: 0.609 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 29.0 | [2560/8000 (32%)]	Loss: 5.072547                         LR: 0.0000  Feat: 72.881 Epoch Time: 23.478 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 29.0 | [5120/8000 (65%)]	Loss: 5.198317                         LR: 0.0000  Feat: 72.824 Epoch Time: 24.978 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 29.0 | [7680/8000 (97%)]	Loss: 5.206196                         LR: 0.0000  Feat: 73.004 Epoch Time: 26.474 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  2.6999999999999996e-05
Find_phi_psi for agent:  1
Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 25.0 | [0/8000 (0%)]	Loss: 5.197136                         LR: 0.0000  Feat: 60.768 Epoch Time: 0.756 Model Time: 0.057 Data Time: 0.604 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 25.0 | [2560/8000 (32%)]	Loss: 5.156057                         LR: 0.0000  Feat: 60.694 Epoch Time: 2.257 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 25.0 | [5120/8000 (65%)]	Loss: 5.137386                         LR: 0.0000  Feat: 60.705 Epoch Time: 3.754 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 25.0 | [7680/8000 (97%)]	Loss: 5.170503                         LR: 0.0000  Feat: 60.737 Epoch Time: 5.250 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 26.0 | [0/8000 (0%)]	Loss: 5.224452                         LR: 0.0000  Feat: 60.781 Epoch Time: 6.063 Model Time: 0.063 Data Time: 0.616 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 26.0 | [2560/8000 (32%)]	Loss: 5.203737                         LR: 0.0000  Feat: 60.832 Epoch Time: 7.563 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 26.0 | [5120/8000 (65%)]	Loss: 5.186090                         LR: 0.0000  Feat: 60.784 Epoch Time: 9.063 Model Time: 0.053 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 26.0 | [7680/8000 (97%)]	Loss: 5.116825                         LR: 0.0000  Feat: 60.904 Epoch Time: 10.560 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 27.0 | [0/8000 (0%)]	Loss: 5.196525                         LR: 0.0000  Feat: 60.820 Epoch Time: 11.403 Model Time: 0.060 Data Time: 0.650 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 27.0 | [2560/8000 (32%)]	Loss: 5.199878                         LR: 0.0000  Feat: 60.878 Epoch Time: 12.902 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 27.0 | [5120/8000 (65%)]	Loss: 5.162241                         LR: 0.0000  Feat: 60.688 Epoch Time: 14.397 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 27.0 | [7680/8000 (97%)]	Loss: 5.161328                         LR: 0.0000  Feat: 60.884 Epoch Time: 15.892 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 28.0 | [0/8000 (0%)]	Loss: 5.166318                         LR: 0.0000  Feat: 60.696 Epoch Time: 16.723 Model Time: 0.055 Data Time: 0.639 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 28.0 | [2560/8000 (32%)]	Loss: 5.160971                         LR: 0.0000  Feat: 60.842 Epoch Time: 18.221 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 28.0 | [5120/8000 (65%)]	Loss: 5.149750                         LR: 0.0000  Feat: 60.568 Epoch Time: 19.718 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 28.0 | [7680/8000 (97%)]	Loss: 5.200892                         LR: 0.0000  Feat: 60.678 Epoch Time: 21.215 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 29.0 | [0/8000 (0%)]	Loss: 5.180395                         LR: 0.0000  Feat: 60.815 Epoch Time: 22.166 Model Time: 0.057 Data Time: 0.752 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 29.0 | [2560/8000 (32%)]	Loss: 5.181660                         LR: 0.0000  Feat: 60.598 Epoch Time: 23.663 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 29.0 | [5120/8000 (65%)]	Loss: 5.160685                         LR: 0.0000  Feat: 60.892 Epoch Time: 25.160 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 29.0 | [7680/8000 (97%)]	Loss: 5.157129                         LR: 0.0000  Feat: 60.758 Epoch Time: 26.657 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  2.6999999999999996e-05
Find_phi_psi for agent:  0
Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 25.0 | [0/8000 (0%)]	Loss: 5.197921                         LR: 0.0000  Feat: 125.204 Epoch Time: 0.766 Model Time: 0.061 Data Time: 0.614 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 25.0 | [2560/8000 (32%)]	Loss: 5.218347                         LR: 0.0000  Feat: 125.039 Epoch Time: 2.263 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 25.0 | [5120/8000 (65%)]	Loss: 5.136214                         LR: 0.0000  Feat: 125.338 Epoch Time: 3.801 Model Time: 0.097 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 25.0 | [7680/8000 (97%)]	Loss: 5.146291                         LR: 0.0000  Feat: 125.046 Epoch Time: 5.297 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 26.0 | [0/8000 (0%)]	Loss: 5.141416                         LR: 0.0000  Feat: 125.160 Epoch Time: 6.106 Model Time: 0.055 Data Time: 0.617 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 26.0 | [2560/8000 (32%)]	Loss: 5.180117                         LR: 0.0000  Feat: 125.233 Epoch Time: 7.603 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 26.0 | [5120/8000 (65%)]	Loss: 5.185025                         LR: 0.0000  Feat: 125.217 Epoch Time: 9.100 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 26.0 | [7680/8000 (97%)]	Loss: 5.154902                         LR: 0.0000  Feat: 125.257 Epoch Time: 10.598 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 27.0 | [0/8000 (0%)]	Loss: 5.186774                         LR: 0.0000  Feat: 125.448 Epoch Time: 11.419 Model Time: 0.055 Data Time: 0.629 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 27.0 | [2560/8000 (32%)]	Loss: 5.182856                         LR: 0.0000  Feat: 125.258 Epoch Time: 12.916 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 27.0 | [5120/8000 (65%)]	Loss: 5.103935                         LR: 0.0000  Feat: 125.430 Epoch Time: 14.413 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 27.0 | [7680/8000 (97%)]	Loss: 5.142450                         LR: 0.0000  Feat: 125.231 Epoch Time: 15.913 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 28.0 | [0/8000 (0%)]	Loss: 5.192810                         LR: 0.0000  Feat: 125.216 Epoch Time: 16.739 Model Time: 0.055 Data Time: 0.631 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 28.0 | [2560/8000 (32%)]	Loss: 5.192695                         LR: 0.0000  Feat: 125.116 Epoch Time: 18.237 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 28.0 | [5120/8000 (65%)]	Loss: 5.225036                         LR: 0.0000  Feat: 125.418 Epoch Time: 19.733 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 28.0 | [7680/8000 (97%)]	Loss: 5.191450                         LR: 0.0000  Feat: 125.384 Epoch Time: 21.229 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 29.0 | [0/8000 (0%)]	Loss: 5.200499                         LR: 0.0000  Feat: 125.005 Epoch Time: 22.035 Model Time: 0.059 Data Time: 0.615 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 29.0 | [2560/8000 (32%)]	Loss: 5.125753                         LR: 0.0000  Feat: 125.275 Epoch Time: 23.531 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 29.0 | [5120/8000 (65%)]	Loss: 5.184141                         LR: 0.0000  Feat: 125.484 Epoch Time: 25.028 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 29.0 | [7680/8000 (97%)]	Loss: 5.149582                         LR: 0.0000  Feat: 125.351 Epoch Time: 26.523 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  2.6999999999999996e-05
Find_phi_psi for agent:  4
Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 25.0 | [0/8000 (0%)]	Loss: 5.194077                         LR: 0.0000  Feat: 104.359 Epoch Time: 0.758 Model Time: 0.056 Data Time: 0.607 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 25.0 | [2560/8000 (32%)]	Loss: 5.194036                         LR: 0.0000  Feat: 104.478 Epoch Time: 2.257 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 25.0 | [5120/8000 (65%)]	Loss: 5.159965                         LR: 0.0000  Feat: 104.372 Epoch Time: 3.753 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 25.0 | [7680/8000 (97%)]	Loss: 5.113521                         LR: 0.0000  Feat: 104.582 Epoch Time: 5.249 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 26.0 | [0/8000 (0%)]	Loss: 5.131697                         LR: 0.0000  Feat: 104.368 Epoch Time: 6.068 Model Time: 0.056 Data Time: 0.624 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 26.0 | [2560/8000 (32%)]	Loss: 5.157746                         LR: 0.0000  Feat: 104.446 Epoch Time: 7.563 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 26.0 | [5120/8000 (65%)]	Loss: 5.202879                         LR: 0.0000  Feat: 104.474 Epoch Time: 9.059 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 26.0 | [7680/8000 (97%)]	Loss: 5.190015                         LR: 0.0000  Feat: 104.264 Epoch Time: 10.552 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 27.0 | [0/8000 (0%)]	Loss: 5.122049                         LR: 0.0000  Feat: 104.411 Epoch Time: 11.346 Model Time: 0.056 Data Time: 0.598 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 27.0 | [2560/8000 (32%)]	Loss: 5.169371                         LR: 0.0000  Feat: 104.455 Epoch Time: 12.844 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 27.0 | [5120/8000 (65%)]	Loss: 5.192648                         LR: 0.0000  Feat: 104.485 Epoch Time: 14.338 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 27.0 | [7680/8000 (97%)]	Loss: 5.146121                         LR: 0.0000  Feat: 104.316 Epoch Time: 15.831 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 28.0 | [0/8000 (0%)]	Loss: 5.105285                         LR: 0.0000  Feat: 104.310 Epoch Time: 16.628 Model Time: 0.055 Data Time: 0.603 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 28.0 | [2560/8000 (32%)]	Loss: 5.253829                         LR: 0.0000  Feat: 104.391 Epoch Time: 18.305 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 28.0 | [5120/8000 (65%)]	Loss: 5.161144                         LR: 0.0000  Feat: 104.612 Epoch Time: 19.800 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 28.0 | [7680/8000 (97%)]	Loss: 5.125703                         LR: 0.0000  Feat: 104.459 Epoch Time: 21.296 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 29.0 | [0/8000 (0%)]	Loss: 5.214136                         LR: 0.0000  Feat: 104.149 Epoch Time: 22.093 Model Time: 0.056 Data Time: 0.604 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 29.0 | [2560/8000 (32%)]	Loss: 5.180263                         LR: 0.0000  Feat: 104.314 Epoch Time: 23.588 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 29.0 | [5120/8000 (65%)]	Loss: 5.234372                         LR: 0.0000  Feat: 104.450 Epoch Time: 25.084 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 29.0 | [7680/8000 (97%)]	Loss: 5.189197                         LR: 0.0000  Feat: 104.305 Epoch Time: 26.579 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  2.6999999999999996e-05
Find_phi_psi for agent:  3
Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 25.0 | [0/8000 (0%)]	Loss: 5.152516                         LR: 0.0000  Feat: 87.203 Epoch Time: 0.792 Model Time: 0.055 Data Time: 0.641 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 25.0 | [2560/8000 (32%)]	Loss: 5.130229                         LR: 0.0000  Feat: 87.176 Epoch Time: 2.286 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 25.0 | [5120/8000 (65%)]	Loss: 5.165241                         LR: 0.0000  Feat: 87.213 Epoch Time: 3.782 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 25.0 | [7680/8000 (97%)]	Loss: 5.157732                         LR: 0.0000  Feat: 87.256 Epoch Time: 5.277 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 26.0 | [0/8000 (0%)]	Loss: 5.154127                         LR: 0.0000  Feat: 87.349 Epoch Time: 6.091 Model Time: 0.055 Data Time: 0.618 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 26.0 | [2560/8000 (32%)]	Loss: 5.149363                         LR: 0.0000  Feat: 87.261 Epoch Time: 7.588 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 26.0 | [5120/8000 (65%)]	Loss: 5.126456                         LR: 0.0000  Feat: 87.147 Epoch Time: 9.084 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 26.0 | [7680/8000 (97%)]	Loss: 5.215369                         LR: 0.0000  Feat: 87.143 Epoch Time: 10.581 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 27.0 | [0/8000 (0%)]	Loss: 5.202378                         LR: 0.0000  Feat: 87.130 Epoch Time: 11.391 Model Time: 0.054 Data Time: 0.617 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 27.0 | [2560/8000 (32%)]	Loss: 5.184257                         LR: 0.0000  Feat: 87.263 Epoch Time: 12.889 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 27.0 | [5120/8000 (65%)]	Loss: 5.218013                         LR: 0.0000  Feat: 87.095 Epoch Time: 14.385 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 27.0 | [7680/8000 (97%)]	Loss: 5.146389                         LR: 0.0000  Feat: 87.346 Epoch Time: 15.880 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 28.0 | [0/8000 (0%)]	Loss: 5.153872                         LR: 0.0000  Feat: 87.087 Epoch Time: 16.702 Model Time: 0.054 Data Time: 0.631 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 28.0 | [2560/8000 (32%)]	Loss: 5.134218                         LR: 0.0000  Feat: 87.308 Epoch Time: 18.198 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 28.0 | [5120/8000 (65%)]	Loss: 5.203723                         LR: 0.0000  Feat: 87.229 Epoch Time: 19.692 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 28.0 | [7680/8000 (97%)]	Loss: 5.150641                         LR: 0.0000  Feat: 87.181 Epoch Time: 21.188 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 29.0 | [0/8000 (0%)]	Loss: 5.184325                         LR: 0.0000  Feat: 87.198 Epoch Time: 22.000 Model Time: 0.054 Data Time: 0.621 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 29.0 | [2560/8000 (32%)]	Loss: 5.189537                         LR: 0.0000  Feat: 87.382 Epoch Time: 23.495 Model Time: 0.051 Data Time: 0.098 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 29.0 | [5120/8000 (65%)]	Loss: 5.194167                         LR: 0.0000  Feat: 87.526 Epoch Time: 24.989 Model Time: 0.051 Data Time: 0.099 Model: 05-18_17:09_4152430
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 29.0 | [7680/8000 (97%)]	Loss: 5.169402                         LR: 0.0000  Feat: 87.034 Epoch Time: 26.485 Model Time: 0.052 Data Time: 0.098 Model: 05-18_17:09_4152430
learning rate fed to local model:  2.6999999999999996e-05
Find_phi_psi for agent:  2
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
evaluating representations:  save/05-18_17:09_4152430iid_dec-True_ED-True_pe1.0_a5_e30_le5.0
Training a classifier on each of the local models and averaging the accuracy result
Start tarining Classifier for user 0
Training classifier
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 2.715
Use i.i.d. sampling
sample dataset time: 0.028
user data samples: [10000, 10000, 10000, 10000, 10000]
begin training classifier...
Downstream Train Epoch: 1 [0/50000 (0%)]	Loss: 168.385223
Downstream Train Epoch: 1 [12800/50000 (26%)]	Loss: 20.464836
Downstream Train Epoch: 1 [25600/50000 (51%)]	Loss: 20.608683
Downstream Train Epoch: 1 [38400/50000 (77%)]	Loss: 16.990963

 Downstream Train loss: 25.093319868554875 Acc: 0.2771
Downstream Train Epoch: 2 [0/50000 (0%)]	Loss: 16.173395
Downstream Train Epoch: 2 [12800/50000 (26%)]	Loss: 14.979500
Downstream Train Epoch: 2 [25600/50000 (51%)]	Loss: 12.105529
Downstream Train Epoch: 2 [38400/50000 (77%)]	Loss: 12.959966

 Downstream Train loss: 14.707806913220153 Acc: 0.3087
Downstream Train Epoch: 3 [0/50000 (0%)]	Loss: 17.183233
Downstream Train Epoch: 3 [12800/50000 (26%)]	Loss: 12.637899
Downstream Train Epoch: 3 [25600/50000 (51%)]	Loss: 16.198467
Downstream Train Epoch: 3 [38400/50000 (77%)]	Loss: 11.455495

 Downstream Train loss: 12.838268075670515 Acc: 0.3087
Downstream Train Epoch: 4 [0/50000 (0%)]	Loss: 11.729464
Downstream Train Epoch: 4 [12800/50000 (26%)]	Loss: 11.856623
Downstream Train Epoch: 4 [25600/50000 (51%)]	Loss: 11.204552
Downstream Train Epoch: 4 [38400/50000 (77%)]	Loss: 11.229392

 Downstream Train loss: 12.266456302331418 Acc: 0.3312
Downstream Train Epoch: 5 [0/50000 (0%)]	Loss: 11.632568
Downstream Train Epoch: 5 [12800/50000 (26%)]	Loss: 10.990086
Downstream Train Epoch: 5 [25600/50000 (51%)]	Loss: 9.717826
Downstream Train Epoch: 5 [38400/50000 (77%)]	Loss: 7.857328

 Downstream Train loss: 11.601986634488009 Acc: 0.3312
Downstream Train Epoch: 6 [0/50000 (0%)]	Loss: 13.983084
Downstream Train Epoch: 6 [12800/50000 (26%)]	Loss: 14.336806
Downstream Train Epoch: 6 [25600/50000 (51%)]	Loss: 8.936422
Downstream Train Epoch: 6 [38400/50000 (77%)]	Loss: 11.293801

 Downstream Train loss: 11.367057087470075 Acc: 0.3312
Downstream Train Epoch: 7 [0/50000 (0%)]	Loss: 13.803121
Downstream Train Epoch: 7 [12800/50000 (26%)]	Loss: 14.292637
Downstream Train Epoch: 7 [25600/50000 (51%)]	Loss: 9.247197
Downstream Train Epoch: 7 [38400/50000 (77%)]	Loss: 11.021678

 Downstream Train loss: 10.899292157620799 Acc: 0.3312
Downstream Train Epoch: 8 [0/50000 (0%)]	Loss: 10.540112
Downstream Train Epoch: 8 [12800/50000 (26%)]	Loss: 9.292410
Downstream Train Epoch: 8 [25600/50000 (51%)]	Loss: 10.550570
Downstream Train Epoch: 8 [38400/50000 (77%)]	Loss: 13.848096

 Downstream Train loss: 10.97734969975997 Acc: 0.3312
Downstream Train Epoch: 9 [0/50000 (0%)]	Loss: 17.034611
Downstream Train Epoch: 9 [12800/50000 (26%)]	Loss: 9.203806
Downstream Train Epoch: 9 [25600/50000 (51%)]	Loss: 12.364255
Downstream Train Epoch: 9 [38400/50000 (77%)]	Loss: 7.534376

 Downstream Train loss: 10.951573204021065 Acc: 0.344
Downstream Train Epoch: 10 [0/50000 (0%)]	Loss: 8.693053
Downstream Train Epoch: 10 [12800/50000 (26%)]	Loss: 8.559000
Downstream Train Epoch: 10 [25600/50000 (51%)]	Loss: 9.237864
Downstream Train Epoch: 10 [38400/50000 (77%)]	Loss: 10.259478

 Downstream Train loss: 10.820180034150882 Acc: 0.3569
Downstream Train Epoch: 11 [0/50000 (0%)]	Loss: 7.329155
Downstream Train Epoch: 11 [12800/50000 (26%)]	Loss: 9.782803
Downstream Train Epoch: 11 [25600/50000 (51%)]	Loss: 11.766296
Downstream Train Epoch: 11 [38400/50000 (77%)]	Loss: 13.115633

 Downstream Train loss: 9.782750265938896 Acc: 0.3569
Downstream Train Epoch: 12 [0/50000 (0%)]	Loss: 8.727789
Downstream Train Epoch: 12 [12800/50000 (26%)]	Loss: 9.222192
Downstream Train Epoch: 12 [25600/50000 (51%)]	Loss: 9.879353
Downstream Train Epoch: 12 [38400/50000 (77%)]	Loss: 9.077149

 Downstream Train loss: 9.98822927961544 Acc: 0.3754
Downstream Train Epoch: 13 [0/50000 (0%)]	Loss: 7.364984
Downstream Train Epoch: 13 [12800/50000 (26%)]	Loss: 11.658287
Downstream Train Epoch: 13 [25600/50000 (51%)]	Loss: 12.603772
Downstream Train Epoch: 13 [38400/50000 (77%)]	Loss: 8.272162

 Downstream Train loss: 10.359515267975477 Acc: 0.3754
Downstream Train Epoch: 14 [0/50000 (0%)]	Loss: 8.256109
Downstream Train Epoch: 14 [12800/50000 (26%)]	Loss: 8.101260
Downstream Train Epoch: 14 [25600/50000 (51%)]	Loss: 8.349623
Downstream Train Epoch: 14 [38400/50000 (77%)]	Loss: 9.152708

 Downstream Train loss: 9.439975504972496 Acc: 0.3754
Downstream Train Epoch: 15 [0/50000 (0%)]	Loss: 7.012332
Downstream Train Epoch: 15 [12800/50000 (26%)]	Loss: 7.048406
Downstream Train Epoch: 15 [25600/50000 (51%)]	Loss: 7.639285
Downstream Train Epoch: 15 [38400/50000 (77%)]	Loss: 8.346922

 Downstream Train loss: 10.33248748098101 Acc: 0.3754
Downstream Train Epoch: 16 [0/50000 (0%)]	Loss: 7.998565
Downstream Train Epoch: 16 [12800/50000 (26%)]	Loss: 9.893690
Downstream Train Epoch: 16 [25600/50000 (51%)]	Loss: 7.014268
Downstream Train Epoch: 16 [38400/50000 (77%)]	Loss: 9.523366

 Downstream Train loss: 9.807297640917252 Acc: 0.3754
Downstream Train Epoch: 17 [0/50000 (0%)]	Loss: 10.557343
Downstream Train Epoch: 17 [12800/50000 (26%)]	Loss: 7.296017
Downstream Train Epoch: 17 [25600/50000 (51%)]	Loss: 7.697486
Downstream Train Epoch: 17 [38400/50000 (77%)]	Loss: 8.170152

 Downstream Train loss: 8.90330230459875 Acc: 0.3754
Downstream Train Epoch: 18 [0/50000 (0%)]	Loss: 11.978683
Downstream Train Epoch: 18 [12800/50000 (26%)]	Loss: 10.868961
Downstream Train Epoch: 18 [25600/50000 (51%)]	Loss: 9.909479
Downstream Train Epoch: 18 [38400/50000 (77%)]	Loss: 11.615266

 Downstream Train loss: 9.713156580924988 Acc: 0.3754
Downstream Train Epoch: 19 [0/50000 (0%)]	Loss: 10.980728
Downstream Train Epoch: 19 [12800/50000 (26%)]	Loss: 8.385171
Downstream Train Epoch: 19 [25600/50000 (51%)]	Loss: 8.436241
Downstream Train Epoch: 19 [38400/50000 (77%)]	Loss: 8.649440

 Downstream Train loss: 10.250889924107765 Acc: 0.3754
Downstream Train Epoch: 20 [0/50000 (0%)]	Loss: 11.902049
Downstream Train Epoch: 20 [12800/50000 (26%)]	Loss: 7.943764
Downstream Train Epoch: 20 [25600/50000 (51%)]	Loss: 14.436090
Downstream Train Epoch: 20 [38400/50000 (77%)]	Loss: 8.659435

 Downstream Train loss: 10.253015464665939 Acc: 0.3754
Downstream Train Epoch: 21 [0/50000 (0%)]	Loss: 12.446447
Downstream Train Epoch: 21 [12800/50000 (26%)]	Loss: 6.794300
Downstream Train Epoch: 21 [25600/50000 (51%)]	Loss: 8.902293
Downstream Train Epoch: 21 [38400/50000 (77%)]	Loss: 8.088878

 Downstream Train loss: 9.274152266735934 Acc: 0.3754
Downstream Train Epoch: 22 [0/50000 (0%)]	Loss: 9.390200
Downstream Train Epoch: 22 [12800/50000 (26%)]	Loss: 6.669897
Downstream Train Epoch: 22 [25600/50000 (51%)]	Loss: 7.349594
Downstream Train Epoch: 22 [38400/50000 (77%)]	Loss: 10.763504

 Downstream Train loss: 11.064228186801989 Acc: 0.3754
Downstream Train Epoch: 23 [0/50000 (0%)]	Loss: 7.139940
Downstream Train Epoch: 23 [12800/50000 (26%)]	Loss: 9.907029
Downstream Train Epoch: 23 [25600/50000 (51%)]	Loss: 16.196196
Downstream Train Epoch: 23 [38400/50000 (77%)]	Loss: 7.276882

 Downstream Train loss: 9.268130964162399 Acc: 0.4116
Downstream Train Epoch: 24 [0/50000 (0%)]	Loss: 5.489132
Downstream Train Epoch: 24 [12800/50000 (26%)]	Loss: 7.376190
Downstream Train Epoch: 24 [25600/50000 (51%)]	Loss: 10.563978
Downstream Train Epoch: 24 [38400/50000 (77%)]	Loss: 9.981123

 Downstream Train loss: 9.150964425534617 Acc: 0.4116
Downstream Train Epoch: 25 [0/50000 (0%)]	Loss: 7.523756
Downstream Train Epoch: 25 [12800/50000 (26%)]	Loss: 9.800874
Downstream Train Epoch: 25 [25600/50000 (51%)]	Loss: 14.838479
Downstream Train Epoch: 25 [38400/50000 (77%)]	Loss: 6.902916

 Downstream Train loss: 9.679178274407679 Acc: 0.4116
Downstream Train Epoch: 26 [0/50000 (0%)]	Loss: 13.016127
Downstream Train Epoch: 26 [12800/50000 (26%)]	Loss: 8.250798
Downstream Train Epoch: 26 [25600/50000 (51%)]	Loss: 8.374511
Downstream Train Epoch: 26 [38400/50000 (77%)]	Loss: 10.967444

 Downstream Train loss: 9.256724892830363 Acc: 0.4116
Downstream Train Epoch: 27 [0/50000 (0%)]	Loss: 9.702722
Downstream Train Epoch: 27 [12800/50000 (26%)]	Loss: 8.320431
Downstream Train Epoch: 27 [25600/50000 (51%)]	Loss: 6.305084
Downstream Train Epoch: 27 [38400/50000 (77%)]	Loss: 6.483114

 Downstream Train loss: 9.253996182461174 Acc: 0.4116
Downstream Train Epoch: 28 [0/50000 (0%)]	Loss: 8.363049
Downstream Train Epoch: 28 [12800/50000 (26%)]	Loss: 6.346086
Downstream Train Epoch: 28 [25600/50000 (51%)]	Loss: 6.959661
Downstream Train Epoch: 28 [38400/50000 (77%)]	Loss: 8.355694

 Downstream Train loss: 9.43703694976106 Acc: 0.4116
Downstream Train Epoch: 29 [0/50000 (0%)]	Loss: 8.660769
Downstream Train Epoch: 29 [12800/50000 (26%)]	Loss: 7.560443
Downstream Train Epoch: 29 [25600/50000 (51%)]	Loss: 8.997180
Downstream Train Epoch: 29 [38400/50000 (77%)]	Loss: 10.696921

 Downstream Train loss: 9.323711903727784 Acc: 0.4116
Downstream Train Epoch: 30 [0/50000 (0%)]	Loss: 8.649896
Downstream Train Epoch: 30 [12800/50000 (26%)]	Loss: 9.964292
Downstream Train Epoch: 30 [25600/50000 (51%)]	Loss: 8.421546
Downstream Train Epoch: 30 [38400/50000 (77%)]	Loss: 7.997118

 Downstream Train loss: 9.005262883342041 Acc: 0.4116
Downstream Train Epoch: 31 [0/50000 (0%)]	Loss: 10.084876
Downstream Train Epoch: 31 [12800/50000 (26%)]	Loss: 8.785829
Downstream Train Epoch: 31 [25600/50000 (51%)]	Loss: 7.932772
Downstream Train Epoch: 31 [38400/50000 (77%)]	Loss: 8.504076

 Downstream Train loss: 9.019519725624395 Acc: 0.4116
Downstream Train Epoch: 32 [0/50000 (0%)]	Loss: 15.615146
Downstream Train Epoch: 32 [12800/50000 (26%)]	Loss: 7.475018
Downstream Train Epoch: 32 [25600/50000 (51%)]	Loss: 7.886492
Downstream Train Epoch: 32 [38400/50000 (77%)]	Loss: 10.164905

 Downstream Train loss: 9.202037212800006 Acc: 0.4116
Downstream Train Epoch: 33 [0/50000 (0%)]	Loss: 10.231513
Downstream Train Epoch: 33 [12800/50000 (26%)]	Loss: 8.639340
Downstream Train Epoch: 33 [25600/50000 (51%)]	Loss: 12.552809
Downstream Train Epoch: 33 [38400/50000 (77%)]	Loss: 7.154046

 Downstream Train loss: 10.211304238864354 Acc: 0.4116
Downstream Train Epoch: 34 [0/50000 (0%)]	Loss: 13.118521
Downstream Train Epoch: 34 [12800/50000 (26%)]	Loss: 9.839159
Downstream Train Epoch: 34 [25600/50000 (51%)]	Loss: 9.852533
Downstream Train Epoch: 34 [38400/50000 (77%)]	Loss: 7.505281

 Downstream Train loss: 10.110482495658252 Acc: 0.4116
Downstream Train Epoch: 35 [0/50000 (0%)]	Loss: 8.041296
Downstream Train Epoch: 35 [12800/50000 (26%)]	Loss: 11.657804
Downstream Train Epoch: 35 [25600/50000 (51%)]	Loss: 10.710686
Downstream Train Epoch: 35 [38400/50000 (77%)]	Loss: 9.738167

 Downstream Train loss: 9.210384278881307 Acc: 0.4116
Downstream Train Epoch: 36 [0/50000 (0%)]	Loss: 11.774947
Downstream Train Epoch: 36 [12800/50000 (26%)]	Loss: 12.081365
Downstream Train Epoch: 36 [25600/50000 (51%)]	Loss: 5.934781
Downstream Train Epoch: 36 [38400/50000 (77%)]	Loss: 10.592472

 Downstream Train loss: 8.698112169090582 Acc: 0.4116
Downstream Train Epoch: 37 [0/50000 (0%)]	Loss: 12.695390
Downstream Train Epoch: 37 [12800/50000 (26%)]	Loss: 9.980247
Downstream Train Epoch: 37 [25600/50000 (51%)]	Loss: 9.956996
Downstream Train Epoch: 37 [38400/50000 (77%)]	Loss: 10.363996

 Downstream Train loss: 10.171174852215515 Acc: 0.4116
Downstream Train Epoch: 38 [0/50000 (0%)]	Loss: 9.278363
Downstream Train Epoch: 38 [12800/50000 (26%)]	Loss: 6.717566
Downstream Train Epoch: 38 [25600/50000 (51%)]	Loss: 9.451461
Downstream Train Epoch: 38 [38400/50000 (77%)]	Loss: 10.094026

 Downstream Train loss: 9.174397845657504 Acc: 0.4116
Downstream Train Epoch: 39 [0/50000 (0%)]	Loss: 8.405616
Downstream Train Epoch: 39 [12800/50000 (26%)]	Loss: 12.403883
Downstream Train Epoch: 39 [25600/50000 (51%)]	Loss: 12.182368
Downstream Train Epoch: 39 [38400/50000 (77%)]	Loss: 12.083651

 Downstream Train loss: 9.956794225439733 Acc: 0.4116
Downstream Train Epoch: 40 [0/50000 (0%)]	Loss: 9.313074
Downstream Train Epoch: 40 [12800/50000 (26%)]	Loss: 9.315791
Downstream Train Epoch: 40 [25600/50000 (51%)]	Loss: 9.255971
Downstream Train Epoch: 40 [38400/50000 (77%)]	Loss: 11.838892

 Downstream Train loss: 9.777989229377436 Acc: 0.4116
Downstream Train Epoch: 41 [0/50000 (0%)]	Loss: 9.493155
Downstream Train Epoch: 41 [12800/50000 (26%)]	Loss: 10.957423
Downstream Train Epoch: 41 [25600/50000 (51%)]	Loss: 11.188409
Downstream Train Epoch: 41 [38400/50000 (77%)]	Loss: 10.387887

 Downstream Train loss: 9.832563439194036 Acc: 0.4116
Downstream Train Epoch: 42 [0/50000 (0%)]	Loss: 9.951952
Downstream Train Epoch: 42 [12800/50000 (26%)]	Loss: 6.438701
Downstream Train Epoch: 42 [25600/50000 (51%)]	Loss: 7.343990
Downstream Train Epoch: 42 [38400/50000 (77%)]	Loss: 8.456650

 Downstream Train loss: 9.270034099111752 Acc: 0.4116
Downstream Train Epoch: 43 [0/50000 (0%)]	Loss: 5.540011
Downstream Train Epoch: 43 [12800/50000 (26%)]	Loss: 6.331869
Downstream Train Epoch: 43 [25600/50000 (51%)]	Loss: 6.898794
Downstream Train Epoch: 43 [38400/50000 (77%)]	Loss: 8.981323

 Downstream Train loss: 8.965239201273237 Acc: 0.4116
Downstream Train Epoch: 44 [0/50000 (0%)]	Loss: 10.055977
Downstream Train Epoch: 44 [12800/50000 (26%)]	Loss: 10.182066
Downstream Train Epoch: 44 [25600/50000 (51%)]	Loss: 9.334805
Downstream Train Epoch: 44 [38400/50000 (77%)]	Loss: 10.061231

 Downstream Train loss: 9.133809184541507 Acc: 0.4116
Downstream Train Epoch: 45 [0/50000 (0%)]	Loss: 10.362634
Downstream Train Epoch: 45 [12800/50000 (26%)]	Loss: 6.818944
Downstream Train Epoch: 45 [25600/50000 (51%)]	Loss: 8.210467
Downstream Train Epoch: 45 [38400/50000 (77%)]	Loss: 9.080710

 Downstream Train loss: 9.234780661913813 Acc: 0.4116
Downstream Train Epoch: 46 [0/50000 (0%)]	Loss: 6.754179
Downstream Train Epoch: 46 [12800/50000 (26%)]	Loss: 8.983508
Downstream Train Epoch: 46 [25600/50000 (51%)]	Loss: 8.226476
Downstream Train Epoch: 46 [38400/50000 (77%)]	Loss: 11.771153

 Downstream Train loss: 10.605856785968859 Acc: 0.4116
Downstream Train Epoch: 47 [0/50000 (0%)]	Loss: 9.271347
Downstream Train Epoch: 47 [12800/50000 (26%)]	Loss: 5.682758
Downstream Train Epoch: 47 [25600/50000 (51%)]	Loss: 11.708393
Downstream Train Epoch: 47 [38400/50000 (77%)]	Loss: 4.408339

 Downstream Train loss: 8.599886395493332 Acc: 0.4116
Downstream Train Epoch: 48 [0/50000 (0%)]	Loss: 7.423724
Downstream Train Epoch: 48 [12800/50000 (26%)]	Loss: 11.974743
Downstream Train Epoch: 48 [25600/50000 (51%)]	Loss: 11.345400
Downstream Train Epoch: 48 [38400/50000 (77%)]	Loss: 8.786196

 Downstream Train loss: 10.076420611264755 Acc: 0.4116
Downstream Train Epoch: 49 [0/50000 (0%)]	Loss: 7.164795
Downstream Train Epoch: 49 [12800/50000 (26%)]	Loss: 9.994021
Downstream Train Epoch: 49 [25600/50000 (51%)]	Loss: 8.021732
Downstream Train Epoch: 49 [38400/50000 (77%)]	Loss: 9.237914

 Downstream Train loss: 8.33942122362098 Acc: 0.4116
Downstream Train Epoch: 50 [0/50000 (0%)]	Loss: 10.931720
Downstream Train Epoch: 50 [12800/50000 (26%)]	Loss: 6.967607
Downstream Train Epoch: 50 [25600/50000 (51%)]	Loss: 10.634489
Downstream Train Epoch: 50 [38400/50000 (77%)]	Loss: 14.033626

 Downstream Train loss: 9.41434077827298 Acc: 0.4116
Downstream Train Epoch: 51 [0/50000 (0%)]	Loss: 10.313944
Downstream Train Epoch: 51 [12800/50000 (26%)]	Loss: 14.619642
Downstream Train Epoch: 51 [25600/50000 (51%)]	Loss: 14.041702
Downstream Train Epoch: 51 [38400/50000 (77%)]	Loss: 7.781341

 Downstream Train loss: 9.39413160937173 Acc: 0.4116
Downstream Train Epoch: 52 [0/50000 (0%)]	Loss: 11.127314
Downstream Train Epoch: 52 [12800/50000 (26%)]	Loss: 6.318594
Downstream Train Epoch: 52 [25600/50000 (51%)]	Loss: 9.761343
Downstream Train Epoch: 52 [38400/50000 (77%)]	Loss: 9.024194

 Downstream Train loss: 9.242373130759415 Acc: 0.4116
Downstream Train Epoch: 53 [0/50000 (0%)]	Loss: 12.331999
Downstream Train Epoch: 53 [12800/50000 (26%)]	Loss: 5.528439
Downstream Train Epoch: 53 [25600/50000 (51%)]	Loss: 9.307536
Downstream Train Epoch: 53 [38400/50000 (77%)]	Loss: 10.422884

 Downstream Train loss: 9.339900593368375 Acc: 0.4116
Downstream Train Epoch: 54 [0/50000 (0%)]	Loss: 9.424208
Downstream Train Epoch: 54 [12800/50000 (26%)]	Loss: 4.983209
Downstream Train Epoch: 54 [25600/50000 (51%)]	Loss: 8.396507
Downstream Train Epoch: 54 [38400/50000 (77%)]	Loss: 10.087556

 Downstream Train loss: 9.057529785195175 Acc: 0.4116
Downstream Train Epoch: 55 [0/50000 (0%)]	Loss: 15.013684
Downstream Train Epoch: 55 [12800/50000 (26%)]	Loss: 6.084350
Downstream Train Epoch: 55 [25600/50000 (51%)]	Loss: 11.775866
Downstream Train Epoch: 55 [38400/50000 (77%)]	Loss: 7.413167

 Downstream Train loss: 9.900726481359833 Acc: 0.4116
Downstream Train Epoch: 56 [0/50000 (0%)]	Loss: 10.362261
Downstream Train Epoch: 56 [12800/50000 (26%)]	Loss: 10.521477
Downstream Train Epoch: 56 [25600/50000 (51%)]	Loss: 7.485771
Downstream Train Epoch: 56 [38400/50000 (77%)]	Loss: 7.189013

 Downstream Train loss: 9.861253336984284 Acc: 0.4116
Downstream Train Epoch: 57 [0/50000 (0%)]	Loss: 11.733021
Downstream Train Epoch: 57 [12800/50000 (26%)]	Loss: 9.494396
Downstream Train Epoch: 57 [25600/50000 (51%)]	Loss: 7.175675
Downstream Train Epoch: 57 [38400/50000 (77%)]	Loss: 8.978920

 Downstream Train loss: 9.401893754394687 Acc: 0.4116
Downstream Train Epoch: 58 [0/50000 (0%)]	Loss: 7.044044
Downstream Train Epoch: 58 [12800/50000 (26%)]	Loss: 6.203654
Downstream Train Epoch: 58 [25600/50000 (51%)]	Loss: 9.168375
Downstream Train Epoch: 58 [38400/50000 (77%)]	Loss: 7.446977

 Downstream Train loss: 8.787483964647565 Acc: 0.4116
Downstream Train Epoch: 59 [0/50000 (0%)]	Loss: 12.853183
Downstream Train Epoch: 59 [12800/50000 (26%)]	Loss: 10.060637
Downstream Train Epoch: 59 [25600/50000 (51%)]	Loss: 6.386499
Downstream Train Epoch: 59 [38400/50000 (77%)]	Loss: 13.876263

 Downstream Train loss: 9.454001343980128 Acc: 0.4116
Downstream Train Epoch: 60 [0/50000 (0%)]	Loss: 15.490198
Downstream Train Epoch: 60 [12800/50000 (26%)]	Loss: 5.963170
Downstream Train Epoch: 60 [25600/50000 (51%)]	Loss: 9.635579
Downstream Train Epoch: 60 [38400/50000 (77%)]	Loss: 11.650688

 Downstream Train loss: 9.697087404679278 Acc: 0.4116
Classifier Accuracy for user 0 is 0.4116
Start tarining Classifier for user 1
Training classifier
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 3.425
Use i.i.d. sampling
sample dataset time: 0.027
user data samples: [10000, 10000, 10000, 10000, 10000]
begin training classifier...
Downstream Train Epoch: 1 [0/50000 (0%)]	Loss: 216.724045
Downstream Train Epoch: 1 [12800/50000 (26%)]	Loss: 26.994486
Downstream Train Epoch: 1 [25600/50000 (51%)]	Loss: 22.257854
Downstream Train Epoch: 1 [38400/50000 (77%)]	Loss: 19.637888

 Downstream Train loss: 30.48810237767745 Acc: 0.3064
Downstream Train Epoch: 2 [0/50000 (0%)]	Loss: 23.216536
Downstream Train Epoch: 2 [12800/50000 (26%)]	Loss: 17.543728
Downstream Train Epoch: 2 [25600/50000 (51%)]	Loss: 17.318987
Downstream Train Epoch: 2 [38400/50000 (77%)]	Loss: 16.457848

 Downstream Train loss: 18.068219939056707 Acc: 0.3259
Downstream Train Epoch: 3 [0/50000 (0%)]	Loss: 16.250212
Downstream Train Epoch: 3 [12800/50000 (26%)]	Loss: 14.393498
Downstream Train Epoch: 3 [25600/50000 (51%)]	Loss: 16.594683
Downstream Train Epoch: 3 [38400/50000 (77%)]	Loss: 14.218985

 Downstream Train loss: 15.773703594597018 Acc: 0.3259
Downstream Train Epoch: 4 [0/50000 (0%)]	Loss: 16.515049
Downstream Train Epoch: 4 [12800/50000 (26%)]	Loss: 14.676173
Downstream Train Epoch: 4 [25600/50000 (51%)]	Loss: 11.738585
Downstream Train Epoch: 4 [38400/50000 (77%)]	Loss: 12.751860

 Downstream Train loss: 15.600594457314939 Acc: 0.3453
Downstream Train Epoch: 5 [0/50000 (0%)]	Loss: 13.730336
Downstream Train Epoch: 5 [12800/50000 (26%)]	Loss: 12.597798
Downstream Train Epoch: 5 [25600/50000 (51%)]	Loss: 13.361191
Downstream Train Epoch: 5 [38400/50000 (77%)]	Loss: 11.352224

 Downstream Train loss: 13.41471758180735 Acc: 0.3453
Downstream Train Epoch: 6 [0/50000 (0%)]	Loss: 15.292244
Downstream Train Epoch: 6 [12800/50000 (26%)]	Loss: 14.054354
Downstream Train Epoch: 6 [25600/50000 (51%)]	Loss: 11.647737
Downstream Train Epoch: 6 [38400/50000 (77%)]	Loss: 10.952437

 Downstream Train loss: 12.855245030656153 Acc: 0.3453
Downstream Train Epoch: 7 [0/50000 (0%)]	Loss: 14.238859
Downstream Train Epoch: 7 [12800/50000 (26%)]	Loss: 12.630964
Downstream Train Epoch: 7 [25600/50000 (51%)]	Loss: 15.120657
Downstream Train Epoch: 7 [38400/50000 (77%)]	Loss: 15.518289

 Downstream Train loss: 13.048574627662191 Acc: 0.3453
Downstream Train Epoch: 8 [0/50000 (0%)]	Loss: 17.208324
Downstream Train Epoch: 8 [12800/50000 (26%)]	Loss: 10.579220
Downstream Train Epoch: 8 [25600/50000 (51%)]	Loss: 18.710052
Downstream Train Epoch: 8 [38400/50000 (77%)]	Loss: 11.656519

 Downstream Train loss: 13.75073311280231 Acc: 0.3803
Downstream Train Epoch: 9 [0/50000 (0%)]	Loss: 10.282809
Downstream Train Epoch: 9 [12800/50000 (26%)]	Loss: 11.148510
Downstream Train Epoch: 9 [25600/50000 (51%)]	Loss: 13.360848
Downstream Train Epoch: 9 [38400/50000 (77%)]	Loss: 15.674153

 Downstream Train loss: 13.49197844583161 Acc: 0.3803
Downstream Train Epoch: 10 [0/50000 (0%)]	Loss: 15.748371
Downstream Train Epoch: 10 [12800/50000 (26%)]	Loss: 18.412079
Downstream Train Epoch: 10 [25600/50000 (51%)]	Loss: 13.341343
Downstream Train Epoch: 10 [38400/50000 (77%)]	Loss: 11.134648

 Downstream Train loss: 12.844589783220876 Acc: 0.3803
Downstream Train Epoch: 11 [0/50000 (0%)]	Loss: 13.291248
Downstream Train Epoch: 11 [12800/50000 (26%)]	Loss: 13.029310
Downstream Train Epoch: 11 [25600/50000 (51%)]	Loss: 13.770610
Downstream Train Epoch: 11 [38400/50000 (77%)]	Loss: 11.997127

 Downstream Train loss: 12.80856164620847 Acc: 0.3803
Downstream Train Epoch: 12 [0/50000 (0%)]	Loss: 11.043600
Downstream Train Epoch: 12 [12800/50000 (26%)]	Loss: 11.928169
Downstream Train Epoch: 12 [25600/50000 (51%)]	Loss: 10.359972
Downstream Train Epoch: 12 [38400/50000 (77%)]	Loss: 11.914217

 Downstream Train loss: 11.455836498007482 Acc: 0.3803
Downstream Train Epoch: 13 [0/50000 (0%)]	Loss: 11.280042
Downstream Train Epoch: 13 [12800/50000 (26%)]	Loss: 15.018750
Downstream Train Epoch: 13 [25600/50000 (51%)]	Loss: 9.971615
Downstream Train Epoch: 13 [38400/50000 (77%)]	Loss: 12.044818

 Downstream Train loss: 12.523624568569417 Acc: 0.3821
Downstream Train Epoch: 14 [0/50000 (0%)]	Loss: 9.880234
Downstream Train Epoch: 14 [12800/50000 (26%)]	Loss: 12.073769
Downstream Train Epoch: 14 [25600/50000 (51%)]	Loss: 11.790333
Downstream Train Epoch: 14 [38400/50000 (77%)]	Loss: 14.432335

 Downstream Train loss: 12.41066943139446 Acc: 0.3821
Downstream Train Epoch: 15 [0/50000 (0%)]	Loss: 11.202826
Downstream Train Epoch: 15 [12800/50000 (26%)]	Loss: 14.689103
Downstream Train Epoch: 15 [25600/50000 (51%)]	Loss: 11.612837
Downstream Train Epoch: 15 [38400/50000 (77%)]	Loss: 12.133371

 Downstream Train loss: 12.670222029394033 Acc: 0.3821
Downstream Train Epoch: 16 [0/50000 (0%)]	Loss: 10.953226
Downstream Train Epoch: 16 [12800/50000 (26%)]	Loss: 10.950955
Downstream Train Epoch: 16 [25600/50000 (51%)]	Loss: 18.434902
Downstream Train Epoch: 16 [38400/50000 (77%)]	Loss: 10.013976

 Downstream Train loss: 12.495264807525945 Acc: 0.3821
Downstream Train Epoch: 17 [0/50000 (0%)]	Loss: 10.392902
Downstream Train Epoch: 17 [12800/50000 (26%)]	Loss: 9.961444
Downstream Train Epoch: 17 [25600/50000 (51%)]	Loss: 11.015744
Downstream Train Epoch: 17 [38400/50000 (77%)]	Loss: 14.247393

 Downstream Train loss: 12.282896438423467 Acc: 0.3821
Downstream Train Epoch: 18 [0/50000 (0%)]	Loss: 10.294510
Downstream Train Epoch: 18 [12800/50000 (26%)]	Loss: 10.166155
Downstream Train Epoch: 18 [25600/50000 (51%)]	Loss: 9.080767
Downstream Train Epoch: 18 [38400/50000 (77%)]	Loss: 9.605000

 Downstream Train loss: 11.461483875099493 Acc: 0.3821
Downstream Train Epoch: 19 [0/50000 (0%)]	Loss: 11.788950
Downstream Train Epoch: 19 [12800/50000 (26%)]	Loss: 9.210124
Downstream Train Epoch: 19 [25600/50000 (51%)]	Loss: 20.691017
Downstream Train Epoch: 19 [38400/50000 (77%)]	Loss: 11.780644

 Downstream Train loss: 12.85706226193175 Acc: 0.3821
Downstream Train Epoch: 20 [0/50000 (0%)]	Loss: 17.232689
Downstream Train Epoch: 20 [12800/50000 (26%)]	Loss: 8.484475
Downstream Train Epoch: 20 [25600/50000 (51%)]	Loss: 13.769727
Downstream Train Epoch: 20 [38400/50000 (77%)]	Loss: 10.252435

 Downstream Train loss: 11.279824140120526 Acc: 0.3821
Downstream Train Epoch: 21 [0/50000 (0%)]	Loss: 21.962206
Downstream Train Epoch: 21 [12800/50000 (26%)]	Loss: 17.904222
Downstream Train Epoch: 21 [25600/50000 (51%)]	Loss: 7.904572
Downstream Train Epoch: 21 [38400/50000 (77%)]	Loss: 9.635150

 Downstream Train loss: 12.028819624258547 Acc: 0.3821
Downstream Train Epoch: 22 [0/50000 (0%)]	Loss: 14.022168
Downstream Train Epoch: 22 [12800/50000 (26%)]	Loss: 10.794759
Downstream Train Epoch: 22 [25600/50000 (51%)]	Loss: 10.389752
Downstream Train Epoch: 22 [38400/50000 (77%)]	Loss: 9.789482

 Downstream Train loss: 10.35565808597876 Acc: 0.3824
Downstream Train Epoch: 23 [0/50000 (0%)]	Loss: 10.337060
Downstream Train Epoch: 23 [12800/50000 (26%)]	Loss: 11.880745
Downstream Train Epoch: 23 [25600/50000 (51%)]	Loss: 10.758737
Downstream Train Epoch: 23 [38400/50000 (77%)]	Loss: 13.257373

 Downstream Train loss: 11.112243591522684 Acc: 0.3824
Downstream Train Epoch: 24 [0/50000 (0%)]	Loss: 10.766058
Downstream Train Epoch: 24 [12800/50000 (26%)]	Loss: 8.636537
Downstream Train Epoch: 24 [25600/50000 (51%)]	Loss: 9.908230
Downstream Train Epoch: 24 [38400/50000 (77%)]	Loss: 8.384576

 Downstream Train loss: 11.717780748192144 Acc: 0.3867
Downstream Train Epoch: 25 [0/50000 (0%)]	Loss: 9.824887
Downstream Train Epoch: 25 [12800/50000 (26%)]	Loss: 14.468710
Downstream Train Epoch: 25 [25600/50000 (51%)]	Loss: 11.075283
Downstream Train Epoch: 25 [38400/50000 (77%)]	Loss: 8.475085

 Downstream Train loss: 12.48529971132473 Acc: 0.3867
Downstream Train Epoch: 26 [0/50000 (0%)]	Loss: 11.875821
Downstream Train Epoch: 26 [12800/50000 (26%)]	Loss: 14.398099
Downstream Train Epoch: 26 [25600/50000 (51%)]	Loss: 12.694479
Downstream Train Epoch: 26 [38400/50000 (77%)]	Loss: 8.261107

 Downstream Train loss: 12.447231876606844 Acc: 0.3867
Downstream Train Epoch: 27 [0/50000 (0%)]	Loss: 16.979578
Downstream Train Epoch: 27 [12800/50000 (26%)]	Loss: 10.739530
Downstream Train Epoch: 27 [25600/50000 (51%)]	Loss: 11.402301
Downstream Train Epoch: 27 [38400/50000 (77%)]	Loss: 10.486507

 Downstream Train loss: 12.2758862315392 Acc: 0.3944
Downstream Train Epoch: 28 [0/50000 (0%)]	Loss: 11.313616
Downstream Train Epoch: 28 [12800/50000 (26%)]	Loss: 16.096830
Downstream Train Epoch: 28 [25600/50000 (51%)]	Loss: 9.083369
Downstream Train Epoch: 28 [38400/50000 (77%)]	Loss: 10.220450

 Downstream Train loss: 10.652070597726471 Acc: 0.3944
Downstream Train Epoch: 29 [0/50000 (0%)]	Loss: 11.318809
Downstream Train Epoch: 29 [12800/50000 (26%)]	Loss: 17.785482
Downstream Train Epoch: 29 [25600/50000 (51%)]	Loss: 12.270902
Downstream Train Epoch: 29 [38400/50000 (77%)]	Loss: 9.121078

 Downstream Train loss: 12.431715323000539 Acc: 0.3944
Downstream Train Epoch: 30 [0/50000 (0%)]	Loss: 9.256769
Downstream Train Epoch: 30 [12800/50000 (26%)]	Loss: 8.882810
Downstream Train Epoch: 30 [25600/50000 (51%)]	Loss: 15.224415
Downstream Train Epoch: 30 [38400/50000 (77%)]	Loss: 7.608656

 Downstream Train loss: 11.943224722025345 Acc: 0.3959
Downstream Train Epoch: 31 [0/50000 (0%)]	Loss: 9.060186
Downstream Train Epoch: 31 [12800/50000 (26%)]	Loss: 6.571551
Downstream Train Epoch: 31 [25600/50000 (51%)]	Loss: 9.029585
Downstream Train Epoch: 31 [38400/50000 (77%)]	Loss: 11.357243

 Downstream Train loss: 10.341001065409912 Acc: 0.3959
Downstream Train Epoch: 32 [0/50000 (0%)]	Loss: 10.151125
Downstream Train Epoch: 32 [12800/50000 (26%)]	Loss: 13.814487
Downstream Train Epoch: 32 [25600/50000 (51%)]	Loss: 11.101845
Downstream Train Epoch: 32 [38400/50000 (77%)]	Loss: 23.605646

 Downstream Train loss: 11.74210333094305 Acc: 0.3959
Downstream Train Epoch: 33 [0/50000 (0%)]	Loss: 16.987747
Downstream Train Epoch: 33 [12800/50000 (26%)]	Loss: 7.498463
Downstream Train Epoch: 33 [25600/50000 (51%)]	Loss: 8.921193
Downstream Train Epoch: 33 [38400/50000 (77%)]	Loss: 10.815986

 Downstream Train loss: 11.925407669982132 Acc: 0.3959
Downstream Train Epoch: 34 [0/50000 (0%)]	Loss: 16.029154
Downstream Train Epoch: 34 [12800/50000 (26%)]	Loss: 12.177874
Downstream Train Epoch: 34 [25600/50000 (51%)]	Loss: 10.355789
Downstream Train Epoch: 34 [38400/50000 (77%)]	Loss: 12.796142

 Downstream Train loss: 10.559580272557785 Acc: 0.3959
Downstream Train Epoch: 35 [0/50000 (0%)]	Loss: 7.735122
Downstream Train Epoch: 35 [12800/50000 (26%)]	Loss: 9.935627
Downstream Train Epoch: 35 [25600/50000 (51%)]	Loss: 12.667530
Downstream Train Epoch: 35 [38400/50000 (77%)]	Loss: 9.404740

 Downstream Train loss: 11.059046188179327 Acc: 0.3959
Downstream Train Epoch: 36 [0/50000 (0%)]	Loss: 9.927077
Downstream Train Epoch: 36 [12800/50000 (26%)]	Loss: 11.923612
Downstream Train Epoch: 36 [25600/50000 (51%)]	Loss: 9.156994
Downstream Train Epoch: 36 [38400/50000 (77%)]	Loss: 10.829610

 Downstream Train loss: 11.665730863201375 Acc: 0.3959
Downstream Train Epoch: 37 [0/50000 (0%)]	Loss: 10.232094
Downstream Train Epoch: 37 [12800/50000 (26%)]	Loss: 10.358157
Downstream Train Epoch: 37 [25600/50000 (51%)]	Loss: 20.121029
Downstream Train Epoch: 37 [38400/50000 (77%)]	Loss: 7.741877

 Downstream Train loss: 10.878068865561971 Acc: 0.3959
Downstream Train Epoch: 38 [0/50000 (0%)]	Loss: 9.867475
Downstream Train Epoch: 38 [12800/50000 (26%)]	Loss: 16.331749
Downstream Train Epoch: 38 [25600/50000 (51%)]	Loss: 8.649120
Downstream Train Epoch: 38 [38400/50000 (77%)]	Loss: 14.259397

 Downstream Train loss: 12.1584361694297 Acc: 0.3959
Downstream Train Epoch: 39 [0/50000 (0%)]	Loss: 8.039090
Downstream Train Epoch: 39 [12800/50000 (26%)]	Loss: 9.957499
Downstream Train Epoch: 39 [25600/50000 (51%)]	Loss: 8.204252
Downstream Train Epoch: 39 [38400/50000 (77%)]	Loss: 17.160299

 Downstream Train loss: 10.922678317342486 Acc: 0.3959
Downstream Train Epoch: 40 [0/50000 (0%)]	Loss: 10.281466
Downstream Train Epoch: 40 [12800/50000 (26%)]	Loss: 15.364841
Downstream Train Epoch: 40 [25600/50000 (51%)]	Loss: 19.380089
Downstream Train Epoch: 40 [38400/50000 (77%)]	Loss: 10.840176

 Downstream Train loss: 12.077363885178858 Acc: 0.3959
Downstream Train Epoch: 41 [0/50000 (0%)]	Loss: 12.280454
Downstream Train Epoch: 41 [12800/50000 (26%)]	Loss: 7.701463
Downstream Train Epoch: 41 [25600/50000 (51%)]	Loss: 13.041691
Downstream Train Epoch: 41 [38400/50000 (77%)]	Loss: 12.009267

 Downstream Train loss: 10.563949533871241 Acc: 0.3959
Downstream Train Epoch: 42 [0/50000 (0%)]	Loss: 11.733395
Downstream Train Epoch: 42 [12800/50000 (26%)]	Loss: 11.897321
Downstream Train Epoch: 42 [25600/50000 (51%)]	Loss: 14.693732
Downstream Train Epoch: 42 [38400/50000 (77%)]	Loss: 10.681526

 Downstream Train loss: 11.509386400787198 Acc: 0.3959
Downstream Train Epoch: 43 [0/50000 (0%)]	Loss: 11.529313
Downstream Train Epoch: 43 [12800/50000 (26%)]	Loss: 20.152176
Downstream Train Epoch: 43 [25600/50000 (51%)]	Loss: 9.738199
Downstream Train Epoch: 43 [38400/50000 (77%)]	Loss: 15.763069

 Downstream Train loss: 11.771953580330829 Acc: 0.3959
Downstream Train Epoch: 44 [0/50000 (0%)]	Loss: 14.621266
Downstream Train Epoch: 44 [12800/50000 (26%)]	Loss: 7.508628
Downstream Train Epoch: 44 [25600/50000 (51%)]	Loss: 8.669331
Downstream Train Epoch: 44 [38400/50000 (77%)]	Loss: 11.498527

 Downstream Train loss: 10.609586810579104 Acc: 0.3959
Downstream Train Epoch: 45 [0/50000 (0%)]	Loss: 9.736012
Downstream Train Epoch: 45 [12800/50000 (26%)]	Loss: 12.901073
Downstream Train Epoch: 45 [25600/50000 (51%)]	Loss: 7.119604
Downstream Train Epoch: 45 [38400/50000 (77%)]	Loss: 32.420517

 Downstream Train loss: 12.12096101410535 Acc: 0.3959
Downstream Train Epoch: 46 [0/50000 (0%)]	Loss: 15.759236
Downstream Train Epoch: 46 [12800/50000 (26%)]	Loss: 14.490122
Downstream Train Epoch: 46 [25600/50000 (51%)]	Loss: 13.287607
Downstream Train Epoch: 46 [38400/50000 (77%)]	Loss: 8.677575

 Downstream Train loss: 11.55955120008819 Acc: 0.3959
Downstream Train Epoch: 47 [0/50000 (0%)]	Loss: 12.322579
Downstream Train Epoch: 47 [12800/50000 (26%)]	Loss: 17.851336
Downstream Train Epoch: 47 [25600/50000 (51%)]	Loss: 9.766837
Downstream Train Epoch: 47 [38400/50000 (77%)]	Loss: 10.359199

 Downstream Train loss: 12.063131974667918 Acc: 0.3959
Downstream Train Epoch: 48 [0/50000 (0%)]	Loss: 13.744170
Downstream Train Epoch: 48 [12800/50000 (26%)]	Loss: 9.400579
Downstream Train Epoch: 48 [25600/50000 (51%)]	Loss: 7.574741
Downstream Train Epoch: 48 [38400/50000 (77%)]	Loss: 13.916062

 Downstream Train loss: 11.788288152947718 Acc: 0.3959
Downstream Train Epoch: 49 [0/50000 (0%)]	Loss: 11.938646
Downstream Train Epoch: 49 [12800/50000 (26%)]	Loss: 10.847041
Downstream Train Epoch: 49 [25600/50000 (51%)]	Loss: 7.402082
Downstream Train Epoch: 49 [38400/50000 (77%)]	Loss: 7.154956

 Downstream Train loss: 10.562985062599182 Acc: 0.4097
Downstream Train Epoch: 50 [0/50000 (0%)]	Loss: 10.155721
Downstream Train Epoch: 50 [12800/50000 (26%)]	Loss: 14.834992
Downstream Train Epoch: 50 [25600/50000 (51%)]	Loss: 11.130277
Downstream Train Epoch: 50 [38400/50000 (77%)]	Loss: 9.489604

 Downstream Train loss: 12.579657574089206 Acc: 0.4097
Downstream Train Epoch: 51 [0/50000 (0%)]	Loss: 10.224438
Downstream Train Epoch: 51 [12800/50000 (26%)]	Loss: 14.209207
Downstream Train Epoch: 51 [25600/50000 (51%)]	Loss: 11.469959
Downstream Train Epoch: 51 [38400/50000 (77%)]	Loss: 8.980675

 Downstream Train loss: 10.364050074499481 Acc: 0.4097
Downstream Train Epoch: 52 [0/50000 (0%)]	Loss: 9.753405
Downstream Train Epoch: 52 [12800/50000 (26%)]	Loss: 13.926819
Downstream Train Epoch: 52 [25600/50000 (51%)]	Loss: 13.147717
Downstream Train Epoch: 52 [38400/50000 (77%)]	Loss: 14.498103

 Downstream Train loss: 12.090790816715785 Acc: 0.4097
Downstream Train Epoch: 53 [0/50000 (0%)]	Loss: 15.170504
Downstream Train Epoch: 53 [12800/50000 (26%)]	Loss: 12.057181
Downstream Train Epoch: 53 [25600/50000 (51%)]	Loss: 17.068697
Downstream Train Epoch: 53 [38400/50000 (77%)]	Loss: 9.442603

 Downstream Train loss: 11.2961142184783 Acc: 0.4097
Downstream Train Epoch: 54 [0/50000 (0%)]	Loss: 9.616618
Downstream Train Epoch: 54 [12800/50000 (26%)]	Loss: 10.978752
Downstream Train Epoch: 54 [25600/50000 (51%)]	Loss: 10.560735
Downstream Train Epoch: 54 [38400/50000 (77%)]	Loss: 10.980755

 Downstream Train loss: 10.853750805465543 Acc: 0.4097
Downstream Train Epoch: 55 [0/50000 (0%)]	Loss: 20.098217
Downstream Train Epoch: 55 [12800/50000 (26%)]	Loss: 20.817387
Downstream Train Epoch: 55 [25600/50000 (51%)]	Loss: 9.293915
Downstream Train Epoch: 55 [38400/50000 (77%)]	Loss: 9.666507

 Downstream Train loss: 12.771931441462769 Acc: 0.4097
Downstream Train Epoch: 56 [0/50000 (0%)]	Loss: 9.061337
Downstream Train Epoch: 56 [12800/50000 (26%)]	Loss: 12.922750
Downstream Train Epoch: 56 [25600/50000 (51%)]	Loss: 9.323149
Downstream Train Epoch: 56 [38400/50000 (77%)]	Loss: 9.261567

 Downstream Train loss: 11.012398632205262 Acc: 0.4097
Downstream Train Epoch: 57 [0/50000 (0%)]	Loss: 16.582129
Downstream Train Epoch: 57 [12800/50000 (26%)]	Loss: 10.577523
Downstream Train Epoch: 57 [25600/50000 (51%)]	Loss: 13.067256
Downstream Train Epoch: 57 [38400/50000 (77%)]	Loss: 9.617883

 Downstream Train loss: 11.398299375358892 Acc: 0.4097
Downstream Train Epoch: 58 [0/50000 (0%)]	Loss: 16.611006
Downstream Train Epoch: 58 [12800/50000 (26%)]	Loss: 6.589657
Downstream Train Epoch: 58 [25600/50000 (51%)]	Loss: 12.776341
Downstream Train Epoch: 58 [38400/50000 (77%)]	Loss: 12.284751

 Downstream Train loss: 10.296178635285825 Acc: 0.4097
Downstream Train Epoch: 59 [0/50000 (0%)]	Loss: 8.315371
Downstream Train Epoch: 59 [12800/50000 (26%)]	Loss: 9.972213
Downstream Train Epoch: 59 [25600/50000 (51%)]	Loss: 15.830943
Downstream Train Epoch: 59 [38400/50000 (77%)]	Loss: 16.009382

 Downstream Train loss: 12.461354026989062 Acc: 0.4097
Downstream Train Epoch: 60 [0/50000 (0%)]	Loss: 24.726040
Downstream Train Epoch: 60 [12800/50000 (26%)]	Loss: 11.445570
Downstream Train Epoch: 60 [25600/50000 (51%)]	Loss: 11.658250
Downstream Train Epoch: 60 [38400/50000 (77%)]	Loss: 13.542630

 Downstream Train loss: 11.292337974723505 Acc: 0.4097
Classifier Accuracy for user 1 is 0.4097
Start tarining Classifier for user 2
Training classifier
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 3.658
Use i.i.d. sampling
sample dataset time: 0.028
user data samples: [10000, 10000, 10000, 10000, 10000]
begin training classifier...
Downstream Train Epoch: 1 [0/50000 (0%)]	Loss: 246.489410
Downstream Train Epoch: 1 [12800/50000 (26%)]	Loss: 33.485714
Downstream Train Epoch: 1 [25600/50000 (51%)]	Loss: 24.232752
Downstream Train Epoch: 1 [38400/50000 (77%)]	Loss: 26.549398

 Downstream Train loss: 35.40357690927934 Acc: 0.2967
Downstream Train Epoch: 2 [0/50000 (0%)]	Loss: 23.886518
Downstream Train Epoch: 2 [12800/50000 (26%)]	Loss: 19.764763
Downstream Train Epoch: 2 [25600/50000 (51%)]	Loss: 16.389812
Downstream Train Epoch: 2 [38400/50000 (77%)]	Loss: 21.500328

 Downstream Train loss: 21.27398254433457 Acc: 0.2967
Downstream Train Epoch: 3 [0/50000 (0%)]	Loss: 23.713360
Downstream Train Epoch: 3 [12800/50000 (26%)]	Loss: 22.741163
Downstream Train Epoch: 3 [25600/50000 (51%)]	Loss: 17.822437
Downstream Train Epoch: 3 [38400/50000 (77%)]	Loss: 16.433882

 Downstream Train loss: 19.214319652440597 Acc: 0.2967
Downstream Train Epoch: 4 [0/50000 (0%)]	Loss: 18.392208
Downstream Train Epoch: 4 [12800/50000 (26%)]	Loss: 18.218370
Downstream Train Epoch: 4 [25600/50000 (51%)]	Loss: 16.343264
Downstream Train Epoch: 4 [38400/50000 (77%)]	Loss: 16.776175

 Downstream Train loss: 18.059369783012233 Acc: 0.3163
Downstream Train Epoch: 5 [0/50000 (0%)]	Loss: 21.761337
Downstream Train Epoch: 5 [12800/50000 (26%)]	Loss: 14.910373
Downstream Train Epoch: 5 [25600/50000 (51%)]	Loss: 16.796005
Downstream Train Epoch: 5 [38400/50000 (77%)]	Loss: 15.362020

 Downstream Train loss: 17.46557089260646 Acc: 0.3328
Downstream Train Epoch: 6 [0/50000 (0%)]	Loss: 16.811308
Downstream Train Epoch: 6 [12800/50000 (26%)]	Loss: 16.277773
Downstream Train Epoch: 6 [25600/50000 (51%)]	Loss: 13.437061
Downstream Train Epoch: 6 [38400/50000 (77%)]	Loss: 14.511194

 Downstream Train loss: 15.76462018733122 Acc: 0.3507
Downstream Train Epoch: 7 [0/50000 (0%)]	Loss: 16.916721
Downstream Train Epoch: 7 [12800/50000 (26%)]	Loss: 17.254440
Downstream Train Epoch: 7 [25600/50000 (51%)]	Loss: 14.559760
Downstream Train Epoch: 7 [38400/50000 (77%)]	Loss: 17.215387

 Downstream Train loss: 15.996383847022543 Acc: 0.3507
Downstream Train Epoch: 8 [0/50000 (0%)]	Loss: 19.173761
Downstream Train Epoch: 8 [12800/50000 (26%)]	Loss: 23.315115
Downstream Train Epoch: 8 [25600/50000 (51%)]	Loss: 14.815399
Downstream Train Epoch: 8 [38400/50000 (77%)]	Loss: 19.446100

 Downstream Train loss: 16.331259620432952 Acc: 0.3507
Downstream Train Epoch: 9 [0/50000 (0%)]	Loss: 16.501802
Downstream Train Epoch: 9 [12800/50000 (26%)]	Loss: 17.866415
Downstream Train Epoch: 9 [25600/50000 (51%)]	Loss: 16.323385
Downstream Train Epoch: 9 [38400/50000 (77%)]	Loss: 14.399665

 Downstream Train loss: 14.629051826438126 Acc: 0.3507
Downstream Train Epoch: 10 [0/50000 (0%)]	Loss: 23.452995
Downstream Train Epoch: 10 [12800/50000 (26%)]	Loss: 14.360109
Downstream Train Epoch: 10 [25600/50000 (51%)]	Loss: 15.478189
Downstream Train Epoch: 10 [38400/50000 (77%)]	Loss: 17.066536

 Downstream Train loss: 16.033837376808634 Acc: 0.3507
Downstream Train Epoch: 11 [0/50000 (0%)]	Loss: 14.089840
Downstream Train Epoch: 11 [12800/50000 (26%)]	Loss: 14.319392
Downstream Train Epoch: 11 [25600/50000 (51%)]	Loss: 16.151270
Downstream Train Epoch: 11 [38400/50000 (77%)]	Loss: 18.450327

 Downstream Train loss: 14.485533300711184 Acc: 0.3507
Downstream Train Epoch: 12 [0/50000 (0%)]	Loss: 14.602448
Downstream Train Epoch: 12 [12800/50000 (26%)]	Loss: 12.894228
Downstream Train Epoch: 12 [25600/50000 (51%)]	Loss: 13.858342
Downstream Train Epoch: 12 [38400/50000 (77%)]	Loss: 14.936063

 Downstream Train loss: 15.150528022221156 Acc: 0.3671
Downstream Train Epoch: 13 [0/50000 (0%)]	Loss: 17.632481
Downstream Train Epoch: 13 [12800/50000 (26%)]	Loss: 16.055721
Downstream Train Epoch: 13 [25600/50000 (51%)]	Loss: 12.942684
Downstream Train Epoch: 13 [38400/50000 (77%)]	Loss: 11.425392

 Downstream Train loss: 14.05188825665688 Acc: 0.3671
Downstream Train Epoch: 14 [0/50000 (0%)]	Loss: 12.431284
Downstream Train Epoch: 14 [12800/50000 (26%)]	Loss: 13.652419
Downstream Train Epoch: 14 [25600/50000 (51%)]	Loss: 15.703407
Downstream Train Epoch: 14 [38400/50000 (77%)]	Loss: 16.142807

 Downstream Train loss: 14.115196568625313 Acc: 0.3671
Downstream Train Epoch: 15 [0/50000 (0%)]	Loss: 21.002506
Downstream Train Epoch: 15 [12800/50000 (26%)]	Loss: 14.047761
Downstream Train Epoch: 15 [25600/50000 (51%)]	Loss: 18.087959
Downstream Train Epoch: 15 [38400/50000 (77%)]	Loss: 13.027755

 Downstream Train loss: 15.29923988361748 Acc: 0.3671
Downstream Train Epoch: 16 [0/50000 (0%)]	Loss: 12.053382
Downstream Train Epoch: 16 [12800/50000 (26%)]	Loss: 13.344599
Downstream Train Epoch: 16 [25600/50000 (51%)]	Loss: 13.616735
Downstream Train Epoch: 16 [38400/50000 (77%)]	Loss: 17.215405

 Downstream Train loss: 14.062902577069341 Acc: 0.3671
Downstream Train Epoch: 17 [0/50000 (0%)]	Loss: 11.077251
Downstream Train Epoch: 17 [12800/50000 (26%)]	Loss: 14.608875
Downstream Train Epoch: 17 [25600/50000 (51%)]	Loss: 17.915121
Downstream Train Epoch: 17 [38400/50000 (77%)]	Loss: 13.438460

 Downstream Train loss: 14.322656324931554 Acc: 0.3671
Downstream Train Epoch: 18 [0/50000 (0%)]	Loss: 14.038127
Downstream Train Epoch: 18 [12800/50000 (26%)]	Loss: 13.152811
Downstream Train Epoch: 18 [25600/50000 (51%)]	Loss: 13.733976
Downstream Train Epoch: 18 [38400/50000 (77%)]	Loss: 12.640180

 Downstream Train loss: 14.660086743685664 Acc: 0.3671
Downstream Train Epoch: 19 [0/50000 (0%)]	Loss: 10.485743
Downstream Train Epoch: 19 [12800/50000 (26%)]	Loss: 12.816529
Downstream Train Epoch: 19 [25600/50000 (51%)]	Loss: 12.055463
Downstream Train Epoch: 19 [38400/50000 (77%)]	Loss: 13.665998

 Downstream Train loss: 12.94772471700396 Acc: 0.3671
Downstream Train Epoch: 20 [0/50000 (0%)]	Loss: 11.257738
Downstream Train Epoch: 20 [12800/50000 (26%)]	Loss: 8.191224
Downstream Train Epoch: 20 [25600/50000 (51%)]	Loss: 21.944777
Downstream Train Epoch: 20 [38400/50000 (77%)]	Loss: 19.618225

 Downstream Train loss: 13.780714609185043 Acc: 0.3701
Downstream Train Epoch: 21 [0/50000 (0%)]	Loss: 12.060271
Downstream Train Epoch: 21 [12800/50000 (26%)]	Loss: 13.362140
Downstream Train Epoch: 21 [25600/50000 (51%)]	Loss: 13.379142
Downstream Train Epoch: 21 [38400/50000 (77%)]	Loss: 12.030262

 Downstream Train loss: 13.234104419241147 Acc: 0.3701
Downstream Train Epoch: 22 [0/50000 (0%)]	Loss: 14.190684
Downstream Train Epoch: 22 [12800/50000 (26%)]	Loss: 11.515386
Downstream Train Epoch: 22 [25600/50000 (51%)]	Loss: 10.672084
Downstream Train Epoch: 22 [38400/50000 (77%)]	Loss: 17.030787

 Downstream Train loss: 15.884676354272026 Acc: 0.3701
Downstream Train Epoch: 23 [0/50000 (0%)]	Loss: 13.746428
Downstream Train Epoch: 23 [12800/50000 (26%)]	Loss: 12.747190
Downstream Train Epoch: 23 [25600/50000 (51%)]	Loss: 11.396160
Downstream Train Epoch: 23 [38400/50000 (77%)]	Loss: 16.608532

 Downstream Train loss: 15.161047592455027 Acc: 0.3701
Downstream Train Epoch: 24 [0/50000 (0%)]	Loss: 9.240955
Downstream Train Epoch: 24 [12800/50000 (26%)]	Loss: 15.992239
Downstream Train Epoch: 24 [25600/50000 (51%)]	Loss: 13.966185
Downstream Train Epoch: 24 [38400/50000 (77%)]	Loss: 13.041252

 Downstream Train loss: 13.794694778870563 Acc: 0.3701
Downstream Train Epoch: 25 [0/50000 (0%)]	Loss: 13.896669
Downstream Train Epoch: 25 [12800/50000 (26%)]	Loss: 18.730719
Downstream Train Epoch: 25 [25600/50000 (51%)]	Loss: 9.035738
Downstream Train Epoch: 25 [38400/50000 (77%)]	Loss: 10.050338

 Downstream Train loss: 12.808899611842875 Acc: 0.3701
Downstream Train Epoch: 26 [0/50000 (0%)]	Loss: 18.230606
Downstream Train Epoch: 26 [12800/50000 (26%)]	Loss: 10.961232
Downstream Train Epoch: 26 [25600/50000 (51%)]	Loss: 14.302077
Downstream Train Epoch: 26 [38400/50000 (77%)]	Loss: 13.210566

 Downstream Train loss: 14.344445184785492 Acc: 0.3701
Downstream Train Epoch: 27 [0/50000 (0%)]	Loss: 18.336296
Downstream Train Epoch: 27 [12800/50000 (26%)]	Loss: 10.395526
Downstream Train Epoch: 27 [25600/50000 (51%)]	Loss: 13.239211
Downstream Train Epoch: 27 [38400/50000 (77%)]	Loss: 11.563983

 Downstream Train loss: 12.713545195910395 Acc: 0.3701
Downstream Train Epoch: 28 [0/50000 (0%)]	Loss: 11.173476
Downstream Train Epoch: 28 [12800/50000 (26%)]	Loss: 18.451115
Downstream Train Epoch: 28 [25600/50000 (51%)]	Loss: 13.685384
Downstream Train Epoch: 28 [38400/50000 (77%)]	Loss: 14.157709

 Downstream Train loss: 14.01925845535434 Acc: 0.374
Downstream Train Epoch: 29 [0/50000 (0%)]	Loss: 10.866627
Downstream Train Epoch: 29 [12800/50000 (26%)]	Loss: 10.977101
Downstream Train Epoch: 29 [25600/50000 (51%)]	Loss: 17.562605
Downstream Train Epoch: 29 [38400/50000 (77%)]	Loss: 15.379662

 Downstream Train loss: 13.33560015474047 Acc: 0.374
Downstream Train Epoch: 30 [0/50000 (0%)]	Loss: 10.824780
Downstream Train Epoch: 30 [12800/50000 (26%)]	Loss: 11.829220
Downstream Train Epoch: 30 [25600/50000 (51%)]	Loss: 10.569160
Downstream Train Epoch: 30 [38400/50000 (77%)]	Loss: 16.562515

 Downstream Train loss: 12.846428754378339 Acc: 0.374
Downstream Train Epoch: 31 [0/50000 (0%)]	Loss: 18.353199
Downstream Train Epoch: 31 [12800/50000 (26%)]	Loss: 11.700083
Downstream Train Epoch: 31 [25600/50000 (51%)]	Loss: 12.554986
Downstream Train Epoch: 31 [38400/50000 (77%)]	Loss: 16.982182

 Downstream Train loss: 14.286711838780617 Acc: 0.374
Downstream Train Epoch: 32 [0/50000 (0%)]	Loss: 16.441162
Downstream Train Epoch: 32 [12800/50000 (26%)]	Loss: 19.335682
Downstream Train Epoch: 32 [25600/50000 (51%)]	Loss: 19.163267
Downstream Train Epoch: 32 [38400/50000 (77%)]	Loss: 16.394161

 Downstream Train loss: 15.419139117610698 Acc: 0.3853
Downstream Train Epoch: 33 [0/50000 (0%)]	Loss: 11.467623
Downstream Train Epoch: 33 [12800/50000 (26%)]	Loss: 15.545441
Downstream Train Epoch: 33 [25600/50000 (51%)]	Loss: 10.543660
Downstream Train Epoch: 33 [38400/50000 (77%)]	Loss: 11.839961

 Downstream Train loss: 12.91945418776298 Acc: 0.3853
Downstream Train Epoch: 34 [0/50000 (0%)]	Loss: 16.024586
Downstream Train Epoch: 34 [12800/50000 (26%)]	Loss: 14.243802
Downstream Train Epoch: 34 [25600/50000 (51%)]	Loss: 12.724231
Downstream Train Epoch: 34 [38400/50000 (77%)]	Loss: 11.033058

 Downstream Train loss: 14.256465182012441 Acc: 0.3853
Downstream Train Epoch: 35 [0/50000 (0%)]	Loss: 14.352414
Downstream Train Epoch: 35 [12800/50000 (26%)]	Loss: 12.196682
Downstream Train Epoch: 35 [25600/50000 (51%)]	Loss: 12.755979
Downstream Train Epoch: 35 [38400/50000 (77%)]	Loss: 14.874761

 Downstream Train loss: 14.053488894384735 Acc: 0.3853
Downstream Train Epoch: 36 [0/50000 (0%)]	Loss: 18.478365
Downstream Train Epoch: 36 [12800/50000 (26%)]	Loss: 11.286858
Downstream Train Epoch: 36 [25600/50000 (51%)]	Loss: 13.029881
Downstream Train Epoch: 36 [38400/50000 (77%)]	Loss: 13.939653

 Downstream Train loss: 13.443220951119248 Acc: 0.3853
Downstream Train Epoch: 37 [0/50000 (0%)]	Loss: 9.023282
Downstream Train Epoch: 37 [12800/50000 (26%)]	Loss: 10.181272
Downstream Train Epoch: 37 [25600/50000 (51%)]	Loss: 8.407588
Downstream Train Epoch: 37 [38400/50000 (77%)]	Loss: 12.345853

 Downstream Train loss: 13.403303090406924 Acc: 0.3853
Downstream Train Epoch: 38 [0/50000 (0%)]	Loss: 10.173446
Downstream Train Epoch: 38 [12800/50000 (26%)]	Loss: 8.328022
Downstream Train Epoch: 38 [25600/50000 (51%)]	Loss: 25.241589
Downstream Train Epoch: 38 [38400/50000 (77%)]	Loss: 10.338470

 Downstream Train loss: 14.560447067630534 Acc: 0.3853
Downstream Train Epoch: 39 [0/50000 (0%)]	Loss: 18.253952
Downstream Train Epoch: 39 [12800/50000 (26%)]	Loss: 10.137790
Downstream Train Epoch: 39 [25600/50000 (51%)]	Loss: 11.133707
Downstream Train Epoch: 39 [38400/50000 (77%)]	Loss: 18.427105

 Downstream Train loss: 14.306321800971517 Acc: 0.3853
Downstream Train Epoch: 40 [0/50000 (0%)]	Loss: 13.549385
Downstream Train Epoch: 40 [12800/50000 (26%)]	Loss: 18.980999
Downstream Train Epoch: 40 [25600/50000 (51%)]	Loss: 10.821328
Downstream Train Epoch: 40 [38400/50000 (77%)]	Loss: 11.168290

 Downstream Train loss: 13.543404459953308 Acc: 0.3853
Downstream Train Epoch: 41 [0/50000 (0%)]	Loss: 12.760773
Downstream Train Epoch: 41 [12800/50000 (26%)]	Loss: 13.666875
Downstream Train Epoch: 41 [25600/50000 (51%)]	Loss: 18.415527
Downstream Train Epoch: 41 [38400/50000 (77%)]	Loss: 8.921482

 Downstream Train loss: 13.894817410683146 Acc: 0.3853
Downstream Train Epoch: 42 [0/50000 (0%)]	Loss: 16.308889
Downstream Train Epoch: 42 [12800/50000 (26%)]	Loss: 11.566484
Downstream Train Epoch: 42 [25600/50000 (51%)]	Loss: 16.526035
Downstream Train Epoch: 42 [38400/50000 (77%)]	Loss: 11.344604

 Downstream Train loss: 13.645957817836683 Acc: 0.3853
Downstream Train Epoch: 43 [0/50000 (0%)]	Loss: 12.596960
Downstream Train Epoch: 43 [12800/50000 (26%)]	Loss: 9.606761
Downstream Train Epoch: 43 [25600/50000 (51%)]	Loss: 13.287565
Downstream Train Epoch: 43 [38400/50000 (77%)]	Loss: 13.258615

 Downstream Train loss: 13.789675634734484 Acc: 0.3853
Downstream Train Epoch: 44 [0/50000 (0%)]	Loss: 18.400305
Downstream Train Epoch: 44 [12800/50000 (26%)]	Loss: 8.276998
Downstream Train Epoch: 44 [25600/50000 (51%)]	Loss: 13.715245
Downstream Train Epoch: 44 [38400/50000 (77%)]	Loss: 15.272127

 Downstream Train loss: 12.866152563873602 Acc: 0.3853
Downstream Train Epoch: 45 [0/50000 (0%)]	Loss: 14.374725
Downstream Train Epoch: 45 [12800/50000 (26%)]	Loss: 14.044390
Downstream Train Epoch: 45 [25600/50000 (51%)]	Loss: 18.395144
Downstream Train Epoch: 45 [38400/50000 (77%)]	Loss: 12.112169

 Downstream Train loss: 14.401842873923632 Acc: 0.3853
Downstream Train Epoch: 46 [0/50000 (0%)]	Loss: 16.346294
Downstream Train Epoch: 46 [12800/50000 (26%)]	Loss: 14.200131
Downstream Train Epoch: 46 [25600/50000 (51%)]	Loss: 13.861465
Downstream Train Epoch: 46 [38400/50000 (77%)]	Loss: 7.261860

 Downstream Train loss: 13.495225753102984 Acc: 0.3853
Downstream Train Epoch: 47 [0/50000 (0%)]	Loss: 12.543056
Downstream Train Epoch: 47 [12800/50000 (26%)]	Loss: 15.622907
Downstream Train Epoch: 47 [25600/50000 (51%)]	Loss: 12.042998
Downstream Train Epoch: 47 [38400/50000 (77%)]	Loss: 12.569274

 Downstream Train loss: 13.84737648039448 Acc: 0.3853
Downstream Train Epoch: 48 [0/50000 (0%)]	Loss: 16.169064
Downstream Train Epoch: 48 [12800/50000 (26%)]	Loss: 14.536647
Downstream Train Epoch: 48 [25600/50000 (51%)]	Loss: 10.464093
Downstream Train Epoch: 48 [38400/50000 (77%)]	Loss: 12.485627

 Downstream Train loss: 12.465493224105057 Acc: 0.3853
Downstream Train Epoch: 49 [0/50000 (0%)]	Loss: 13.274634
Downstream Train Epoch: 49 [12800/50000 (26%)]	Loss: 15.914536
Downstream Train Epoch: 49 [25600/50000 (51%)]	Loss: 17.761873
Downstream Train Epoch: 49 [38400/50000 (77%)]	Loss: 19.071037

 Downstream Train loss: 12.977449864757304 Acc: 0.4116
Downstream Train Epoch: 50 [0/50000 (0%)]	Loss: 9.939401
Downstream Train Epoch: 50 [12800/50000 (26%)]	Loss: 16.767809
Downstream Train Epoch: 50 [25600/50000 (51%)]	Loss: 9.734989
Downstream Train Epoch: 50 [38400/50000 (77%)]	Loss: 19.552618

 Downstream Train loss: 14.051657141471395 Acc: 0.4116
Downstream Train Epoch: 51 [0/50000 (0%)]	Loss: 12.876976
Downstream Train Epoch: 51 [12800/50000 (26%)]	Loss: 16.170330
Downstream Train Epoch: 51 [25600/50000 (51%)]	Loss: 18.486147
Downstream Train Epoch: 51 [38400/50000 (77%)]	Loss: 11.335223

 Downstream Train loss: 13.917220928231064 Acc: 0.4133
Downstream Train Epoch: 52 [0/50000 (0%)]	Loss: 9.518218
Downstream Train Epoch: 52 [12800/50000 (26%)]	Loss: 16.119076
Downstream Train Epoch: 52 [25600/50000 (51%)]	Loss: 9.983486
Downstream Train Epoch: 52 [38400/50000 (77%)]	Loss: 13.663132

 Downstream Train loss: 12.846773743629456 Acc: 0.4133
Downstream Train Epoch: 53 [0/50000 (0%)]	Loss: 9.862707
Downstream Train Epoch: 53 [12800/50000 (26%)]	Loss: 8.021148
Downstream Train Epoch: 53 [25600/50000 (51%)]	Loss: 16.428564
Downstream Train Epoch: 53 [38400/50000 (77%)]	Loss: 8.939598

 Downstream Train loss: 12.594453672973478 Acc: 0.4133
Downstream Train Epoch: 54 [0/50000 (0%)]	Loss: 19.029661
Downstream Train Epoch: 54 [12800/50000 (26%)]	Loss: 7.898637
Downstream Train Epoch: 54 [25600/50000 (51%)]	Loss: 14.574711
Downstream Train Epoch: 54 [38400/50000 (77%)]	Loss: 15.396650

 Downstream Train loss: 14.067393616754181 Acc: 0.4133
Downstream Train Epoch: 55 [0/50000 (0%)]	Loss: 25.823103
Downstream Train Epoch: 55 [12800/50000 (26%)]	Loss: 10.680150
Downstream Train Epoch: 55 [25600/50000 (51%)]	Loss: 15.188506
Downstream Train Epoch: 55 [38400/50000 (77%)]	Loss: 19.558031

 Downstream Train loss: 13.778224259006734 Acc: 0.4133
Downstream Train Epoch: 56 [0/50000 (0%)]	Loss: 12.443886
Downstream Train Epoch: 56 [12800/50000 (26%)]	Loss: 25.360426
Downstream Train Epoch: 56 [25600/50000 (51%)]	Loss: 15.644872
Downstream Train Epoch: 56 [38400/50000 (77%)]	Loss: 13.753247

 Downstream Train loss: 14.437981089767145 Acc: 0.4133
Downstream Train Epoch: 57 [0/50000 (0%)]	Loss: 15.666898
Downstream Train Epoch: 57 [12800/50000 (26%)]	Loss: 13.934602
Downstream Train Epoch: 57 [25600/50000 (51%)]	Loss: 14.399803
Downstream Train Epoch: 57 [38400/50000 (77%)]	Loss: 17.667511

 Downstream Train loss: 14.45949194382648 Acc: 0.4133
Downstream Train Epoch: 58 [0/50000 (0%)]	Loss: 12.567472
Downstream Train Epoch: 58 [12800/50000 (26%)]	Loss: 13.239279
Downstream Train Epoch: 58 [25600/50000 (51%)]	Loss: 10.420928
Downstream Train Epoch: 58 [38400/50000 (77%)]	Loss: 14.470445

 Downstream Train loss: 13.87172453987355 Acc: 0.4133
Downstream Train Epoch: 59 [0/50000 (0%)]	Loss: 19.867208
Downstream Train Epoch: 59 [12800/50000 (26%)]	Loss: 13.554462
Downstream Train Epoch: 59 [25600/50000 (51%)]	Loss: 14.395983
Downstream Train Epoch: 59 [38400/50000 (77%)]	Loss: 9.076757

 Downstream Train loss: 12.972724583684181 Acc: 0.4133
Downstream Train Epoch: 60 [0/50000 (0%)]	Loss: 12.271003
Downstream Train Epoch: 60 [12800/50000 (26%)]	Loss: 18.516117
Downstream Train Epoch: 60 [25600/50000 (51%)]	Loss: 10.109953
Downstream Train Epoch: 60 [38400/50000 (77%)]	Loss: 11.523310

 Downstream Train loss: 13.358194190628675 Acc: 0.4133
Classifier Accuracy for user 2 is 0.4133
Start tarining Classifier for user 3
Training classifier
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 3.142
Use i.i.d. sampling
sample dataset time: 0.027
user data samples: [10000, 10000, 10000, 10000, 10000]
begin training classifier...
Downstream Train Epoch: 1 [0/50000 (0%)]	Loss: 290.662811
Downstream Train Epoch: 1 [12800/50000 (26%)]	Loss: 44.217548
Downstream Train Epoch: 1 [25600/50000 (51%)]	Loss: 35.444523
Downstream Train Epoch: 1 [38400/50000 (77%)]	Loss: 27.058769

 Downstream Train loss: 44.046413197809336 Acc: 0.2659
Downstream Train Epoch: 2 [0/50000 (0%)]	Loss: 32.314884
Downstream Train Epoch: 2 [12800/50000 (26%)]	Loss: 24.536770
Downstream Train Epoch: 2 [25600/50000 (51%)]	Loss: 24.102268
Downstream Train Epoch: 2 [38400/50000 (77%)]	Loss: 24.194120

 Downstream Train loss: 25.185968953735973 Acc: 0.3249
Downstream Train Epoch: 3 [0/50000 (0%)]	Loss: 27.144848
Downstream Train Epoch: 3 [12800/50000 (26%)]	Loss: 21.950544
Downstream Train Epoch: 3 [25600/50000 (51%)]	Loss: 22.150373
Downstream Train Epoch: 3 [38400/50000 (77%)]	Loss: 21.487713

 Downstream Train loss: 23.241591434089504 Acc: 0.3249
Downstream Train Epoch: 4 [0/50000 (0%)]	Loss: 19.390100
Downstream Train Epoch: 4 [12800/50000 (26%)]	Loss: 19.079750
Downstream Train Epoch: 4 [25600/50000 (51%)]	Loss: 18.013771
Downstream Train Epoch: 4 [38400/50000 (77%)]	Loss: 19.873604

 Downstream Train loss: 20.85196107261035 Acc: 0.3357
Downstream Train Epoch: 5 [0/50000 (0%)]	Loss: 21.327162
Downstream Train Epoch: 5 [12800/50000 (26%)]	Loss: 18.958023
Downstream Train Epoch: 5 [25600/50000 (51%)]	Loss: 19.324516
Downstream Train Epoch: 5 [38400/50000 (77%)]	Loss: 22.397306

 Downstream Train loss: 20.49688650637257 Acc: 0.3357
Downstream Train Epoch: 6 [0/50000 (0%)]	Loss: 15.319499
Downstream Train Epoch: 6 [12800/50000 (26%)]	Loss: 21.397654
Downstream Train Epoch: 6 [25600/50000 (51%)]	Loss: 20.430710
Downstream Train Epoch: 6 [38400/50000 (77%)]	Loss: 14.886467

 Downstream Train loss: 18.940720636017467 Acc: 0.3357
Downstream Train Epoch: 7 [0/50000 (0%)]	Loss: 22.575323
Downstream Train Epoch: 7 [12800/50000 (26%)]	Loss: 17.906275
Downstream Train Epoch: 7 [25600/50000 (51%)]	Loss: 17.883207
Downstream Train Epoch: 7 [38400/50000 (77%)]	Loss: 19.855459

 Downstream Train loss: 19.34334353038243 Acc: 0.3572
Downstream Train Epoch: 8 [0/50000 (0%)]	Loss: 15.385839
Downstream Train Epoch: 8 [12800/50000 (26%)]	Loss: 17.743790
Downstream Train Epoch: 8 [25600/50000 (51%)]	Loss: 17.312649
Downstream Train Epoch: 8 [38400/50000 (77%)]	Loss: 15.204578

 Downstream Train loss: 17.855880785961542 Acc: 0.3572
Downstream Train Epoch: 9 [0/50000 (0%)]	Loss: 18.202412
Downstream Train Epoch: 9 [12800/50000 (26%)]	Loss: 20.905745
Downstream Train Epoch: 9 [25600/50000 (51%)]	Loss: 18.649603
Downstream Train Epoch: 9 [38400/50000 (77%)]	Loss: 17.476929

 Downstream Train loss: 19.790544310394598 Acc: 0.3572
Downstream Train Epoch: 10 [0/50000 (0%)]	Loss: 17.068523
Downstream Train Epoch: 10 [12800/50000 (26%)]	Loss: 17.799545
Downstream Train Epoch: 10 [25600/50000 (51%)]	Loss: 19.269798
Downstream Train Epoch: 10 [38400/50000 (77%)]	Loss: 14.973707

 Downstream Train loss: 17.404829531299825 Acc: 0.3572
Downstream Train Epoch: 11 [0/50000 (0%)]	Loss: 19.700775
Downstream Train Epoch: 11 [12800/50000 (26%)]	Loss: 17.147488
Downstream Train Epoch: 11 [25600/50000 (51%)]	Loss: 18.817167
Downstream Train Epoch: 11 [38400/50000 (77%)]	Loss: 17.962189

 Downstream Train loss: 17.91101006099156 Acc: 0.3572
Downstream Train Epoch: 12 [0/50000 (0%)]	Loss: 19.754686
Downstream Train Epoch: 12 [12800/50000 (26%)]	Loss: 11.835491
Downstream Train Epoch: 12 [25600/50000 (51%)]	Loss: 23.254744
Downstream Train Epoch: 12 [38400/50000 (77%)]	Loss: 20.050200

 Downstream Train loss: 19.490862121387405 Acc: 0.3572
Downstream Train Epoch: 13 [0/50000 (0%)]	Loss: 20.817419
Downstream Train Epoch: 13 [12800/50000 (26%)]	Loss: 16.093832
Downstream Train Epoch: 13 [25600/50000 (51%)]	Loss: 12.697440
Downstream Train Epoch: 13 [38400/50000 (77%)]	Loss: 15.353113

 Downstream Train loss: 18.02118730545044 Acc: 0.3572
Downstream Train Epoch: 14 [0/50000 (0%)]	Loss: 20.149418
Downstream Train Epoch: 14 [12800/50000 (26%)]	Loss: 16.646322
Downstream Train Epoch: 14 [25600/50000 (51%)]	Loss: 15.367643
Downstream Train Epoch: 14 [38400/50000 (77%)]	Loss: 15.899133

 Downstream Train loss: 16.567096466920813 Acc: 0.386
Downstream Train Epoch: 15 [0/50000 (0%)]	Loss: 14.962332
Downstream Train Epoch: 15 [12800/50000 (26%)]	Loss: 16.539692
Downstream Train Epoch: 15 [25600/50000 (51%)]	Loss: 17.989662
Downstream Train Epoch: 15 [38400/50000 (77%)]	Loss: 13.570155

 Downstream Train loss: 17.166829873104486 Acc: 0.386
Downstream Train Epoch: 16 [0/50000 (0%)]	Loss: 16.994377
Downstream Train Epoch: 16 [12800/50000 (26%)]	Loss: 14.325584
Downstream Train Epoch: 16 [25600/50000 (51%)]	Loss: 24.867455
Downstream Train Epoch: 16 [38400/50000 (77%)]	Loss: 16.126120

 Downstream Train loss: 17.548056748448587 Acc: 0.386
Downstream Train Epoch: 17 [0/50000 (0%)]	Loss: 15.418390
Downstream Train Epoch: 17 [12800/50000 (26%)]	Loss: 14.456287
Downstream Train Epoch: 17 [25600/50000 (51%)]	Loss: 13.740745
Downstream Train Epoch: 17 [38400/50000 (77%)]	Loss: 12.944110

 Downstream Train loss: 15.535622742711281 Acc: 0.386
Downstream Train Epoch: 18 [0/50000 (0%)]	Loss: 14.293593
Downstream Train Epoch: 18 [12800/50000 (26%)]	Loss: 18.602228
Downstream Train Epoch: 18 [25600/50000 (51%)]	Loss: 16.848747
Downstream Train Epoch: 18 [38400/50000 (77%)]	Loss: 16.901463

 Downstream Train loss: 17.227798510570917 Acc: 0.386
Downstream Train Epoch: 19 [0/50000 (0%)]	Loss: 23.688669
Downstream Train Epoch: 19 [12800/50000 (26%)]	Loss: 15.631080
Downstream Train Epoch: 19 [25600/50000 (51%)]	Loss: 22.024075
Downstream Train Epoch: 19 [38400/50000 (77%)]	Loss: 13.768636

 Downstream Train loss: 16.428098070378205 Acc: 0.386
Downstream Train Epoch: 20 [0/50000 (0%)]	Loss: 16.032095
Downstream Train Epoch: 20 [12800/50000 (26%)]	Loss: 26.626339
Downstream Train Epoch: 20 [25600/50000 (51%)]	Loss: 12.596820
Downstream Train Epoch: 20 [38400/50000 (77%)]	Loss: 16.838055

 Downstream Train loss: 16.0961832708242 Acc: 0.386
Downstream Train Epoch: 21 [0/50000 (0%)]	Loss: 13.358247
Downstream Train Epoch: 21 [12800/50000 (26%)]	Loss: 15.963876
Downstream Train Epoch: 21 [25600/50000 (51%)]	Loss: 13.517011
Downstream Train Epoch: 21 [38400/50000 (77%)]	Loss: 21.662401

 Downstream Train loss: 16.984926632472447 Acc: 0.3977
Downstream Train Epoch: 22 [0/50000 (0%)]	Loss: 13.424062
Downstream Train Epoch: 22 [12800/50000 (26%)]	Loss: 15.698531
Downstream Train Epoch: 22 [25600/50000 (51%)]	Loss: 15.451629
Downstream Train Epoch: 22 [38400/50000 (77%)]	Loss: 11.299825

 Downstream Train loss: 15.424973517048116 Acc: 0.3977
Downstream Train Epoch: 23 [0/50000 (0%)]	Loss: 14.054608
Downstream Train Epoch: 23 [12800/50000 (26%)]	Loss: 12.335146
Downstream Train Epoch: 23 [25600/50000 (51%)]	Loss: 14.487502
Downstream Train Epoch: 23 [38400/50000 (77%)]	Loss: 16.391878

 Downstream Train loss: 17.95162589695989 Acc: 0.3977
Downstream Train Epoch: 24 [0/50000 (0%)]	Loss: 31.407991
Downstream Train Epoch: 24 [12800/50000 (26%)]	Loss: 12.103545
Downstream Train Epoch: 24 [25600/50000 (51%)]	Loss: 14.475146
Downstream Train Epoch: 24 [38400/50000 (77%)]	Loss: 12.551489

 Downstream Train loss: 15.949041926130956 Acc: 0.3977
Downstream Train Epoch: 25 [0/50000 (0%)]	Loss: 15.780264
Downstream Train Epoch: 25 [12800/50000 (26%)]	Loss: 11.963502
Downstream Train Epoch: 25 [25600/50000 (51%)]	Loss: 17.137014
Downstream Train Epoch: 25 [38400/50000 (77%)]	Loss: 22.941294

 Downstream Train loss: 17.72495221118538 Acc: 0.3977
Downstream Train Epoch: 26 [0/50000 (0%)]	Loss: 20.202267
Downstream Train Epoch: 26 [12800/50000 (26%)]	Loss: 11.951442
Downstream Train Epoch: 26 [25600/50000 (51%)]	Loss: 14.182578
Downstream Train Epoch: 26 [38400/50000 (77%)]	Loss: 18.018559

 Downstream Train loss: 16.66099801355479 Acc: 0.3977
Downstream Train Epoch: 27 [0/50000 (0%)]	Loss: 15.914035
Downstream Train Epoch: 27 [12800/50000 (26%)]	Loss: 17.922138
Downstream Train Epoch: 27 [25600/50000 (51%)]	Loss: 15.955658
Downstream Train Epoch: 27 [38400/50000 (77%)]	Loss: 21.615650

 Downstream Train loss: 17.291739021028793 Acc: 0.3977
Downstream Train Epoch: 28 [0/50000 (0%)]	Loss: 24.565016
Downstream Train Epoch: 28 [12800/50000 (26%)]	Loss: 18.648327
Downstream Train Epoch: 28 [25600/50000 (51%)]	Loss: 14.249341
Downstream Train Epoch: 28 [38400/50000 (77%)]	Loss: 13.440991

 Downstream Train loss: 17.33324941323728 Acc: 0.3977
Downstream Train Epoch: 29 [0/50000 (0%)]	Loss: 11.755893
Downstream Train Epoch: 29 [12800/50000 (26%)]	Loss: 11.592388
Downstream Train Epoch: 29 [25600/50000 (51%)]	Loss: 11.326575
Downstream Train Epoch: 29 [38400/50000 (77%)]	Loss: 21.188551

 Downstream Train loss: 15.082251101124044 Acc: 0.3977
Downstream Train Epoch: 30 [0/50000 (0%)]	Loss: 11.662913
Downstream Train Epoch: 30 [12800/50000 (26%)]	Loss: 14.375403
Downstream Train Epoch: 30 [25600/50000 (51%)]	Loss: 14.158340
Downstream Train Epoch: 30 [38400/50000 (77%)]	Loss: 13.090169

 Downstream Train loss: 16.133923914967752 Acc: 0.4059
Downstream Train Epoch: 31 [0/50000 (0%)]	Loss: 15.573377
Downstream Train Epoch: 31 [12800/50000 (26%)]	Loss: 13.522960
Downstream Train Epoch: 31 [25600/50000 (51%)]	Loss: 18.949125
Downstream Train Epoch: 31 [38400/50000 (77%)]	Loss: 13.978238

 Downstream Train loss: 15.795454088522463 Acc: 0.4059
Downstream Train Epoch: 32 [0/50000 (0%)]	Loss: 16.710539
Downstream Train Epoch: 32 [12800/50000 (26%)]	Loss: 20.455063
Downstream Train Epoch: 32 [25600/50000 (51%)]	Loss: 26.827679
Downstream Train Epoch: 32 [38400/50000 (77%)]	Loss: 15.088669

 Downstream Train loss: 19.198227337428502 Acc: 0.4059
Downstream Train Epoch: 33 [0/50000 (0%)]	Loss: 12.889921
Downstream Train Epoch: 33 [12800/50000 (26%)]	Loss: 11.792262
Downstream Train Epoch: 33 [25600/50000 (51%)]	Loss: 16.085148
Downstream Train Epoch: 33 [38400/50000 (77%)]	Loss: 9.902826

 Downstream Train loss: 15.607865046481697 Acc: 0.4059
Downstream Train Epoch: 34 [0/50000 (0%)]	Loss: 16.878086
Downstream Train Epoch: 34 [12800/50000 (26%)]	Loss: 19.685217
Downstream Train Epoch: 34 [25600/50000 (51%)]	Loss: 12.757486
Downstream Train Epoch: 34 [38400/50000 (77%)]	Loss: 16.232979

 Downstream Train loss: 16.52020080722108 Acc: 0.4059
Downstream Train Epoch: 35 [0/50000 (0%)]	Loss: 11.691414
Downstream Train Epoch: 35 [12800/50000 (26%)]	Loss: 17.446449
Downstream Train Epoch: 35 [25600/50000 (51%)]	Loss: 22.104095
Downstream Train Epoch: 35 [38400/50000 (77%)]	Loss: 21.461782

 Downstream Train loss: 16.472908234109685 Acc: 0.4059
Downstream Train Epoch: 36 [0/50000 (0%)]	Loss: 19.331608
Downstream Train Epoch: 36 [12800/50000 (26%)]	Loss: 18.842196
Downstream Train Epoch: 36 [25600/50000 (51%)]	Loss: 22.940765
Downstream Train Epoch: 36 [38400/50000 (77%)]	Loss: 14.299549

 Downstream Train loss: 16.098753398778488 Acc: 0.4059
Downstream Train Epoch: 37 [0/50000 (0%)]	Loss: 21.252724
Downstream Train Epoch: 37 [12800/50000 (26%)]	Loss: 11.429274
Downstream Train Epoch: 37 [25600/50000 (51%)]	Loss: 13.797766
Downstream Train Epoch: 37 [38400/50000 (77%)]	Loss: 11.201269

 Downstream Train loss: 17.604318214922536 Acc: 0.4059
Downstream Train Epoch: 38 [0/50000 (0%)]	Loss: 26.595644
Downstream Train Epoch: 38 [12800/50000 (26%)]	Loss: 13.438239
Downstream Train Epoch: 38 [25600/50000 (51%)]	Loss: 12.262187
Downstream Train Epoch: 38 [38400/50000 (77%)]	Loss: 36.892822

 Downstream Train loss: 16.660492792421458 Acc: 0.4059
Downstream Train Epoch: 39 [0/50000 (0%)]	Loss: 12.370900
Downstream Train Epoch: 39 [12800/50000 (26%)]	Loss: 16.921001
Downstream Train Epoch: 39 [25600/50000 (51%)]	Loss: 13.932587
Downstream Train Epoch: 39 [38400/50000 (77%)]	Loss: 19.607336

 Downstream Train loss: 16.199726489125467 Acc: 0.4059
Downstream Train Epoch: 40 [0/50000 (0%)]	Loss: 22.444822
Downstream Train Epoch: 40 [12800/50000 (26%)]	Loss: 11.324708
Downstream Train Epoch: 40 [25600/50000 (51%)]	Loss: 12.416423
Downstream Train Epoch: 40 [38400/50000 (77%)]	Loss: 16.102797

 Downstream Train loss: 17.631228709707454 Acc: 0.4059
Downstream Train Epoch: 41 [0/50000 (0%)]	Loss: 13.948912
Downstream Train Epoch: 41 [12800/50000 (26%)]	Loss: 18.208576
Downstream Train Epoch: 41 [25600/50000 (51%)]	Loss: 18.582603
Downstream Train Epoch: 41 [38400/50000 (77%)]	Loss: 14.976174

 Downstream Train loss: 16.367118436463024 Acc: 0.4059
Downstream Train Epoch: 42 [0/50000 (0%)]	Loss: 23.823935
Downstream Train Epoch: 42 [12800/50000 (26%)]	Loss: 11.219928
Downstream Train Epoch: 42 [25600/50000 (51%)]	Loss: 16.337502
Downstream Train Epoch: 42 [38400/50000 (77%)]	Loss: 20.329870

 Downstream Train loss: 15.985873378053004 Acc: 0.4059
Downstream Train Epoch: 43 [0/50000 (0%)]	Loss: 15.730421
Downstream Train Epoch: 43 [12800/50000 (26%)]	Loss: 14.552381
Downstream Train Epoch: 43 [25600/50000 (51%)]	Loss: 11.739980
Downstream Train Epoch: 43 [38400/50000 (77%)]	Loss: 12.795136

 Downstream Train loss: 15.933131612077052 Acc: 0.4059
Downstream Train Epoch: 44 [0/50000 (0%)]	Loss: 20.898670
Downstream Train Epoch: 44 [12800/50000 (26%)]	Loss: 20.569359
Downstream Train Epoch: 44 [25600/50000 (51%)]	Loss: 13.264103
Downstream Train Epoch: 44 [38400/50000 (77%)]	Loss: 29.377125

 Downstream Train loss: 16.823757074317154 Acc: 0.4059
Downstream Train Epoch: 45 [0/50000 (0%)]	Loss: 20.862375
Downstream Train Epoch: 45 [12800/50000 (26%)]	Loss: 14.444825
Downstream Train Epoch: 45 [25600/50000 (51%)]	Loss: 16.729372
Downstream Train Epoch: 45 [38400/50000 (77%)]	Loss: 15.292633

 Downstream Train loss: 16.728254337700047 Acc: 0.4059
Downstream Train Epoch: 46 [0/50000 (0%)]	Loss: 17.625971
Downstream Train Epoch: 46 [12800/50000 (26%)]	Loss: 14.775884
Downstream Train Epoch: 46 [25600/50000 (51%)]	Loss: 17.200130
Downstream Train Epoch: 46 [38400/50000 (77%)]	Loss: 20.376366

 Downstream Train loss: 16.13626099849234 Acc: 0.4059
Downstream Train Epoch: 47 [0/50000 (0%)]	Loss: 15.855382
Downstream Train Epoch: 47 [12800/50000 (26%)]	Loss: 13.643558
Downstream Train Epoch: 47 [25600/50000 (51%)]	Loss: 17.321091
Downstream Train Epoch: 47 [38400/50000 (77%)]	Loss: 21.982723

 Downstream Train loss: 16.30151127795784 Acc: 0.4059
Downstream Train Epoch: 48 [0/50000 (0%)]	Loss: 15.457755
Downstream Train Epoch: 48 [12800/50000 (26%)]	Loss: 11.024644
Downstream Train Epoch: 48 [25600/50000 (51%)]	Loss: 19.677134
Downstream Train Epoch: 48 [38400/50000 (77%)]	Loss: 15.523752

 Downstream Train loss: 17.81394171228214 Acc: 0.4059
Downstream Train Epoch: 49 [0/50000 (0%)]	Loss: 13.053109
Downstream Train Epoch: 49 [12800/50000 (26%)]	Loss: 14.000726
Downstream Train Epoch: 49 [25600/50000 (51%)]	Loss: 14.202028
Downstream Train Epoch: 49 [38400/50000 (77%)]	Loss: 13.305972

 Downstream Train loss: 16.757879043111995 Acc: 0.4059
Downstream Train Epoch: 50 [0/50000 (0%)]	Loss: 22.238737
Downstream Train Epoch: 50 [12800/50000 (26%)]	Loss: 15.957603
Downstream Train Epoch: 50 [25600/50000 (51%)]	Loss: 20.191687
Downstream Train Epoch: 50 [38400/50000 (77%)]	Loss: 16.438961

 Downstream Train loss: 15.650060955359011 Acc: 0.4059
Downstream Train Epoch: 51 [0/50000 (0%)]	Loss: 17.417692
Downstream Train Epoch: 51 [12800/50000 (26%)]	Loss: 13.626111
Downstream Train Epoch: 51 [25600/50000 (51%)]	Loss: 19.913456
Downstream Train Epoch: 51 [38400/50000 (77%)]	Loss: 10.931906

 Downstream Train loss: 16.257995819558904 Acc: 0.4059
Downstream Train Epoch: 52 [0/50000 (0%)]	Loss: 15.745067
Downstream Train Epoch: 52 [12800/50000 (26%)]	Loss: 14.404952
Downstream Train Epoch: 52 [25600/50000 (51%)]	Loss: 26.142956
Downstream Train Epoch: 52 [38400/50000 (77%)]	Loss: 26.396688

 Downstream Train loss: 16.075897372498805 Acc: 0.4059
Downstream Train Epoch: 53 [0/50000 (0%)]	Loss: 9.894542
Downstream Train Epoch: 53 [12800/50000 (26%)]	Loss: 29.069954
Downstream Train Epoch: 53 [25600/50000 (51%)]	Loss: 13.234360
Downstream Train Epoch: 53 [38400/50000 (77%)]	Loss: 17.639448

 Downstream Train loss: 16.116575562224096 Acc: 0.4059
Downstream Train Epoch: 54 [0/50000 (0%)]	Loss: 10.575475
Downstream Train Epoch: 54 [12800/50000 (26%)]	Loss: 21.212154
Downstream Train Epoch: 54 [25600/50000 (51%)]	Loss: 13.523218
Downstream Train Epoch: 54 [38400/50000 (77%)]	Loss: 15.019103

 Downstream Train loss: 15.980439468305939 Acc: 0.4059
Downstream Train Epoch: 55 [0/50000 (0%)]	Loss: 11.506279
Downstream Train Epoch: 55 [12800/50000 (26%)]	Loss: 10.280684
Downstream Train Epoch: 55 [25600/50000 (51%)]	Loss: 14.265110
Downstream Train Epoch: 55 [38400/50000 (77%)]	Loss: 16.266600

 Downstream Train loss: 14.758689578698606 Acc: 0.4059
Downstream Train Epoch: 56 [0/50000 (0%)]	Loss: 17.542339
Downstream Train Epoch: 56 [12800/50000 (26%)]	Loss: 29.840261
Downstream Train Epoch: 56 [25600/50000 (51%)]	Loss: 19.376333
Downstream Train Epoch: 56 [38400/50000 (77%)]	Loss: 13.172929

 Downstream Train loss: 17.193147561988052 Acc: 0.4059
Downstream Train Epoch: 57 [0/50000 (0%)]	Loss: 16.826975
Downstream Train Epoch: 57 [12800/50000 (26%)]	Loss: 20.693411
Downstream Train Epoch: 57 [25600/50000 (51%)]	Loss: 17.771839
Downstream Train Epoch: 57 [38400/50000 (77%)]	Loss: 15.019963

 Downstream Train loss: 19.752058802818766 Acc: 0.4059
Downstream Train Epoch: 58 [0/50000 (0%)]	Loss: 17.507410
Downstream Train Epoch: 58 [12800/50000 (26%)]	Loss: 11.641240
Downstream Train Epoch: 58 [25600/50000 (51%)]	Loss: 19.450705
Downstream Train Epoch: 58 [38400/50000 (77%)]	Loss: 11.478972

 Downstream Train loss: 15.474597655996984 Acc: 0.4059
Downstream Train Epoch: 59 [0/50000 (0%)]	Loss: 21.001318
Downstream Train Epoch: 59 [12800/50000 (26%)]	Loss: 21.901249
Downstream Train Epoch: 59 [25600/50000 (51%)]	Loss: 19.323961
Downstream Train Epoch: 59 [38400/50000 (77%)]	Loss: 9.454592

 Downstream Train loss: 16.975015148824575 Acc: 0.4059
Downstream Train Epoch: 60 [0/50000 (0%)]	Loss: 21.750082
Downstream Train Epoch: 60 [12800/50000 (26%)]	Loss: 17.075169
Downstream Train Epoch: 60 [25600/50000 (51%)]	Loss: 12.228875
Downstream Train Epoch: 60 [38400/50000 (77%)]	Loss: 18.171280

 Downstream Train loss: 14.504447041725626 Acc: 0.4059
Classifier Accuracy for user 3 is 0.4059
Start tarining Classifier for user 4
Training classifier
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 3.116
Use i.i.d. sampling
sample dataset time: 0.027
user data samples: [10000, 10000, 10000, 10000, 10000]
begin training classifier...
Downstream Train Epoch: 1 [0/50000 (0%)]	Loss: 306.537720
Downstream Train Epoch: 1 [12800/50000 (26%)]	Loss: 48.535797
Downstream Train Epoch: 1 [25600/50000 (51%)]	Loss: 35.697269
Downstream Train Epoch: 1 [38400/50000 (77%)]	Loss: 34.553616

 Downstream Train loss: 48.971873536401866 Acc: 0.2607
Downstream Train Epoch: 2 [0/50000 (0%)]	Loss: 30.499220
Downstream Train Epoch: 2 [12800/50000 (26%)]	Loss: 37.917377
Downstream Train Epoch: 2 [25600/50000 (51%)]	Loss: 33.960678
Downstream Train Epoch: 2 [38400/50000 (77%)]	Loss: 31.937191

 Downstream Train loss: 31.259548518122457 Acc: 0.2943
Downstream Train Epoch: 3 [0/50000 (0%)]	Loss: 32.098373
Downstream Train Epoch: 3 [12800/50000 (26%)]	Loss: 30.648855
Downstream Train Epoch: 3 [25600/50000 (51%)]	Loss: 24.201492
Downstream Train Epoch: 3 [38400/50000 (77%)]	Loss: 27.249805

 Downstream Train loss: 27.403443628427933 Acc: 0.3154
Downstream Train Epoch: 4 [0/50000 (0%)]	Loss: 27.365284
Downstream Train Epoch: 4 [12800/50000 (26%)]	Loss: 31.995724
Downstream Train Epoch: 4 [25600/50000 (51%)]	Loss: 25.636906
Downstream Train Epoch: 4 [38400/50000 (77%)]	Loss: 24.724342

 Downstream Train loss: 25.45812989254387 Acc: 0.342
Downstream Train Epoch: 5 [0/50000 (0%)]	Loss: 23.613256
Downstream Train Epoch: 5 [12800/50000 (26%)]	Loss: 25.032928
Downstream Train Epoch: 5 [25600/50000 (51%)]	Loss: 26.735809
Downstream Train Epoch: 5 [38400/50000 (77%)]	Loss: 16.932034

 Downstream Train loss: 24.341026150450414 Acc: 0.342
Downstream Train Epoch: 6 [0/50000 (0%)]	Loss: 23.867943
Downstream Train Epoch: 6 [12800/50000 (26%)]	Loss: 22.950979
Downstream Train Epoch: 6 [25600/50000 (51%)]	Loss: 26.086380
Downstream Train Epoch: 6 [38400/50000 (77%)]	Loss: 25.636509

 Downstream Train loss: 24.373688911905095 Acc: 0.342
Downstream Train Epoch: 7 [0/50000 (0%)]	Loss: 36.546150
Downstream Train Epoch: 7 [12800/50000 (26%)]	Loss: 26.595064
Downstream Train Epoch: 7 [25600/50000 (51%)]	Loss: 27.884010
Downstream Train Epoch: 7 [38400/50000 (77%)]	Loss: 17.880507

 Downstream Train loss: 24.804181337356567 Acc: 0.342
Downstream Train Epoch: 8 [0/50000 (0%)]	Loss: 22.297453
Downstream Train Epoch: 8 [12800/50000 (26%)]	Loss: 24.156960
Downstream Train Epoch: 8 [25600/50000 (51%)]	Loss: 24.778475
Downstream Train Epoch: 8 [38400/50000 (77%)]	Loss: 17.382362

 Downstream Train loss: 23.218177094751475 Acc: 0.342
Downstream Train Epoch: 9 [0/50000 (0%)]	Loss: 28.841063
Downstream Train Epoch: 9 [12800/50000 (26%)]	Loss: 20.383991
Downstream Train Epoch: 9 [25600/50000 (51%)]	Loss: 19.810455
Downstream Train Epoch: 9 [38400/50000 (77%)]	Loss: 24.968445

 Downstream Train loss: 22.389927382371862 Acc: 0.342
Downstream Train Epoch: 10 [0/50000 (0%)]	Loss: 34.195713
Downstream Train Epoch: 10 [12800/50000 (26%)]	Loss: 19.413294
Downstream Train Epoch: 10 [25600/50000 (51%)]	Loss: 17.717663
Downstream Train Epoch: 10 [38400/50000 (77%)]	Loss: 18.842518

 Downstream Train loss: 20.824840404549423 Acc: 0.342
Downstream Train Epoch: 11 [0/50000 (0%)]	Loss: 26.566227
Downstream Train Epoch: 11 [12800/50000 (26%)]	Loss: 18.382023
Downstream Train Epoch: 11 [25600/50000 (51%)]	Loss: 25.258869
Downstream Train Epoch: 11 [38400/50000 (77%)]	Loss: 37.435341

 Downstream Train loss: 22.500001522959494 Acc: 0.342
Downstream Train Epoch: 12 [0/50000 (0%)]	Loss: 18.128159
Downstream Train Epoch: 12 [12800/50000 (26%)]	Loss: 25.833664
Downstream Train Epoch: 12 [25600/50000 (51%)]	Loss: 18.978199
Downstream Train Epoch: 12 [38400/50000 (77%)]	Loss: 17.601934

 Downstream Train loss: 20.389413799558366 Acc: 0.342
Downstream Train Epoch: 13 [0/50000 (0%)]	Loss: 21.605726
Downstream Train Epoch: 13 [12800/50000 (26%)]	Loss: 27.404642
Downstream Train Epoch: 13 [25600/50000 (51%)]	Loss: 17.210945
Downstream Train Epoch: 13 [38400/50000 (77%)]	Loss: 16.358774

 Downstream Train loss: 21.217287910227874 Acc: 0.342
Downstream Train Epoch: 14 [0/50000 (0%)]	Loss: 27.452894
Downstream Train Epoch: 14 [12800/50000 (26%)]	Loss: 28.156898
Downstream Train Epoch: 14 [25600/50000 (51%)]	Loss: 12.995539
Downstream Train Epoch: 14 [38400/50000 (77%)]	Loss: 23.472446

 Downstream Train loss: 20.963950604808574 Acc: 0.342
Downstream Train Epoch: 15 [0/50000 (0%)]	Loss: 21.260740
Downstream Train Epoch: 15 [12800/50000 (26%)]	Loss: 27.050480
Downstream Train Epoch: 15 [25600/50000 (51%)]	Loss: 23.981087
Downstream Train Epoch: 15 [38400/50000 (77%)]	Loss: 30.896927

 Downstream Train loss: 21.35619323107661 Acc: 0.342
Downstream Train Epoch: 16 [0/50000 (0%)]	Loss: 22.912786
Downstream Train Epoch: 16 [12800/50000 (26%)]	Loss: 20.259474
Downstream Train Epoch: 16 [25600/50000 (51%)]	Loss: 18.663586
Downstream Train Epoch: 16 [38400/50000 (77%)]	Loss: 19.771084

 Downstream Train loss: 21.82685895841949 Acc: 0.3535
Downstream Train Epoch: 17 [0/50000 (0%)]	Loss: 17.399525
Downstream Train Epoch: 17 [12800/50000 (26%)]	Loss: 19.700268
Downstream Train Epoch: 17 [25600/50000 (51%)]	Loss: 16.690388
Downstream Train Epoch: 17 [38400/50000 (77%)]	Loss: 21.772406

 Downstream Train loss: 20.83755639134621 Acc: 0.3535
Downstream Train Epoch: 18 [0/50000 (0%)]	Loss: 19.196289
Downstream Train Epoch: 18 [12800/50000 (26%)]	Loss: 29.317713
Downstream Train Epoch: 18 [25600/50000 (51%)]	Loss: 17.785204
Downstream Train Epoch: 18 [38400/50000 (77%)]	Loss: 23.810303

 Downstream Train loss: 21.160035931334203 Acc: 0.3535
Downstream Train Epoch: 19 [0/50000 (0%)]	Loss: 27.620386
Downstream Train Epoch: 19 [12800/50000 (26%)]	Loss: 19.733093
Downstream Train Epoch: 19 [25600/50000 (51%)]	Loss: 18.091129
Downstream Train Epoch: 19 [38400/50000 (77%)]	Loss: 14.892072

 Downstream Train loss: 19.361591207737824 Acc: 0.3535
Downstream Train Epoch: 20 [0/50000 (0%)]	Loss: 15.997870
Downstream Train Epoch: 20 [12800/50000 (26%)]	Loss: 19.912292
Downstream Train Epoch: 20 [25600/50000 (51%)]	Loss: 21.072414
Downstream Train Epoch: 20 [38400/50000 (77%)]	Loss: 21.526011

 Downstream Train loss: 19.05333350142654 Acc: 0.3902
Downstream Train Epoch: 21 [0/50000 (0%)]	Loss: 13.173628
Downstream Train Epoch: 21 [12800/50000 (26%)]	Loss: 22.425558
Downstream Train Epoch: 21 [25600/50000 (51%)]	Loss: 22.933193
Downstream Train Epoch: 21 [38400/50000 (77%)]	Loss: 16.010275

 Downstream Train loss: 19.32941592956076 Acc: 0.3902
Downstream Train Epoch: 22 [0/50000 (0%)]	Loss: 19.390902
Downstream Train Epoch: 22 [12800/50000 (26%)]	Loss: 24.373268
Downstream Train Epoch: 22 [25600/50000 (51%)]	Loss: 19.218544
Downstream Train Epoch: 22 [38400/50000 (77%)]	Loss: 15.731009

 Downstream Train loss: 20.922653748064626 Acc: 0.3902
Downstream Train Epoch: 23 [0/50000 (0%)]	Loss: 20.902672
Downstream Train Epoch: 23 [12800/50000 (26%)]	Loss: 17.436167
Downstream Train Epoch: 23 [25600/50000 (51%)]	Loss: 23.266954
Downstream Train Epoch: 23 [38400/50000 (77%)]	Loss: 27.849522

 Downstream Train loss: 21.753739337531886 Acc: 0.3902
Downstream Train Epoch: 24 [0/50000 (0%)]	Loss: 36.854073
Downstream Train Epoch: 24 [12800/50000 (26%)]	Loss: 24.909557
Downstream Train Epoch: 24 [25600/50000 (51%)]	Loss: 14.334146
Downstream Train Epoch: 24 [38400/50000 (77%)]	Loss: 24.766642

 Downstream Train loss: 20.835596843641632 Acc: 0.3902
Downstream Train Epoch: 25 [0/50000 (0%)]	Loss: 17.951494
Downstream Train Epoch: 25 [12800/50000 (26%)]	Loss: 21.429991
Downstream Train Epoch: 25 [25600/50000 (51%)]	Loss: 27.832560
Downstream Train Epoch: 25 [38400/50000 (77%)]	Loss: 24.521317

 Downstream Train loss: 21.295714183729523 Acc: 0.3902
Downstream Train Epoch: 26 [0/50000 (0%)]	Loss: 21.741013
Downstream Train Epoch: 26 [12800/50000 (26%)]	Loss: 18.051973
Downstream Train Epoch: 26 [25600/50000 (51%)]	Loss: 21.768572
Downstream Train Epoch: 26 [38400/50000 (77%)]	Loss: 33.417526

 Downstream Train loss: 21.378062793186732 Acc: 0.3902
Downstream Train Epoch: 27 [0/50000 (0%)]	Loss: 24.660315
Downstream Train Epoch: 27 [12800/50000 (26%)]	Loss: 20.273844
Downstream Train Epoch: 27 [25600/50000 (51%)]	Loss: 24.549212
Downstream Train Epoch: 27 [38400/50000 (77%)]	Loss: 15.560363

 Downstream Train loss: 20.23741180556161 Acc: 0.3902
Downstream Train Epoch: 28 [0/50000 (0%)]	Loss: 19.230953
Downstream Train Epoch: 28 [12800/50000 (26%)]	Loss: 26.844990
Downstream Train Epoch: 28 [25600/50000 (51%)]	Loss: 19.360867
Downstream Train Epoch: 28 [38400/50000 (77%)]	Loss: 17.996208

 Downstream Train loss: 20.173560366338613 Acc: 0.3902
Downstream Train Epoch: 29 [0/50000 (0%)]	Loss: 23.555779
Downstream Train Epoch: 29 [12800/50000 (26%)]	Loss: 15.450395
Downstream Train Epoch: 29 [25600/50000 (51%)]	Loss: 17.956303
Downstream Train Epoch: 29 [38400/50000 (77%)]	Loss: 19.715794

 Downstream Train loss: 21.89719823915131 Acc: 0.3984
Downstream Train Epoch: 30 [0/50000 (0%)]	Loss: 22.809767
Downstream Train Epoch: 30 [12800/50000 (26%)]	Loss: 14.662397
Downstream Train Epoch: 30 [25600/50000 (51%)]	Loss: 17.835224
Downstream Train Epoch: 30 [38400/50000 (77%)]	Loss: 18.287933

 Downstream Train loss: 19.401697713501598 Acc: 0.3984
Downstream Train Epoch: 31 [0/50000 (0%)]	Loss: 20.403328
Downstream Train Epoch: 31 [12800/50000 (26%)]	Loss: 16.933430
Downstream Train Epoch: 31 [25600/50000 (51%)]	Loss: 17.060120
Downstream Train Epoch: 31 [38400/50000 (77%)]	Loss: 21.857327

 Downstream Train loss: 19.57840763306131 Acc: 0.3984
Downstream Train Epoch: 32 [0/50000 (0%)]	Loss: 27.070786
Downstream Train Epoch: 32 [12800/50000 (26%)]	Loss: 13.163179
Downstream Train Epoch: 32 [25600/50000 (51%)]	Loss: 19.637815
Downstream Train Epoch: 32 [38400/50000 (77%)]	Loss: 14.844347

 Downstream Train loss: 22.253471087436285 Acc: 0.3984
Downstream Train Epoch: 33 [0/50000 (0%)]	Loss: 33.062351
Downstream Train Epoch: 33 [12800/50000 (26%)]	Loss: 26.862064
Downstream Train Epoch: 33 [25600/50000 (51%)]	Loss: 18.639309
Downstream Train Epoch: 33 [38400/50000 (77%)]	Loss: 15.994848

 Downstream Train loss: 20.047710374910004 Acc: 0.3984
Downstream Train Epoch: 34 [0/50000 (0%)]	Loss: 19.888786
Downstream Train Epoch: 34 [12800/50000 (26%)]	Loss: 17.726555
Downstream Train Epoch: 34 [25600/50000 (51%)]	Loss: 24.566484
Downstream Train Epoch: 34 [38400/50000 (77%)]	Loss: 17.695045

 Downstream Train loss: 19.238875043635467 Acc: 0.3984
Downstream Train Epoch: 35 [0/50000 (0%)]	Loss: 20.678297
Downstream Train Epoch: 35 [12800/50000 (26%)]	Loss: 28.937077
Downstream Train Epoch: 35 [25600/50000 (51%)]	Loss: 20.584927
Downstream Train Epoch: 35 [38400/50000 (77%)]	Loss: 20.662403

 Downstream Train loss: 21.06141981786611 Acc: 0.3984
Downstream Train Epoch: 36 [0/50000 (0%)]	Loss: 14.966012
Downstream Train Epoch: 36 [12800/50000 (26%)]	Loss: 18.526482
Downstream Train Epoch: 36 [25600/50000 (51%)]	Loss: 12.811172
Downstream Train Epoch: 36 [38400/50000 (77%)]	Loss: 26.761559

 Downstream Train loss: 18.08673688343593 Acc: 0.3984
Downstream Train Epoch: 37 [0/50000 (0%)]	Loss: 22.239187
Downstream Train Epoch: 37 [12800/50000 (26%)]	Loss: 23.798462
Downstream Train Epoch: 37 [25600/50000 (51%)]	Loss: 20.098488
Downstream Train Epoch: 37 [38400/50000 (77%)]	Loss: 19.739481

 Downstream Train loss: 20.667919509264888 Acc: 0.3984
Downstream Train Epoch: 38 [0/50000 (0%)]	Loss: 18.376175
Downstream Train Epoch: 38 [12800/50000 (26%)]	Loss: 16.016407
Downstream Train Epoch: 38 [25600/50000 (51%)]	Loss: 25.139462
Downstream Train Epoch: 38 [38400/50000 (77%)]	Loss: 25.347986

 Downstream Train loss: 19.816173782154006 Acc: 0.3984
Downstream Train Epoch: 39 [0/50000 (0%)]	Loss: 19.633305
Downstream Train Epoch: 39 [12800/50000 (26%)]	Loss: 14.523111
Downstream Train Epoch: 39 [25600/50000 (51%)]	Loss: 17.328131
Downstream Train Epoch: 39 [38400/50000 (77%)]	Loss: 15.650704

 Downstream Train loss: 18.08953920189215 Acc: 0.3984
Downstream Train Epoch: 40 [0/50000 (0%)]	Loss: 17.944374
Downstream Train Epoch: 40 [12800/50000 (26%)]	Loss: 19.358665
Downstream Train Epoch: 40 [25600/50000 (51%)]	Loss: 16.848495
Downstream Train Epoch: 40 [38400/50000 (77%)]	Loss: 19.595167

 Downstream Train loss: 20.674095547929102 Acc: 0.3984
Downstream Train Epoch: 41 [0/50000 (0%)]	Loss: 31.213764
Downstream Train Epoch: 41 [12800/50000 (26%)]	Loss: 32.446594
Downstream Train Epoch: 41 [25600/50000 (51%)]	Loss: 16.629362
Downstream Train Epoch: 41 [38400/50000 (77%)]	Loss: 15.633982

 Downstream Train loss: 18.718841479749095 Acc: 0.3984
Downstream Train Epoch: 42 [0/50000 (0%)]	Loss: 25.821301
Downstream Train Epoch: 42 [12800/50000 (26%)]	Loss: 16.540215
Downstream Train Epoch: 42 [25600/50000 (51%)]	Loss: 28.476767
Downstream Train Epoch: 42 [38400/50000 (77%)]	Loss: 29.304455

 Downstream Train loss: 21.16765935080392 Acc: 0.3984
Downstream Train Epoch: 43 [0/50000 (0%)]	Loss: 19.273342
Downstream Train Epoch: 43 [12800/50000 (26%)]	Loss: 22.469751
Downstream Train Epoch: 43 [25600/50000 (51%)]	Loss: 13.848844
Downstream Train Epoch: 43 [38400/50000 (77%)]	Loss: 17.427593

 Downstream Train loss: 20.26018287697617 Acc: 0.3984
Downstream Train Epoch: 44 [0/50000 (0%)]	Loss: 19.647532
Downstream Train Epoch: 44 [12800/50000 (26%)]	Loss: 21.907207
Downstream Train Epoch: 44 [25600/50000 (51%)]	Loss: 33.420612
Downstream Train Epoch: 44 [38400/50000 (77%)]	Loss: 15.718578

 Downstream Train loss: 19.32293999438383 Acc: 0.3984
Downstream Train Epoch: 45 [0/50000 (0%)]	Loss: 24.971521
Downstream Train Epoch: 45 [12800/50000 (26%)]	Loss: 11.580435
Downstream Train Epoch: 45 [25600/50000 (51%)]	Loss: 18.789881
Downstream Train Epoch: 45 [38400/50000 (77%)]	Loss: 12.293073

 Downstream Train loss: 19.165080537601394 Acc: 0.3984
Downstream Train Epoch: 46 [0/50000 (0%)]	Loss: 20.594776
Downstream Train Epoch: 46 [12800/50000 (26%)]	Loss: 22.134815
Downstream Train Epoch: 46 [25600/50000 (51%)]	Loss: 23.511459
Downstream Train Epoch: 46 [38400/50000 (77%)]	Loss: 17.833836

 Downstream Train loss: 20.546800443104335 Acc: 0.3984
Downstream Train Epoch: 47 [0/50000 (0%)]	Loss: 21.046600
Downstream Train Epoch: 47 [12800/50000 (26%)]	Loss: 12.824360
Downstream Train Epoch: 47 [25600/50000 (51%)]	Loss: 13.645093
Downstream Train Epoch: 47 [38400/50000 (77%)]	Loss: 14.958815

 Downstream Train loss: 20.0531907422202 Acc: 0.3984
Downstream Train Epoch: 48 [0/50000 (0%)]	Loss: 12.390421
Downstream Train Epoch: 48 [12800/50000 (26%)]	Loss: 13.885509
Downstream Train Epoch: 48 [25600/50000 (51%)]	Loss: 17.887772
Downstream Train Epoch: 48 [38400/50000 (77%)]	Loss: 26.446163

 Downstream Train loss: 18.748738639208735 Acc: 0.3984
Downstream Train Epoch: 49 [0/50000 (0%)]	Loss: 18.884586
Downstream Train Epoch: 49 [12800/50000 (26%)]	Loss: 18.508362
Downstream Train Epoch: 49 [25600/50000 (51%)]	Loss: 13.300213
Downstream Train Epoch: 49 [38400/50000 (77%)]	Loss: 31.741978

 Downstream Train loss: 19.525762499595174 Acc: 0.3984
Downstream Train Epoch: 50 [0/50000 (0%)]	Loss: 33.331078
Downstream Train Epoch: 50 [12800/50000 (26%)]	Loss: 22.244417
Downstream Train Epoch: 50 [25600/50000 (51%)]	Loss: 16.063757
Downstream Train Epoch: 50 [38400/50000 (77%)]	Loss: 12.600085

 Downstream Train loss: 19.31619523496044 Acc: 0.3984
Downstream Train Epoch: 51 [0/50000 (0%)]	Loss: 26.624430
Downstream Train Epoch: 51 [12800/50000 (26%)]	Loss: 15.511223
Downstream Train Epoch: 51 [25600/50000 (51%)]	Loss: 11.378462
Downstream Train Epoch: 51 [38400/50000 (77%)]	Loss: 18.446081

 Downstream Train loss: 18.09079025229629 Acc: 0.3984
Downstream Train Epoch: 52 [0/50000 (0%)]	Loss: 21.655516
Downstream Train Epoch: 52 [12800/50000 (26%)]	Loss: 23.382137
Downstream Train Epoch: 52 [25600/50000 (51%)]	Loss: 28.291193
Downstream Train Epoch: 52 [38400/50000 (77%)]	Loss: 17.082510

 Downstream Train loss: 20.9862652214206 Acc: 0.3984
Downstream Train Epoch: 53 [0/50000 (0%)]	Loss: 14.851347
Downstream Train Epoch: 53 [12800/50000 (26%)]	Loss: 18.376398
Downstream Train Epoch: 53 [25600/50000 (51%)]	Loss: 18.214329
Downstream Train Epoch: 53 [38400/50000 (77%)]	Loss: 21.463385

 Downstream Train loss: 21.00941640990121 Acc: 0.4016
Downstream Train Epoch: 54 [0/50000 (0%)]	Loss: 13.441279
Downstream Train Epoch: 54 [12800/50000 (26%)]	Loss: 13.243380
Downstream Train Epoch: 54 [25600/50000 (51%)]	Loss: 28.987684
Downstream Train Epoch: 54 [38400/50000 (77%)]	Loss: 20.418793

 Downstream Train loss: 21.334981353915467 Acc: 0.4016
Downstream Train Epoch: 55 [0/50000 (0%)]	Loss: 23.439871
Downstream Train Epoch: 55 [12800/50000 (26%)]	Loss: 20.763206
Downstream Train Epoch: 55 [25600/50000 (51%)]	Loss: 23.320148
Downstream Train Epoch: 55 [38400/50000 (77%)]	Loss: 23.365850

 Downstream Train loss: 22.21266629744549 Acc: 0.4016
Downstream Train Epoch: 56 [0/50000 (0%)]	Loss: 22.546881
Downstream Train Epoch: 56 [12800/50000 (26%)]	Loss: 16.040827
Downstream Train Epoch: 56 [25600/50000 (51%)]	Loss: 15.037507
Downstream Train Epoch: 56 [38400/50000 (77%)]	Loss: 19.705009

 Downstream Train loss: 16.38765168676571 Acc: 0.4016
Downstream Train Epoch: 57 [0/50000 (0%)]	Loss: 13.642303
Downstream Train Epoch: 57 [12800/50000 (26%)]	Loss: 18.360611
Downstream Train Epoch: 57 [25600/50000 (51%)]	Loss: 13.426577
Downstream Train Epoch: 57 [38400/50000 (77%)]	Loss: 16.242489

 Downstream Train loss: 19.600113562175206 Acc: 0.4016
Downstream Train Epoch: 58 [0/50000 (0%)]	Loss: 20.635010
Downstream Train Epoch: 58 [12800/50000 (26%)]	Loss: 16.887409
Downstream Train Epoch: 58 [25600/50000 (51%)]	Loss: 18.193373
Downstream Train Epoch: 58 [38400/50000 (77%)]	Loss: 17.342894

 Downstream Train loss: 19.29766508024566 Acc: 0.4016
Downstream Train Epoch: 59 [0/50000 (0%)]	Loss: 26.321611
Downstream Train Epoch: 59 [12800/50000 (26%)]	Loss: 18.367111
Downstream Train Epoch: 59 [25600/50000 (51%)]	Loss: 20.161415
Downstream Train Epoch: 59 [38400/50000 (77%)]	Loss: 22.445660

 Downstream Train loss: 19.032509852428827 Acc: 0.4016
Downstream Train Epoch: 60 [0/50000 (0%)]	Loss: 25.899303
Downstream Train Epoch: 60 [12800/50000 (26%)]	Loss: 24.065552
Downstream Train Epoch: 60 [25600/50000 (51%)]	Loss: 25.523296
Downstream Train Epoch: 60 [38400/50000 (77%)]	Loss: 29.164461

 Downstream Train loss: 20.284590954683264 Acc: 0.4016
Classifier Accuracy for user 4 is 0.4016
Training a classifier on the federated global model
 
 Results after 30 global rounds of training:
|----Average Classifier Test Accuracy for 5 agents is: 40.84%

 Total Run Time: 3043.8716
Namespace(exact_diffusion=True, decentralized=True, edge_prob=1.0, epochs=30, num_users=5, frac=1.0, local_ep=5.0, local_bs=256, lr=0.001, momentum=0.9, num_workers=16, model='resnet', batch_size=256, weight_decay=0.0005, dataset='mnist', backbone='resnet18', num_classes=10, gpu='0', optimizer='adam', save_name_suffix='', iid=1, verbose=0, seed=1, feature_dim=128, temperature=0.5, k=200, ssl_method='simclr', x_noniid=False, dirichlet=False, test_intermediate=False, dir_beta=0.5, imagenet_based_cluster=False, y_partition=False, log_file_name='skew_ssl_comm', num_clusters=1, imagenet100=False, y_partition_skew=True, y_partition_ratio=0.0, x_shift_dirichlet=False, reg_scale=1, load_pretrained_path='', full_size=False, local_rank=0, distributed_training=False, log_directory='comm_scripts', emd=0, dist_url='env://', average_without_bn=False, model_continue_training=0, finetuning_epoch=60, script_name='', x_shift_skew=False, load_dataset_to_memory=False, model_time='05-18_17:09_4152430', start_time=datetime.datetime(2024, 5, 18, 17, 9, 29, 701862))
dec_True_ED_True_a_5_resnet_256_30__dec_ssl_simclr
writing best results for dec_True_ED_True_a_5_resnet_256_30__dec_ssl_simclr___mnist_acc_0.40842_num of user_5_frac_1.0_epoch_30_local_ep_5.0_local_bs_256_lr_0.001_backbone_resnet18_dirichlet False_0.5_imagenet_based_cluster_False_partition_skew_True_partition_skew_ratio_0.0_iid_1_reg scale_1_cont opt_0_05-18_17:09_4152430_elapsed_time_3040: 0.40842 !
Job outputs are saved in results/05-18_17:08_iid_dec-true_ED-true_ep1_e30_le5_a5
