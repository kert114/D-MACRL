
Experimental details:
    Model     : resnet
    Optimizer : adam
    Learning  : 0.001
    Global Rounds   : 30

    Fraction of users  : 1.0
    Local Batch size   : 256
    Local Epochs       : 5.0

Running model  iid_dec-True_ED-True_pe1.0_a5_e30_le5.0
device:  cuda
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 2.783
Y partition skewness sampling
partition skew: 5 1.0 
10000 10000 0
len of skewed: 50000 len of unskewed: 0 data_num_per_user_skew: 10000
10000 5000 10000
partition skew: 5 1.0 
2000 2000 0
len of skewed: 10000 len of unskewed: 0 data_num_per_user_skew: 2000
2000 1000 2000
sample dataset time: 0.009
user data samples: [10000, 10000, 10000, 10000, 10000]
Namespace(exact_diffusion=True, decentralized=True, edge_prob=1.0, epochs=30, num_users=5, frac=1.0, local_ep=5.0, local_bs=256, lr=0.001, momentum=0.9, num_workers=16, model='resnet', batch_size=256, weight_decay=0.0005, dataset='mnist', backbone='resnet18', num_classes=10, gpu='0', optimizer='adam', save_name_suffix='', iid=0, verbose=0, seed=1, feature_dim=128, temperature=0.5, k=200, ssl_method='simclr', x_noniid=False, dirichlet=False, test_intermediate=False, dir_beta=0.5, imagenet_based_cluster=False, y_partition=False, log_file_name='results/05-17_20:08_testingphi_iid_dec-true_ED-true_ep1_e30_le5_a5/skew_ssl_comm', num_clusters=1, imagenet100=False, y_partition_skew=True, y_partition_ratio=0.0, x_shift_dirichlet=False, reg_scale=1, load_pretrained_path='', full_size=False, local_rank=0, distributed_training=False, log_directory='results/05-17_20:08_testingphi_iid_dec-true_ED-true_ep1_e30_le5_a5', emd=0, dist_url='env://', average_without_bn=False, model_continue_training=0, finetuning_epoch=60, script_name='', x_shift_skew=False, load_dataset_to_memory=False)
output model: save/05-17_20:09_2267728iid_dec-True_ED-True_pe1.0_a5_e30_le5.0
number of users per round: 5
total number of rounds: 6
Training uses 0.8 andd validation 0.8 of the dataset
Training uses 0.8 andd validation 0.8 of the dataset
Training uses 0.8 andd validation 0.8 of the dataset
Training uses 0.8 andd validation 0.8 of the dataset
Training uses 0.8 andd validation 0.8 of the dataset
matrix C  [[1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]]
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
matrix A  [[0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]]
Createda a Communication graph with edges = :  [(0, 1), (0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]
Number of edges:  10
Graph nodes:  [0, 1, 2, 3, 4]
matrix C  [[1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]]
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
5.0
matrix A  [[0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]]
Combination matrix A:  [[0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]]

 | Global Training Round : 1 | Model : 05-17_20:09_2267728

Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 0.0 | [0/8000 (0%)]	Loss: 6.134717                         LR: 0.0010  Feat: 0.743 Epoch Time: 9.577 Model Time: 8.944 Data Time: 0.633 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 0.0 | [2560/8000 (32%)]	Loss: 5.615620                         LR: 0.0010  Feat: 0.921 Epoch Time: 11.076 Model Time: 0.055 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 0.0 | [5120/8000 (65%)]	Loss: 5.571568                         LR: 0.0010  Feat: 0.928 Epoch Time: 12.548 Model Time: 0.052 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 0.0 | [7680/8000 (97%)]	Loss: 5.513326                         LR: 0.0010  Feat: 0.937 Epoch Time: 14.019 Model Time: 0.052 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 1.0 | [0/8000 (0%)]	Loss: 5.562386                         LR: 0.0010  Feat: 0.941 Epoch Time: 15.010 Model Time: 0.060 Data Time: 0.801 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 1.0 | [2560/8000 (32%)]	Loss: 5.510137                         LR: 0.0010  Feat: 0.962 Epoch Time: 16.484 Model Time: 0.052 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 1.0 | [5120/8000 (65%)]	Loss: 5.415465                         LR: 0.0010  Feat: 0.974 Epoch Time: 17.959 Model Time: 0.052 Data Time: 0.094 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 1.0 | [7680/8000 (97%)]	Loss: 5.443052                         LR: 0.0010  Feat: 0.957 Epoch Time: 19.451 Model Time: 0.054 Data Time: 0.094 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 2.0 | [0/8000 (0%)]	Loss: 5.395866                         LR: 0.0010  Feat: 0.963 Epoch Time: 20.437 Model Time: 0.062 Data Time: 0.773 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 2.0 | [2560/8000 (32%)]	Loss: 5.421920                         LR: 0.0010  Feat: 0.982 Epoch Time: 21.926 Model Time: 0.053 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 2.0 | [5120/8000 (65%)]	Loss: 5.365083                         LR: 0.0010  Feat: 0.995 Epoch Time: 23.418 Model Time: 0.053 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 2.0 | [7680/8000 (97%)]	Loss: 5.362741                         LR: 0.0010  Feat: 0.992 Epoch Time: 24.902 Model Time: 0.054 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 3.0 | [0/8000 (0%)]	Loss: 5.301169                         LR: 0.0010  Feat: 0.993 Epoch Time: 25.886 Model Time: 0.078 Data Time: 0.748 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 3.0 | [2560/8000 (32%)]	Loss: 5.300156                         LR: 0.0010  Feat: 0.984 Epoch Time: 27.381 Model Time: 0.054 Data Time: 0.087 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 3.0 | [5120/8000 (65%)]	Loss: 5.296146                         LR: 0.0010  Feat: 0.991 Epoch Time: 28.858 Model Time: 0.052 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 3.0 | [7680/8000 (97%)]	Loss: 5.313859                         LR: 0.0010  Feat: 0.994 Epoch Time: 30.340 Model Time: 0.052 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 4.0 | [0/8000 (0%)]	Loss: 5.265911                         LR: 0.0010  Feat: 0.995 Epoch Time: 31.326 Model Time: 0.061 Data Time: 0.777 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 4.0 | [2560/8000 (32%)]	Loss: 5.270505                         LR: 0.0010  Feat: 0.996 Epoch Time: 32.809 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 4.0 | [5120/8000 (65%)]	Loss: 5.236110                         LR: 0.0010  Feat: 0.994 Epoch Time: 34.292 Model Time: 0.052 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 0 | Local Epoch : 4.0 | [7680/8000 (97%)]	Loss: 5.213784                         LR: 0.0010  Feat: 0.998 Epoch Time: 35.781 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.001
Find_phi_psi for agent:  4
Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 0.0 | [0/8000 (0%)]	Loss: 6.180848                         LR: 0.0010  Feat: 0.761 Epoch Time: 0.973 Model Time: 0.063 Data Time: 0.820 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 0.0 | [2560/8000 (32%)]	Loss: 5.810781                         LR: 0.0010  Feat: 0.904 Epoch Time: 2.475 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 0.0 | [5120/8000 (65%)]	Loss: 5.660187                         LR: 0.0010  Feat: 0.931 Epoch Time: 3.979 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 0.0 | [7680/8000 (97%)]	Loss: 5.623207                         LR: 0.0010  Feat: 0.931 Epoch Time: 5.473 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 1.0 | [0/8000 (0%)]	Loss: 5.626917                         LR: 0.0010  Feat: 0.936 Epoch Time: 6.483 Model Time: 0.064 Data Time: 0.794 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 1.0 | [2560/8000 (32%)]	Loss: 5.586834                         LR: 0.0010  Feat: 0.948 Epoch Time: 7.979 Model Time: 0.055 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 1.0 | [5120/8000 (65%)]	Loss: 5.598794                         LR: 0.0010  Feat: 0.957 Epoch Time: 9.474 Model Time: 0.052 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 1.0 | [7680/8000 (97%)]	Loss: 5.438953                         LR: 0.0010  Feat: 0.960 Epoch Time: 10.957 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 2.0 | [0/8000 (0%)]	Loss: 5.495627                         LR: 0.0010  Feat: 0.959 Epoch Time: 11.913 Model Time: 0.056 Data Time: 0.745 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 2.0 | [2560/8000 (32%)]	Loss: 5.447755                         LR: 0.0010  Feat: 0.951 Epoch Time: 13.410 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 2.0 | [5120/8000 (65%)]	Loss: 5.477317                         LR: 0.0010  Feat: 0.965 Epoch Time: 14.907 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 2.0 | [7680/8000 (97%)]	Loss: 5.328092                         LR: 0.0010  Feat: 0.972 Epoch Time: 16.400 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 3.0 | [0/8000 (0%)]	Loss: 5.355517                         LR: 0.0010  Feat: 0.968 Epoch Time: 17.406 Model Time: 0.060 Data Time: 0.792 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 3.0 | [2560/8000 (32%)]	Loss: 5.359829                         LR: 0.0010  Feat: 0.967 Epoch Time: 18.914 Model Time: 0.055 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 3.0 | [5120/8000 (65%)]	Loss: 5.332546                         LR: 0.0010  Feat: 0.962 Epoch Time: 20.417 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 3.0 | [7680/8000 (97%)]	Loss: 5.413483                         LR: 0.0010  Feat: 0.976 Epoch Time: 21.916 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 4.0 | [0/8000 (0%)]	Loss: 5.298372                         LR: 0.0010  Feat: 0.975 Epoch Time: 22.939 Model Time: 0.059 Data Time: 0.799 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 4.0 | [2560/8000 (32%)]	Loss: 5.322805                         LR: 0.0010  Feat: 0.972 Epoch Time: 24.439 Model Time: 0.056 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 4.0 | [5120/8000 (65%)]	Loss: 5.348968                         LR: 0.0010  Feat: 0.972 Epoch Time: 25.938 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 0 | Local Epoch : 4.0 | [7680/8000 (97%)]	Loss: 5.322864                         LR: 0.0010  Feat: 0.976 Epoch Time: 27.439 Model Time: 0.060 Data Time: 0.101 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.001
Find_phi_psi for agent:  3
Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 0.0 | [0/8000 (0%)]	Loss: 6.129567                         LR: 0.0010  Feat: 0.746 Epoch Time: 0.886 Model Time: 0.059 Data Time: 0.735 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 0.0 | [2560/8000 (32%)]	Loss: 5.675696                         LR: 0.0010  Feat: 0.885 Epoch Time: 2.378 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 0.0 | [5120/8000 (65%)]	Loss: 5.590166                         LR: 0.0010  Feat: 0.940 Epoch Time: 3.872 Model Time: 0.065 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 0.0 | [7680/8000 (97%)]	Loss: 5.546480                         LR: 0.0010  Feat: 0.944 Epoch Time: 5.365 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 1.0 | [0/8000 (0%)]	Loss: 5.512319                         LR: 0.0010  Feat: 0.943 Epoch Time: 6.312 Model Time: 0.058 Data Time: 0.741 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 1.0 | [2560/8000 (32%)]	Loss: 5.369878                         LR: 0.0010  Feat: 0.960 Epoch Time: 7.812 Model Time: 0.061 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 1.0 | [5120/8000 (65%)]	Loss: 5.485695                         LR: 0.0010  Feat: 0.979 Epoch Time: 9.312 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 1.0 | [7680/8000 (97%)]	Loss: 5.393773                         LR: 0.0010  Feat: 0.973 Epoch Time: 10.812 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 2.0 | [0/8000 (0%)]	Loss: 5.372287                         LR: 0.0010  Feat: 0.967 Epoch Time: 11.833 Model Time: 0.061 Data Time: 0.798 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 2.0 | [2560/8000 (32%)]	Loss: 5.235733                         LR: 0.0010  Feat: 0.980 Epoch Time: 13.333 Model Time: 0.053 Data Time: 0.091 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 2.0 | [5120/8000 (65%)]	Loss: 5.304306                         LR: 0.0010  Feat: 0.986 Epoch Time: 14.834 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 2.0 | [7680/8000 (97%)]	Loss: 5.355543                         LR: 0.0010  Feat: 0.980 Epoch Time: 16.332 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 3.0 | [0/8000 (0%)]	Loss: 5.275572                         LR: 0.0010  Feat: 0.981 Epoch Time: 17.320 Model Time: 0.054 Data Time: 0.781 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 3.0 | [2560/8000 (32%)]	Loss: 5.324093                         LR: 0.0010  Feat: 0.992 Epoch Time: 18.813 Model Time: 0.051 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 3.0 | [5120/8000 (65%)]	Loss: 5.292327                         LR: 0.0010  Feat: 0.990 Epoch Time: 20.307 Model Time: 0.051 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 3.0 | [7680/8000 (97%)]	Loss: 5.271186                         LR: 0.0010  Feat: 0.995 Epoch Time: 21.796 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 4.0 | [0/8000 (0%)]	Loss: 5.275704                         LR: 0.0010  Feat: 0.994 Epoch Time: 22.746 Model Time: 0.066 Data Time: 0.742 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 4.0 | [2560/8000 (32%)]	Loss: 5.196904                         LR: 0.0010  Feat: 0.991 Epoch Time: 24.244 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 4.0 | [5120/8000 (65%)]	Loss: 5.204375                         LR: 0.0010  Feat: 0.985 Epoch Time: 25.748 Model Time: 0.063 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 0 | Local Epoch : 4.0 | [7680/8000 (97%)]	Loss: 5.195180                         LR: 0.0010  Feat: 0.985 Epoch Time: 27.251 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.001
Find_phi_psi for agent:  0
Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 0.0 | [0/8000 (0%)]	Loss: 6.144423                         LR: 0.0010  Feat: 0.750 Epoch Time: 0.969 Model Time: 0.060 Data Time: 0.816 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 0.0 | [2560/8000 (32%)]	Loss: 5.735847                         LR: 0.0010  Feat: 0.890 Epoch Time: 2.468 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 0.0 | [5120/8000 (65%)]	Loss: 5.560813                         LR: 0.0010  Feat: 0.897 Epoch Time: 3.966 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 0.0 | [7680/8000 (97%)]	Loss: 5.531793                         LR: 0.0010  Feat: 0.942 Epoch Time: 5.464 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 1.0 | [0/8000 (0%)]	Loss: 5.584875                         LR: 0.0010  Feat: 0.935 Epoch Time: 6.467 Model Time: 0.056 Data Time: 0.799 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 1.0 | [2560/8000 (32%)]	Loss: 5.498693                         LR: 0.0010  Feat: 0.964 Epoch Time: 7.959 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 1.0 | [5120/8000 (65%)]	Loss: 5.454636                         LR: 0.0010  Feat: 0.970 Epoch Time: 9.453 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 1.0 | [7680/8000 (97%)]	Loss: 5.332057                         LR: 0.0010  Feat: 0.969 Epoch Time: 10.946 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 2.0 | [0/8000 (0%)]	Loss: 5.472888                         LR: 0.0010  Feat: 0.967 Epoch Time: 11.892 Model Time: 0.060 Data Time: 0.739 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 2.0 | [2560/8000 (32%)]	Loss: 5.427631                         LR: 0.0010  Feat: 0.968 Epoch Time: 13.389 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 2.0 | [5120/8000 (65%)]	Loss: 5.351602                         LR: 0.0010  Feat: 0.983 Epoch Time: 14.890 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 2.0 | [7680/8000 (97%)]	Loss: 5.373054                         LR: 0.0010  Feat: 0.976 Epoch Time: 16.397 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 3.0 | [0/8000 (0%)]	Loss: 5.438882                         LR: 0.0010  Feat: 0.972 Epoch Time: 17.382 Model Time: 0.056 Data Time: 0.779 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 3.0 | [2560/8000 (32%)]	Loss: 5.410478                         LR: 0.0010  Feat: 0.982 Epoch Time: 18.882 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 3.0 | [5120/8000 (65%)]	Loss: 5.346942                         LR: 0.0010  Feat: 0.983 Epoch Time: 20.389 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 3.0 | [7680/8000 (97%)]	Loss: 5.304907                         LR: 0.0010  Feat: 0.975 Epoch Time: 21.890 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 4.0 | [0/8000 (0%)]	Loss: 5.336078                         LR: 0.0010  Feat: 0.978 Epoch Time: 22.877 Model Time: 0.060 Data Time: 0.781 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 4.0 | [2560/8000 (32%)]	Loss: 5.296541                         LR: 0.0010  Feat: 0.973 Epoch Time: 24.377 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 4.0 | [5120/8000 (65%)]	Loss: 5.317352                         LR: 0.0010  Feat: 0.984 Epoch Time: 25.880 Model Time: 0.054 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 0 | Local Epoch : 4.0 | [7680/8000 (97%)]	Loss: 5.302178                         LR: 0.0010  Feat: 0.966 Epoch Time: 27.379 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.001
Find_phi_psi for agent:  1
Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 0.0 | [0/8000 (0%)]	Loss: 6.137736                         LR: 0.0010  Feat: 0.745 Epoch Time: 0.903 Model Time: 0.063 Data Time: 0.750 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 0.0 | [2560/8000 (32%)]	Loss: 5.662101                         LR: 0.0010  Feat: 0.847 Epoch Time: 2.414 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 0.0 | [5120/8000 (65%)]	Loss: 5.636525                         LR: 0.0010  Feat: 0.931 Epoch Time: 3.910 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 0.0 | [7680/8000 (97%)]	Loss: 5.521441                         LR: 0.0010  Feat: 0.948 Epoch Time: 5.408 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 1.0 | [0/8000 (0%)]	Loss: 5.554771                         LR: 0.0010  Feat: 0.951 Epoch Time: 6.451 Model Time: 0.056 Data Time: 0.840 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 1.0 | [2560/8000 (32%)]	Loss: 5.492470                         LR: 0.0010  Feat: 0.954 Epoch Time: 7.958 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 1.0 | [5120/8000 (65%)]	Loss: 5.566981                         LR: 0.0010  Feat: 0.952 Epoch Time: 9.467 Model Time: 0.060 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 1.0 | [7680/8000 (97%)]	Loss: 5.473423                         LR: 0.0010  Feat: 0.963 Epoch Time: 10.974 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 2.0 | [0/8000 (0%)]	Loss: 5.505141                         LR: 0.0010  Feat: 0.952 Epoch Time: 11.992 Model Time: 0.063 Data Time: 0.807 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 2.0 | [2560/8000 (32%)]	Loss: 5.435420                         LR: 0.0010  Feat: 0.954 Epoch Time: 13.502 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 2.0 | [5120/8000 (65%)]	Loss: 5.447215                         LR: 0.0010  Feat: 0.971 Epoch Time: 15.002 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 2.0 | [7680/8000 (97%)]	Loss: 5.407966                         LR: 0.0010  Feat: 0.968 Epoch Time: 16.500 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 3.0 | [0/8000 (0%)]	Loss: 5.428791                         LR: 0.0010  Feat: 0.970 Epoch Time: 17.456 Model Time: 0.055 Data Time: 0.753 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 3.0 | [2560/8000 (32%)]	Loss: 5.440571                         LR: 0.0010  Feat: 0.971 Epoch Time: 18.956 Model Time: 0.051 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 3.0 | [5120/8000 (65%)]	Loss: 5.441594                         LR: 0.0010  Feat: 0.969 Epoch Time: 20.448 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 3.0 | [7680/8000 (97%)]	Loss: 5.455708                         LR: 0.0010  Feat: 0.974 Epoch Time: 21.948 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 4.0 | [0/8000 (0%)]	Loss: 5.322064                         LR: 0.0010  Feat: 0.971 Epoch Time: 23.005 Model Time: 0.060 Data Time: 0.846 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 4.0 | [2560/8000 (32%)]	Loss: 5.316747                         LR: 0.0010  Feat: 0.971 Epoch Time: 24.505 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 4.0 | [5120/8000 (65%)]	Loss: 5.338856                         LR: 0.0010  Feat: 0.978 Epoch Time: 26.003 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 0 | Local Epoch : 4.0 | [7680/8000 (97%)]	Loss: 5.295582                         LR: 0.0010  Feat: 0.978 Epoch Time: 27.506 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.001
Find_phi_psi for agent:  2
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked

 | Global Training Round : 2 | Model : 05-17_20:09_2267728

Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 5.0 | [0/8000 (0%)]	Loss: 5.367576                         LR: 0.0003  Feat: 3.035 Epoch Time: 0.944 Model Time: 0.065 Data Time: 0.789 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 5.0 | [2560/8000 (32%)]	Loss: 5.251803                         LR: 0.0003  Feat: 2.992 Epoch Time: 2.461 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 5.0 | [5120/8000 (65%)]	Loss: 5.213575                         LR: 0.0003  Feat: 2.986 Epoch Time: 3.962 Model Time: 0.054 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 5.0 | [7680/8000 (97%)]	Loss: 5.258340                         LR: 0.0003  Feat: 2.984 Epoch Time: 5.456 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 6.0 | [0/8000 (0%)]	Loss: 5.214789                         LR: 0.0003  Feat: 2.984 Epoch Time: 6.435 Model Time: 0.057 Data Time: 0.763 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 6.0 | [2560/8000 (32%)]	Loss: 5.153104                         LR: 0.0003  Feat: 2.976 Epoch Time: 7.930 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 6.0 | [5120/8000 (65%)]	Loss: 5.282913                         LR: 0.0003  Feat: 2.967 Epoch Time: 9.426 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 6.0 | [7680/8000 (97%)]	Loss: 5.114270                         LR: 0.0003  Feat: 2.966 Epoch Time: 10.927 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 7.0 | [0/8000 (0%)]	Loss: 5.173431                         LR: 0.0003  Feat: 2.967 Epoch Time: 11.958 Model Time: 0.061 Data Time: 0.807 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 7.0 | [2560/8000 (32%)]	Loss: 5.175589                         LR: 0.0003  Feat: 2.974 Epoch Time: 13.471 Model Time: 0.056 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 7.0 | [5120/8000 (65%)]	Loss: 5.205755                         LR: 0.0003  Feat: 2.966 Epoch Time: 14.982 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 7.0 | [7680/8000 (97%)]	Loss: 5.157768                         LR: 0.0003  Feat: 2.961 Epoch Time: 16.493 Model Time: 0.054 Data Time: 0.091 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 8.0 | [0/8000 (0%)]	Loss: 5.144794                         LR: 0.0003  Feat: 2.964 Epoch Time: 17.525 Model Time: 0.065 Data Time: 0.819 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 8.0 | [2560/8000 (32%)]	Loss: 5.128605                         LR: 0.0003  Feat: 2.962 Epoch Time: 19.041 Model Time: 0.055 Data Time: 0.090 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 8.0 | [5120/8000 (65%)]	Loss: 5.124071                         LR: 0.0003  Feat: 2.958 Epoch Time: 20.549 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 8.0 | [7680/8000 (97%)]	Loss: 5.161844                         LR: 0.0003  Feat: 2.957 Epoch Time: 22.053 Model Time: 0.054 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 9.0 | [0/8000 (0%)]	Loss: 5.156044                         LR: 0.0003  Feat: 2.960 Epoch Time: 23.082 Model Time: 0.062 Data Time: 0.815 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 9.0 | [2560/8000 (32%)]	Loss: 5.130070                         LR: 0.0003  Feat: 2.956 Epoch Time: 24.588 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 9.0 | [5120/8000 (65%)]	Loss: 5.104083                         LR: 0.0003  Feat: 2.955 Epoch Time: 26.093 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 1 | Local Epoch : 9.0 | [7680/8000 (97%)]	Loss: 5.129318                         LR: 0.0003  Feat: 2.949 Epoch Time: 27.599 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  4
Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 5.0 | [0/8000 (0%)]	Loss: 5.261117                         LR: 0.0003  Feat: 1.966 Epoch Time: 0.948 Model Time: 0.066 Data Time: 0.794 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 5.0 | [2560/8000 (32%)]	Loss: 5.233920                         LR: 0.0003  Feat: 1.958 Epoch Time: 2.468 Model Time: 0.054 Data Time: 0.091 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 5.0 | [5120/8000 (65%)]	Loss: 5.240092                         LR: 0.0003  Feat: 1.954 Epoch Time: 3.969 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 5.0 | [7680/8000 (97%)]	Loss: 5.183786                         LR: 0.0003  Feat: 1.951 Epoch Time: 5.468 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 6.0 | [0/8000 (0%)]	Loss: 5.184559                         LR: 0.0003  Feat: 1.951 Epoch Time: 6.439 Model Time: 0.055 Data Time: 0.763 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 6.0 | [2560/8000 (32%)]	Loss: 5.211003                         LR: 0.0003  Feat: 1.950 Epoch Time: 7.948 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 6.0 | [5120/8000 (65%)]	Loss: 5.179281                         LR: 0.0003  Feat: 1.951 Epoch Time: 9.447 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 6.0 | [7680/8000 (97%)]	Loss: 5.121351                         LR: 0.0003  Feat: 1.948 Epoch Time: 10.951 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 7.0 | [0/8000 (0%)]	Loss: 5.029469                         LR: 0.0003  Feat: 1.946 Epoch Time: 11.910 Model Time: 0.058 Data Time: 0.748 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 7.0 | [2560/8000 (32%)]	Loss: 5.138217                         LR: 0.0003  Feat: 1.945 Epoch Time: 13.411 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 7.0 | [5120/8000 (65%)]	Loss: 5.192922                         LR: 0.0003  Feat: 1.942 Epoch Time: 14.911 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 7.0 | [7680/8000 (97%)]	Loss: 5.156697                         LR: 0.0003  Feat: 1.932 Epoch Time: 16.410 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 8.0 | [0/8000 (0%)]	Loss: 5.112303                         LR: 0.0003  Feat: 1.941 Epoch Time: 17.652 Model Time: 0.054 Data Time: 1.039 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 8.0 | [2560/8000 (32%)]	Loss: 5.108896                         LR: 0.0003  Feat: 1.939 Epoch Time: 19.146 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 8.0 | [5120/8000 (65%)]	Loss: 5.075600                         LR: 0.0003  Feat: 1.939 Epoch Time: 20.645 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 8.0 | [7680/8000 (97%)]	Loss: 5.140355                         LR: 0.0003  Feat: 1.938 Epoch Time: 22.147 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 9.0 | [0/8000 (0%)]	Loss: 5.101093                         LR: 0.0003  Feat: 1.945 Epoch Time: 23.200 Model Time: 0.064 Data Time: 0.830 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 9.0 | [2560/8000 (32%)]	Loss: 5.101995                         LR: 0.0003  Feat: 1.933 Epoch Time: 24.706 Model Time: 0.054 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 9.0 | [5120/8000 (65%)]	Loss: 5.094140                         LR: 0.0003  Feat: 1.936 Epoch Time: 26.210 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 1 | Local Epoch : 9.0 | [7680/8000 (97%)]	Loss: 5.076741                         LR: 0.0003  Feat: 1.932 Epoch Time: 27.713 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  0
Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 5.0 | [0/8000 (0%)]	Loss: 5.411296                         LR: 0.0003  Feat: 2.644 Epoch Time: 0.945 Model Time: 0.058 Data Time: 0.793 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 5.0 | [2560/8000 (32%)]	Loss: 5.323503                         LR: 0.0003  Feat: 2.619 Epoch Time: 2.441 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 5.0 | [5120/8000 (65%)]	Loss: 5.236504                         LR: 0.0003  Feat: 2.596 Epoch Time: 3.933 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 5.0 | [7680/8000 (97%)]	Loss: 5.277658                         LR: 0.0003  Feat: 2.605 Epoch Time: 5.429 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 6.0 | [0/8000 (0%)]	Loss: 5.238951                         LR: 0.0003  Feat: 2.601 Epoch Time: 6.390 Model Time: 0.059 Data Time: 0.748 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 6.0 | [2560/8000 (32%)]	Loss: 5.227031                         LR: 0.0003  Feat: 2.600 Epoch Time: 7.887 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 6.0 | [5120/8000 (65%)]	Loss: 5.267758                         LR: 0.0003  Feat: 2.593 Epoch Time: 9.384 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 6.0 | [7680/8000 (97%)]	Loss: 5.205114                         LR: 0.0003  Feat: 2.597 Epoch Time: 10.886 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 7.0 | [0/8000 (0%)]	Loss: 5.250604                         LR: 0.0003  Feat: 2.601 Epoch Time: 11.864 Model Time: 0.059 Data Time: 0.772 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 7.0 | [2560/8000 (32%)]	Loss: 5.143481                         LR: 0.0003  Feat: 2.600 Epoch Time: 13.363 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 7.0 | [5120/8000 (65%)]	Loss: 5.225086                         LR: 0.0003  Feat: 2.595 Epoch Time: 14.861 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 7.0 | [7680/8000 (97%)]	Loss: 5.245063                         LR: 0.0003  Feat: 2.590 Epoch Time: 16.359 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 8.0 | [0/8000 (0%)]	Loss: 5.206002                         LR: 0.0003  Feat: 2.587 Epoch Time: 17.382 Model Time: 0.066 Data Time: 0.795 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 8.0 | [2560/8000 (32%)]	Loss: 5.211282                         LR: 0.0003  Feat: 2.590 Epoch Time: 18.896 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 8.0 | [5120/8000 (65%)]	Loss: 5.191007                         LR: 0.0003  Feat: 2.587 Epoch Time: 20.393 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 8.0 | [7680/8000 (97%)]	Loss: 5.231768                         LR: 0.0003  Feat: 2.584 Epoch Time: 21.889 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 9.0 | [0/8000 (0%)]	Loss: 5.205688                         LR: 0.0003  Feat: 2.585 Epoch Time: 23.101 Model Time: 0.057 Data Time: 0.986 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 9.0 | [2560/8000 (32%)]	Loss: 5.160378                         LR: 0.0003  Feat: 2.582 Epoch Time: 24.599 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 9.0 | [5120/8000 (65%)]	Loss: 5.137537                         LR: 0.0003  Feat: 2.584 Epoch Time: 26.101 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 1 | Local Epoch : 9.0 | [7680/8000 (97%)]	Loss: 5.129085                         LR: 0.0003  Feat: 2.579 Epoch Time: 27.612 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  3
Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 5.0 | [0/8000 (0%)]	Loss: 5.407272                         LR: 0.0003  Feat: 2.157 Epoch Time: 0.982 Model Time: 0.068 Data Time: 0.828 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 5.0 | [2560/8000 (32%)]	Loss: 5.312295                         LR: 0.0003  Feat: 2.100 Epoch Time: 2.502 Model Time: 0.060 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 5.0 | [5120/8000 (65%)]	Loss: 5.211759                         LR: 0.0003  Feat: 2.130 Epoch Time: 4.012 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 5.0 | [7680/8000 (97%)]	Loss: 5.301861                         LR: 0.0003  Feat: 2.132 Epoch Time: 5.517 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 6.0 | [0/8000 (0%)]	Loss: 5.269708                         LR: 0.0003  Feat: 2.141 Epoch Time: 6.542 Model Time: 0.063 Data Time: 0.799 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 6.0 | [2560/8000 (32%)]	Loss: 5.213597                         LR: 0.0003  Feat: 2.116 Epoch Time: 8.053 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 6.0 | [5120/8000 (65%)]	Loss: 5.295598                         LR: 0.0003  Feat: 2.124 Epoch Time: 9.555 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 6.0 | [7680/8000 (97%)]	Loss: 5.188025                         LR: 0.0003  Feat: 2.130 Epoch Time: 11.057 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 7.0 | [0/8000 (0%)]	Loss: 5.242679                         LR: 0.0003  Feat: 2.129 Epoch Time: 12.082 Model Time: 0.058 Data Time: 0.808 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 7.0 | [2560/8000 (32%)]	Loss: 5.256787                         LR: 0.0003  Feat: 2.128 Epoch Time: 13.584 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 7.0 | [5120/8000 (65%)]	Loss: 5.247787                         LR: 0.0003  Feat: 2.126 Epoch Time: 15.089 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 7.0 | [7680/8000 (97%)]	Loss: 5.257044                         LR: 0.0003  Feat: 2.115 Epoch Time: 16.594 Model Time: 0.055 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 8.0 | [0/8000 (0%)]	Loss: 5.216262                         LR: 0.0003  Feat: 2.131 Epoch Time: 17.651 Model Time: 0.064 Data Time: 0.841 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 8.0 | [2560/8000 (32%)]	Loss: 5.170709                         LR: 0.0003  Feat: 2.114 Epoch Time: 19.158 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 8.0 | [5120/8000 (65%)]	Loss: 5.229421                         LR: 0.0003  Feat: 2.128 Epoch Time: 20.666 Model Time: 0.061 Data Time: 0.091 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 8.0 | [7680/8000 (97%)]	Loss: 5.221943                         LR: 0.0003  Feat: 2.118 Epoch Time: 22.176 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 9.0 | [0/8000 (0%)]	Loss: 5.222873                         LR: 0.0003  Feat: 2.130 Epoch Time: 23.174 Model Time: 0.059 Data Time: 0.781 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 9.0 | [2560/8000 (32%)]	Loss: 5.215625                         LR: 0.0003  Feat: 2.112 Epoch Time: 24.684 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 9.0 | [5120/8000 (65%)]	Loss: 5.200639                         LR: 0.0003  Feat: 2.111 Epoch Time: 26.190 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 1 | Local Epoch : 9.0 | [7680/8000 (97%)]	Loss: 5.141051                         LR: 0.0003  Feat: 2.123 Epoch Time: 27.685 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  1
Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 5.0 | [0/8000 (0%)]	Loss: 5.387293                         LR: 0.0003  Feat: 2.383 Epoch Time: 0.892 Model Time: 0.058 Data Time: 0.739 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 5.0 | [2560/8000 (32%)]	Loss: 5.298477                         LR: 0.0003  Feat: 2.347 Epoch Time: 2.394 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 5.0 | [5120/8000 (65%)]	Loss: 5.318912                         LR: 0.0003  Feat: 2.346 Epoch Time: 3.891 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 5.0 | [7680/8000 (97%)]	Loss: 5.283568                         LR: 0.0003  Feat: 2.347 Epoch Time: 5.388 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 6.0 | [0/8000 (0%)]	Loss: 5.250623                         LR: 0.0003  Feat: 2.346 Epoch Time: 6.386 Model Time: 0.067 Data Time: 0.778 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 6.0 | [2560/8000 (32%)]	Loss: 5.255655                         LR: 0.0003  Feat: 2.351 Epoch Time: 7.893 Model Time: 0.053 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 6.0 | [5120/8000 (65%)]	Loss: 5.274257                         LR: 0.0003  Feat: 2.346 Epoch Time: 9.399 Model Time: 0.060 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 6.0 | [7680/8000 (97%)]	Loss: 5.203172                         LR: 0.0003  Feat: 2.343 Epoch Time: 10.907 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 7.0 | [0/8000 (0%)]	Loss: 5.266855                         LR: 0.0003  Feat: 2.343 Epoch Time: 11.921 Model Time: 0.059 Data Time: 0.799 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 7.0 | [2560/8000 (32%)]	Loss: 5.168651                         LR: 0.0003  Feat: 2.346 Epoch Time: 13.434 Model Time: 0.058 Data Time: 0.100 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 7.0 | [5120/8000 (65%)]	Loss: 5.241805                         LR: 0.0003  Feat: 2.338 Epoch Time: 14.944 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 7.0 | [7680/8000 (97%)]	Loss: 5.211158                         LR: 0.0003  Feat: 2.343 Epoch Time: 16.450 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 8.0 | [0/8000 (0%)]	Loss: 5.232842                         LR: 0.0003  Feat: 2.335 Epoch Time: 17.417 Model Time: 0.059 Data Time: 0.759 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 8.0 | [2560/8000 (32%)]	Loss: 5.236251                         LR: 0.0003  Feat: 2.347 Epoch Time: 18.928 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 8.0 | [5120/8000 (65%)]	Loss: 5.198588                         LR: 0.0003  Feat: 2.343 Epoch Time: 20.442 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 8.0 | [7680/8000 (97%)]	Loss: 5.180344                         LR: 0.0003  Feat: 2.345 Epoch Time: 21.952 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 9.0 | [0/8000 (0%)]	Loss: 5.323600                         LR: 0.0003  Feat: 2.352 Epoch Time: 22.930 Model Time: 0.056 Data Time: 0.775 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 9.0 | [2560/8000 (32%)]	Loss: 5.241901                         LR: 0.0003  Feat: 2.350 Epoch Time: 24.454 Model Time: 0.056 Data Time: 0.091 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 9.0 | [5120/8000 (65%)]	Loss: 5.230307                         LR: 0.0003  Feat: 2.349 Epoch Time: 25.968 Model Time: 0.054 Data Time: 0.094 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 1 | Local Epoch : 9.0 | [7680/8000 (97%)]	Loss: 5.133119                         LR: 0.0003  Feat: 2.351 Epoch Time: 27.475 Model Time: 0.060 Data Time: 0.096 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  2
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked

 | Global Training Round : 3 | Model : 05-17_20:09_2267728

Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 10.0 | [0/8000 (0%)]	Loss: 5.395485                         LR: 0.0003  Feat: 6.637 Epoch Time: 0.932 Model Time: 0.065 Data Time: 0.778 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 10.0 | [2560/8000 (32%)]	Loss: 5.272842                         LR: 0.0003  Feat: 6.597 Epoch Time: 2.441 Model Time: 0.059 Data Time: 0.092 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 10.0 | [5120/8000 (65%)]	Loss: 5.226311                         LR: 0.0003  Feat: 6.568 Epoch Time: 3.942 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 10.0 | [7680/8000 (97%)]	Loss: 5.177756                         LR: 0.0003  Feat: 6.545 Epoch Time: 5.440 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 11.0 | [0/8000 (0%)]	Loss: 5.201902                         LR: 0.0003  Feat: 6.559 Epoch Time: 6.397 Model Time: 0.066 Data Time: 0.744 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 11.0 | [2560/8000 (32%)]	Loss: 5.188222                         LR: 0.0003  Feat: 6.552 Epoch Time: 7.892 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 11.0 | [5120/8000 (65%)]	Loss: 5.207624                         LR: 0.0003  Feat: 6.551 Epoch Time: 9.386 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 11.0 | [7680/8000 (97%)]	Loss: 5.142324                         LR: 0.0003  Feat: 6.536 Epoch Time: 10.885 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 12.0 | [0/8000 (0%)]	Loss: 5.172349                         LR: 0.0003  Feat: 6.539 Epoch Time: 11.866 Model Time: 0.056 Data Time: 0.773 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 12.0 | [2560/8000 (32%)]	Loss: 5.178347                         LR: 0.0003  Feat: 6.531 Epoch Time: 13.379 Model Time: 0.059 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 12.0 | [5120/8000 (65%)]	Loss: 5.196947                         LR: 0.0003  Feat: 6.538 Epoch Time: 14.881 Model Time: 0.054 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 12.0 | [7680/8000 (97%)]	Loss: 5.199894                         LR: 0.0003  Feat: 6.500 Epoch Time: 16.382 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 13.0 | [0/8000 (0%)]	Loss: 5.210878                         LR: 0.0003  Feat: 6.514 Epoch Time: 17.388 Model Time: 0.066 Data Time: 0.795 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 13.0 | [2560/8000 (32%)]	Loss: 5.203725                         LR: 0.0003  Feat: 6.525 Epoch Time: 18.890 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 13.0 | [5120/8000 (65%)]	Loss: 5.230894                         LR: 0.0003  Feat: 6.517 Epoch Time: 20.394 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 13.0 | [7680/8000 (97%)]	Loss: 5.174144                         LR: 0.0003  Feat: 6.497 Epoch Time: 21.901 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 14.0 | [0/8000 (0%)]	Loss: 5.172909                         LR: 0.0003  Feat: 6.489 Epoch Time: 22.932 Model Time: 0.056 Data Time: 0.808 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 14.0 | [2560/8000 (32%)]	Loss: 5.183041                         LR: 0.0003  Feat: 6.503 Epoch Time: 24.428 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 14.0 | [5120/8000 (65%)]	Loss: 5.176171                         LR: 0.0003  Feat: 6.507 Epoch Time: 25.922 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 2 | Local Epoch : 14.0 | [7680/8000 (97%)]	Loss: 5.156745                         LR: 0.0003  Feat: 6.496 Epoch Time: 27.420 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  3
Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 10.0 | [0/8000 (0%)]	Loss: 5.388020                         LR: 0.0003  Feat: 5.761 Epoch Time: 0.897 Model Time: 0.056 Data Time: 0.746 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 10.0 | [2560/8000 (32%)]	Loss: 5.241793                         LR: 0.0003  Feat: 5.730 Epoch Time: 2.393 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 10.0 | [5120/8000 (65%)]	Loss: 5.296298                         LR: 0.0003  Feat: 5.700 Epoch Time: 3.897 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 10.0 | [7680/8000 (97%)]	Loss: 5.228335                         LR: 0.0003  Feat: 5.705 Epoch Time: 5.394 Model Time: 0.055 Data Time: 0.094 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 11.0 | [0/8000 (0%)]	Loss: 5.216854                         LR: 0.0003  Feat: 5.694 Epoch Time: 6.371 Model Time: 0.054 Data Time: 0.772 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 11.0 | [2560/8000 (32%)]	Loss: 5.162014                         LR: 0.0003  Feat: 5.693 Epoch Time: 7.872 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 11.0 | [5120/8000 (65%)]	Loss: 5.176824                         LR: 0.0003  Feat: 5.684 Epoch Time: 9.376 Model Time: 0.052 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 11.0 | [7680/8000 (97%)]	Loss: 5.152368                         LR: 0.0003  Feat: 5.688 Epoch Time: 10.875 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 12.0 | [0/8000 (0%)]	Loss: 5.245820                         LR: 0.0003  Feat: 5.689 Epoch Time: 11.863 Model Time: 0.059 Data Time: 0.764 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 12.0 | [2560/8000 (32%)]	Loss: 5.207807                         LR: 0.0003  Feat: 5.685 Epoch Time: 13.359 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 12.0 | [5120/8000 (65%)]	Loss: 5.163911                         LR: 0.0003  Feat: 5.689 Epoch Time: 14.855 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 12.0 | [7680/8000 (97%)]	Loss: 5.208688                         LR: 0.0003  Feat: 5.662 Epoch Time: 16.353 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 13.0 | [0/8000 (0%)]	Loss: 5.187551                         LR: 0.0003  Feat: 5.673 Epoch Time: 17.294 Model Time: 0.056 Data Time: 0.734 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 13.0 | [2560/8000 (32%)]	Loss: 5.288733                         LR: 0.0003  Feat: 5.662 Epoch Time: 18.797 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 13.0 | [5120/8000 (65%)]	Loss: 5.239775                         LR: 0.0003  Feat: 5.660 Epoch Time: 20.299 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 13.0 | [7680/8000 (97%)]	Loss: 5.198318                         LR: 0.0003  Feat: 5.657 Epoch Time: 21.803 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 14.0 | [0/8000 (0%)]	Loss: 5.130564                         LR: 0.0003  Feat: 5.666 Epoch Time: 22.814 Model Time: 0.061 Data Time: 0.790 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 14.0 | [2560/8000 (32%)]	Loss: 5.128997                         LR: 0.0003  Feat: 5.662 Epoch Time: 24.326 Model Time: 0.055 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 14.0 | [5120/8000 (65%)]	Loss: 5.179596                         LR: 0.0003  Feat: 5.647 Epoch Time: 25.832 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 2 | Local Epoch : 14.0 | [7680/8000 (97%)]	Loss: 5.152503                         LR: 0.0003  Feat: 5.650 Epoch Time: 27.339 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  2
Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 10.0 | [0/8000 (0%)]	Loss: 5.282448                         LR: 0.0003  Feat: 4.988 Epoch Time: 1.000 Model Time: 0.060 Data Time: 0.847 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 10.0 | [2560/8000 (32%)]	Loss: 5.202296                         LR: 0.0003  Feat: 4.932 Epoch Time: 2.509 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 10.0 | [5120/8000 (65%)]	Loss: 5.211981                         LR: 0.0003  Feat: 4.923 Epoch Time: 4.015 Model Time: 0.054 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 10.0 | [7680/8000 (97%)]	Loss: 5.198612                         LR: 0.0003  Feat: 4.926 Epoch Time: 5.520 Model Time: 0.055 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 11.0 | [0/8000 (0%)]	Loss: 5.221581                         LR: 0.0003  Feat: 4.925 Epoch Time: 6.455 Model Time: 0.058 Data Time: 0.729 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 11.0 | [2560/8000 (32%)]	Loss: 5.207068                         LR: 0.0003  Feat: 4.918 Epoch Time: 7.963 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 11.0 | [5120/8000 (65%)]	Loss: 5.209691                         LR: 0.0003  Feat: 4.912 Epoch Time: 9.473 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 11.0 | [7680/8000 (97%)]	Loss: 5.177746                         LR: 0.0003  Feat: 4.892 Epoch Time: 10.978 Model Time: 0.057 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 12.0 | [0/8000 (0%)]	Loss: 5.216128                         LR: 0.0003  Feat: 4.883 Epoch Time: 12.029 Model Time: 0.060 Data Time: 0.835 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 12.0 | [2560/8000 (32%)]	Loss: 5.182688                         LR: 0.0003  Feat: 4.902 Epoch Time: 13.539 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 12.0 | [5120/8000 (65%)]	Loss: 5.227150                         LR: 0.0003  Feat: 4.905 Epoch Time: 15.046 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 12.0 | [7680/8000 (97%)]	Loss: 5.157389                         LR: 0.0003  Feat: 4.883 Epoch Time: 16.619 Model Time: 0.055 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 13.0 | [0/8000 (0%)]	Loss: 5.152705                         LR: 0.0003  Feat: 4.896 Epoch Time: 17.665 Model Time: 0.057 Data Time: 0.830 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 13.0 | [2560/8000 (32%)]	Loss: 5.216873                         LR: 0.0003  Feat: 4.907 Epoch Time: 19.174 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 13.0 | [5120/8000 (65%)]	Loss: 5.176927                         LR: 0.0003  Feat: 4.886 Epoch Time: 20.677 Model Time: 0.059 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 13.0 | [7680/8000 (97%)]	Loss: 5.160324                         LR: 0.0003  Feat: 4.889 Epoch Time: 22.177 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 14.0 | [0/8000 (0%)]	Loss: 5.189886                         LR: 0.0003  Feat: 4.890 Epoch Time: 23.118 Model Time: 0.060 Data Time: 0.735 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 14.0 | [2560/8000 (32%)]	Loss: 5.233953                         LR: 0.0003  Feat: 4.891 Epoch Time: 24.629 Model Time: 0.062 Data Time: 0.099 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 14.0 | [5120/8000 (65%)]	Loss: 5.188699                         LR: 0.0003  Feat: 4.877 Epoch Time: 26.139 Model Time: 0.054 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 2 | Local Epoch : 14.0 | [7680/8000 (97%)]	Loss: 5.148862                         LR: 0.0003  Feat: 4.866 Epoch Time: 27.642 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  1
Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 10.0 | [0/8000 (0%)]	Loss: 5.259148                         LR: 0.0003  Feat: 4.318 Epoch Time: 0.922 Model Time: 0.070 Data Time: 0.768 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 10.0 | [2560/8000 (32%)]	Loss: 5.162431                         LR: 0.0003  Feat: 4.288 Epoch Time: 2.432 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 10.0 | [5120/8000 (65%)]	Loss: 5.120513                         LR: 0.0003  Feat: 4.278 Epoch Time: 3.939 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 10.0 | [7680/8000 (97%)]	Loss: 5.146563                         LR: 0.0003  Feat: 4.251 Epoch Time: 5.450 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 11.0 | [0/8000 (0%)]	Loss: 5.155053                         LR: 0.0003  Feat: 4.267 Epoch Time: 6.454 Model Time: 0.058 Data Time: 0.796 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 11.0 | [2560/8000 (32%)]	Loss: 5.128260                         LR: 0.0003  Feat: 4.254 Epoch Time: 7.962 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 11.0 | [5120/8000 (65%)]	Loss: 5.126600                         LR: 0.0003  Feat: 4.266 Epoch Time: 9.473 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 11.0 | [7680/8000 (97%)]	Loss: 5.125302                         LR: 0.0003  Feat: 4.256 Epoch Time: 10.978 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 12.0 | [0/8000 (0%)]	Loss: 5.139518                         LR: 0.0003  Feat: 4.265 Epoch Time: 11.946 Model Time: 0.057 Data Time: 0.762 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 12.0 | [2560/8000 (32%)]	Loss: 5.085578                         LR: 0.0003  Feat: 4.267 Epoch Time: 13.451 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 12.0 | [5120/8000 (65%)]	Loss: 5.086605                         LR: 0.0003  Feat: 4.260 Epoch Time: 14.952 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 12.0 | [7680/8000 (97%)]	Loss: 5.092809                         LR: 0.0003  Feat: 4.248 Epoch Time: 16.450 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 13.0 | [0/8000 (0%)]	Loss: 5.128303                         LR: 0.0003  Feat: 4.245 Epoch Time: 17.498 Model Time: 0.059 Data Time: 0.843 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 13.0 | [2560/8000 (32%)]	Loss: 5.101634                         LR: 0.0003  Feat: 4.244 Epoch Time: 19.014 Model Time: 0.056 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 13.0 | [5120/8000 (65%)]	Loss: 5.071441                         LR: 0.0003  Feat: 4.247 Epoch Time: 20.527 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 13.0 | [7680/8000 (97%)]	Loss: 5.099141                         LR: 0.0003  Feat: 4.240 Epoch Time: 22.054 Model Time: 0.056 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 14.0 | [0/8000 (0%)]	Loss: 5.110532                         LR: 0.0003  Feat: 4.246 Epoch Time: 23.125 Model Time: 0.059 Data Time: 0.857 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 14.0 | [2560/8000 (32%)]	Loss: 5.084277                         LR: 0.0003  Feat: 4.252 Epoch Time: 24.629 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 14.0 | [5120/8000 (65%)]	Loss: 5.072165                         LR: 0.0003  Feat: 4.244 Epoch Time: 26.143 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 2 | Local Epoch : 14.0 | [7680/8000 (97%)]	Loss: 5.101452                         LR: 0.0003  Feat: 4.222 Epoch Time: 27.645 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  0
Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 10.0 | [0/8000 (0%)]	Loss: 5.320260                         LR: 0.0003  Feat: 7.882 Epoch Time: 0.918 Model Time: 0.062 Data Time: 0.765 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 10.0 | [2560/8000 (32%)]	Loss: 5.242902                         LR: 0.0003  Feat: 7.829 Epoch Time: 2.419 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 10.0 | [5120/8000 (65%)]	Loss: 5.212299                         LR: 0.0003  Feat: 7.817 Epoch Time: 3.921 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 10.0 | [7680/8000 (97%)]	Loss: 5.206384                         LR: 0.0003  Feat: 7.802 Epoch Time: 5.425 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 11.0 | [0/8000 (0%)]	Loss: 5.160072                         LR: 0.0003  Feat: 7.802 Epoch Time: 6.401 Model Time: 0.060 Data Time: 0.772 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 11.0 | [2560/8000 (32%)]	Loss: 5.235176                         LR: 0.0003  Feat: 7.797 Epoch Time: 7.912 Model Time: 0.056 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 11.0 | [5120/8000 (65%)]	Loss: 5.173643                         LR: 0.0003  Feat: 7.807 Epoch Time: 9.427 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 11.0 | [7680/8000 (97%)]	Loss: 5.146143                         LR: 0.0003  Feat: 7.783 Epoch Time: 10.934 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 12.0 | [0/8000 (0%)]	Loss: 5.100797                         LR: 0.0003  Feat: 7.794 Epoch Time: 11.948 Model Time: 0.072 Data Time: 0.782 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 12.0 | [2560/8000 (32%)]	Loss: 5.163675                         LR: 0.0003  Feat: 7.778 Epoch Time: 13.463 Model Time: 0.056 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 12.0 | [5120/8000 (65%)]	Loss: 5.131822                         LR: 0.0003  Feat: 7.780 Epoch Time: 14.982 Model Time: 0.056 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 12.0 | [7680/8000 (97%)]	Loss: 5.121771                         LR: 0.0003  Feat: 7.778 Epoch Time: 16.493 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 13.0 | [0/8000 (0%)]	Loss: 5.177877                         LR: 0.0003  Feat: 7.771 Epoch Time: 17.455 Model Time: 0.056 Data Time: 0.758 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 13.0 | [2560/8000 (32%)]	Loss: 5.163055                         LR: 0.0003  Feat: 7.757 Epoch Time: 18.958 Model Time: 0.052 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 13.0 | [5120/8000 (65%)]	Loss: 5.124931                         LR: 0.0003  Feat: 7.765 Epoch Time: 20.458 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 13.0 | [7680/8000 (97%)]	Loss: 5.122962                         LR: 0.0003  Feat: 7.758 Epoch Time: 21.963 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 14.0 | [0/8000 (0%)]	Loss: 5.125027                         LR: 0.0003  Feat: 7.755 Epoch Time: 22.903 Model Time: 0.058 Data Time: 0.736 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 14.0 | [2560/8000 (32%)]	Loss: 5.187095                         LR: 0.0003  Feat: 7.768 Epoch Time: 24.409 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 14.0 | [5120/8000 (65%)]	Loss: 5.144490                         LR: 0.0003  Feat: 7.763 Epoch Time: 25.919 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 2 | Local Epoch : 14.0 | [7680/8000 (97%)]	Loss: 5.150951                         LR: 0.0003  Feat: 7.745 Epoch Time: 27.427 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
learning rate fed to local model:  0.0003
Find_phi_psi for agent:  4
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked

 | Global Training Round : 4 | Model : 05-17_20:09_2267728

Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 15.0 | [0/8000 (0%)]	Loss: 5.328489                         LR: 0.0001  Feat: 16.410 Epoch Time: 0.985 Model Time: 0.064 Data Time: 0.819 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 15.0 | [2560/8000 (32%)]	Loss: 5.230115                         LR: 0.0001  Feat: 16.425 Epoch Time: 2.491 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 15.0 | [5120/8000 (65%)]	Loss: 5.276158                         LR: 0.0001  Feat: 16.385 Epoch Time: 4.003 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 15.0 | [7680/8000 (97%)]	Loss: 5.266476                         LR: 0.0001  Feat: 16.367 Epoch Time: 5.521 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 16.0 | [0/8000 (0%)]	Loss: 5.273020                         LR: 0.0001  Feat: 16.368 Epoch Time: 6.487 Model Time: 0.057 Data Time: 0.761 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 16.0 | [2560/8000 (32%)]	Loss: 5.209400                         LR: 0.0001  Feat: 16.341 Epoch Time: 7.992 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 16.0 | [5120/8000 (65%)]	Loss: 5.226596                         LR: 0.0001  Feat: 16.360 Epoch Time: 9.509 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 16.0 | [7680/8000 (97%)]	Loss: 5.212309                         LR: 0.0001  Feat: 16.347 Epoch Time: 11.012 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 17.0 | [0/8000 (0%)]	Loss: 5.281680                         LR: 0.0001  Feat: 16.353 Epoch Time: 11.997 Model Time: 0.057 Data Time: 0.779 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 17.0 | [2560/8000 (32%)]	Loss: 5.205323                         LR: 0.0001  Feat: 16.302 Epoch Time: 13.507 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 17.0 | [5120/8000 (65%)]	Loss: 5.250813                         LR: 0.0001  Feat: 16.311 Epoch Time: 15.017 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 17.0 | [7680/8000 (97%)]	Loss: 5.182186                         LR: 0.0001  Feat: 16.315 Epoch Time: 16.526 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 18.0 | [0/8000 (0%)]	Loss: 5.218187                         LR: 0.0001  Feat: 16.304 Epoch Time: 17.538 Model Time: 0.057 Data Time: 0.787 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 18.0 | [2560/8000 (32%)]	Loss: 5.178389                         LR: 0.0001  Feat: 16.283 Epoch Time: 19.045 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 18.0 | [5120/8000 (65%)]	Loss: 5.258700                         LR: 0.0001  Feat: 16.265 Epoch Time: 20.557 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 18.0 | [7680/8000 (97%)]	Loss: 5.195794                         LR: 0.0001  Feat: 16.282 Epoch Time: 22.064 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 19.0 | [0/8000 (0%)]	Loss: 5.153181                         LR: 0.0001  Feat: 16.316 Epoch Time: 23.048 Model Time: 0.059 Data Time: 0.774 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 19.0 | [2560/8000 (32%)]	Loss: 5.178784                         LR: 0.0001  Feat: 16.272 Epoch Time: 24.553 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 19.0 | [5120/8000 (65%)]	Loss: 5.220591                         LR: 0.0001  Feat: 16.253 Epoch Time: 26.055 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 3 | Local Epoch : 19.0 | [7680/8000 (97%)]	Loss: 5.229414                         LR: 0.0001  Feat: 16.279 Epoch Time: 27.555 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  3
Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 15.0 | [0/8000 (0%)]	Loss: 5.257217                         LR: 0.0001  Feat: 11.825 Epoch Time: 0.904 Model Time: 0.059 Data Time: 0.752 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 15.0 | [2560/8000 (32%)]	Loss: 5.221574                         LR: 0.0001  Feat: 11.824 Epoch Time: 2.411 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 15.0 | [5120/8000 (65%)]	Loss: 5.248818                         LR: 0.0001  Feat: 11.790 Epoch Time: 3.911 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 15.0 | [7680/8000 (97%)]	Loss: 5.220522                         LR: 0.0001  Feat: 11.773 Epoch Time: 5.417 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 16.0 | [0/8000 (0%)]	Loss: 5.191164                         LR: 0.0001  Feat: 11.795 Epoch Time: 6.448 Model Time: 0.064 Data Time: 0.814 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 16.0 | [2560/8000 (32%)]	Loss: 5.223279                         LR: 0.0001  Feat: 11.788 Epoch Time: 7.955 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 16.0 | [5120/8000 (65%)]	Loss: 5.204942                         LR: 0.0001  Feat: 11.763 Epoch Time: 9.458 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 16.0 | [7680/8000 (97%)]	Loss: 5.195858                         LR: 0.0001  Feat: 11.766 Epoch Time: 10.963 Model Time: 0.056 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 17.0 | [0/8000 (0%)]	Loss: 5.175053                         LR: 0.0001  Feat: 11.764 Epoch Time: 11.979 Model Time: 0.061 Data Time: 0.809 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 17.0 | [2560/8000 (32%)]	Loss: 5.172492                         LR: 0.0001  Feat: 11.768 Epoch Time: 13.486 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 17.0 | [5120/8000 (65%)]	Loss: 5.231237                         LR: 0.0001  Feat: 11.768 Epoch Time: 14.991 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 17.0 | [7680/8000 (97%)]	Loss: 5.182323                         LR: 0.0001  Feat: 11.752 Epoch Time: 16.491 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 18.0 | [0/8000 (0%)]	Loss: 5.172565                         LR: 0.0001  Feat: 11.757 Epoch Time: 17.472 Model Time: 0.057 Data Time: 0.775 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 18.0 | [2560/8000 (32%)]	Loss: 5.193467                         LR: 0.0001  Feat: 11.738 Epoch Time: 18.978 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 18.0 | [5120/8000 (65%)]	Loss: 5.186641                         LR: 0.0001  Feat: 11.725 Epoch Time: 20.478 Model Time: 0.056 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 18.0 | [7680/8000 (97%)]	Loss: 5.188025                         LR: 0.0001  Feat: 11.771 Epoch Time: 21.992 Model Time: 0.056 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 19.0 | [0/8000 (0%)]	Loss: 5.142422                         LR: 0.0001  Feat: 11.737 Epoch Time: 23.020 Model Time: 0.061 Data Time: 0.788 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 19.0 | [2560/8000 (32%)]	Loss: 5.179855                         LR: 0.0001  Feat: 11.730 Epoch Time: 24.526 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 19.0 | [5120/8000 (65%)]	Loss: 5.165169                         LR: 0.0001  Feat: 11.748 Epoch Time: 26.037 Model Time: 0.057 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 3 | Local Epoch : 19.0 | [7680/8000 (97%)]	Loss: 5.183006                         LR: 0.0001  Feat: 11.725 Epoch Time: 27.544 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  1
Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 15.0 | [0/8000 (0%)]	Loss: 5.153432                         LR: 0.0001  Feat: 10.023 Epoch Time: 0.940 Model Time: 0.059 Data Time: 0.788 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 15.0 | [2560/8000 (32%)]	Loss: 5.153563                         LR: 0.0001  Feat: 10.012 Epoch Time: 2.445 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 15.0 | [5120/8000 (65%)]	Loss: 5.167361                         LR: 0.0001  Feat: 10.006 Epoch Time: 3.949 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 15.0 | [7680/8000 (97%)]	Loss: 5.161167                         LR: 0.0001  Feat: 9.989 Epoch Time: 5.453 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 16.0 | [0/8000 (0%)]	Loss: 5.161531                         LR: 0.0001  Feat: 9.984 Epoch Time: 6.431 Model Time: 0.057 Data Time: 0.771 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 16.0 | [2560/8000 (32%)]	Loss: 5.110897                         LR: 0.0001  Feat: 9.967 Epoch Time: 7.932 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 16.0 | [5120/8000 (65%)]	Loss: 5.082158                         LR: 0.0001  Feat: 9.971 Epoch Time: 9.429 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 16.0 | [7680/8000 (97%)]	Loss: 5.078848                         LR: 0.0001  Feat: 9.985 Epoch Time: 10.932 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 17.0 | [0/8000 (0%)]	Loss: 5.080274                         LR: 0.0001  Feat: 9.967 Epoch Time: 11.994 Model Time: 0.057 Data Time: 0.854 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 17.0 | [2560/8000 (32%)]	Loss: 5.101912                         LR: 0.0001  Feat: 9.973 Epoch Time: 13.505 Model Time: 0.056 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 17.0 | [5120/8000 (65%)]	Loss: 5.074854                         LR: 0.0001  Feat: 9.960 Epoch Time: 15.011 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 17.0 | [7680/8000 (97%)]	Loss: 5.120964                         LR: 0.0001  Feat: 9.950 Epoch Time: 16.519 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 18.0 | [0/8000 (0%)]	Loss: 5.060753                         LR: 0.0001  Feat: 9.928 Epoch Time: 17.509 Model Time: 0.060 Data Time: 0.771 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 18.0 | [2560/8000 (32%)]	Loss: 5.117871                         LR: 0.0001  Feat: 9.968 Epoch Time: 19.019 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 18.0 | [5120/8000 (65%)]	Loss: 5.125101                         LR: 0.0001  Feat: 9.963 Epoch Time: 20.526 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 18.0 | [7680/8000 (97%)]	Loss: 5.077218                         LR: 0.0001  Feat: 9.965 Epoch Time: 22.027 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 19.0 | [0/8000 (0%)]	Loss: 5.033187                         LR: 0.0001  Feat: 9.976 Epoch Time: 22.996 Model Time: 0.059 Data Time: 0.766 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 19.0 | [2560/8000 (32%)]	Loss: 5.127490                         LR: 0.0001  Feat: 9.943 Epoch Time: 24.500 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 19.0 | [5120/8000 (65%)]	Loss: 5.101357                         LR: 0.0001  Feat: 9.953 Epoch Time: 26.008 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 3 | Local Epoch : 19.0 | [7680/8000 (97%)]	Loss: 5.110428                         LR: 0.0001  Feat: 9.946 Epoch Time: 27.514 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  0
Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 15.0 | [0/8000 (0%)]	Loss: 5.252133                         LR: 0.0001  Feat: 19.745 Epoch Time: 0.991 Model Time: 0.063 Data Time: 0.838 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 15.0 | [2560/8000 (32%)]	Loss: 5.262052                         LR: 0.0001  Feat: 19.694 Epoch Time: 2.502 Model Time: 0.054 Data Time: 0.092 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 15.0 | [5120/8000 (65%)]	Loss: 5.259356                         LR: 0.0001  Feat: 19.733 Epoch Time: 4.012 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 15.0 | [7680/8000 (97%)]	Loss: 5.196709                         LR: 0.0001  Feat: 19.751 Epoch Time: 5.520 Model Time: 0.056 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 16.0 | [0/8000 (0%)]	Loss: 5.231063                         LR: 0.0001  Feat: 19.744 Epoch Time: 6.526 Model Time: 0.060 Data Time: 0.780 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 16.0 | [2560/8000 (32%)]	Loss: 5.267845                         LR: 0.0001  Feat: 19.684 Epoch Time: 8.036 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 16.0 | [5120/8000 (65%)]	Loss: 5.212516                         LR: 0.0001  Feat: 19.713 Epoch Time: 9.548 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 16.0 | [7680/8000 (97%)]	Loss: 5.204850                         LR: 0.0001  Feat: 19.691 Epoch Time: 11.055 Model Time: 0.058 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 17.0 | [0/8000 (0%)]	Loss: 5.278616                         LR: 0.0001  Feat: 19.704 Epoch Time: 12.017 Model Time: 0.056 Data Time: 0.759 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 17.0 | [2560/8000 (32%)]	Loss: 5.181100                         LR: 0.0001  Feat: 19.675 Epoch Time: 13.516 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 17.0 | [5120/8000 (65%)]	Loss: 5.138997                         LR: 0.0001  Feat: 19.706 Epoch Time: 15.016 Model Time: 0.054 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 17.0 | [7680/8000 (97%)]	Loss: 5.175989                         LR: 0.0001  Feat: 19.667 Epoch Time: 16.518 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 18.0 | [0/8000 (0%)]	Loss: 5.165671                         LR: 0.0001  Feat: 19.656 Epoch Time: 17.469 Model Time: 0.062 Data Time: 0.744 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 18.0 | [2560/8000 (32%)]	Loss: 5.195492                         LR: 0.0001  Feat: 19.678 Epoch Time: 18.981 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 18.0 | [5120/8000 (65%)]	Loss: 5.214909                         LR: 0.0001  Feat: 19.695 Epoch Time: 20.490 Model Time: 0.056 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 18.0 | [7680/8000 (97%)]	Loss: 5.146018                         LR: 0.0001  Feat: 19.662 Epoch Time: 21.996 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 19.0 | [0/8000 (0%)]	Loss: 5.217976                         LR: 0.0001  Feat: 19.686 Epoch Time: 23.062 Model Time: 0.061 Data Time: 0.843 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 19.0 | [2560/8000 (32%)]	Loss: 5.179317                         LR: 0.0001  Feat: 19.658 Epoch Time: 24.572 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 19.0 | [5120/8000 (65%)]	Loss: 5.207696                         LR: 0.0001  Feat: 19.678 Epoch Time: 26.082 Model Time: 0.054 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 3 | Local Epoch : 19.0 | [7680/8000 (97%)]	Loss: 5.186483                         LR: 0.0001  Feat: 19.678 Epoch Time: 27.591 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  4
Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 15.0 | [0/8000 (0%)]	Loss: 5.280530                         LR: 0.0001  Feat: 13.929 Epoch Time: 0.955 Model Time: 0.058 Data Time: 0.803 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 15.0 | [2560/8000 (32%)]	Loss: 5.262903                         LR: 0.0001  Feat: 13.941 Epoch Time: 2.458 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 15.0 | [5120/8000 (65%)]	Loss: 5.126643                         LR: 0.0001  Feat: 13.958 Epoch Time: 3.960 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 15.0 | [7680/8000 (97%)]	Loss: 5.299164                         LR: 0.0001  Feat: 13.879 Epoch Time: 5.462 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 16.0 | [0/8000 (0%)]	Loss: 5.270142                         LR: 0.0001  Feat: 13.912 Epoch Time: 6.399 Model Time: 0.059 Data Time: 0.732 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 16.0 | [2560/8000 (32%)]	Loss: 5.285118                         LR: 0.0001  Feat: 13.886 Epoch Time: 7.906 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 16.0 | [5120/8000 (65%)]	Loss: 5.211099                         LR: 0.0001  Feat: 13.908 Epoch Time: 9.426 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 16.0 | [7680/8000 (97%)]	Loss: 5.237432                         LR: 0.0001  Feat: 13.872 Epoch Time: 10.939 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 17.0 | [0/8000 (0%)]	Loss: 5.232205                         LR: 0.0001  Feat: 13.921 Epoch Time: 11.985 Model Time: 0.061 Data Time: 0.827 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 17.0 | [2560/8000 (32%)]	Loss: 5.241815                         LR: 0.0001  Feat: 13.877 Epoch Time: 13.495 Model Time: 0.055 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 17.0 | [5120/8000 (65%)]	Loss: 5.254080                         LR: 0.0001  Feat: 13.892 Epoch Time: 15.003 Model Time: 0.055 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 17.0 | [7680/8000 (97%)]	Loss: 5.207394                         LR: 0.0001  Feat: 13.860 Epoch Time: 16.511 Model Time: 0.054 Data Time: 0.099 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 18.0 | [0/8000 (0%)]	Loss: 5.165983                         LR: 0.0001  Feat: 13.872 Epoch Time: 17.468 Model Time: 0.064 Data Time: 0.740 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 18.0 | [2560/8000 (32%)]	Loss: 5.252044                         LR: 0.0001  Feat: 13.876 Epoch Time: 18.967 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 18.0 | [5120/8000 (65%)]	Loss: 5.249984                         LR: 0.0001  Feat: 13.854 Epoch Time: 20.469 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 18.0 | [7680/8000 (97%)]	Loss: 5.240545                         LR: 0.0001  Feat: 13.853 Epoch Time: 21.968 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 19.0 | [0/8000 (0%)]	Loss: 5.187000                         LR: 0.0001  Feat: 13.875 Epoch Time: 22.986 Model Time: 0.062 Data Time: 0.806 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 19.0 | [2560/8000 (32%)]	Loss: 5.229585                         LR: 0.0001  Feat: 13.881 Epoch Time: 24.487 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 19.0 | [5120/8000 (65%)]	Loss: 5.239727                         LR: 0.0001  Feat: 13.840 Epoch Time: 25.988 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 3 | Local Epoch : 19.0 | [7680/8000 (97%)]	Loss: 5.221539                         LR: 0.0001  Feat: 13.862 Epoch Time: 27.500 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  2
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked

 | Global Training Round : 5 | Model : 05-17_20:09_2267728

Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 20.0 | [0/8000 (0%)]	Loss: 5.241010                         LR: 0.0001  Feat: 28.886 Epoch Time: 0.993 Model Time: 0.063 Data Time: 0.840 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 20.0 | [2560/8000 (32%)]	Loss: 5.208898                         LR: 0.0001  Feat: 28.831 Epoch Time: 2.505 Model Time: 0.060 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 20.0 | [5120/8000 (65%)]	Loss: 5.279236                         LR: 0.0001  Feat: 28.843 Epoch Time: 4.024 Model Time: 0.054 Data Time: 0.088 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 20.0 | [7680/8000 (97%)]	Loss: 5.214135                         LR: 0.0001  Feat: 28.796 Epoch Time: 5.541 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 21.0 | [0/8000 (0%)]	Loss: 5.250185                         LR: 0.0001  Feat: 28.840 Epoch Time: 6.520 Model Time: 0.055 Data Time: 0.764 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 21.0 | [2560/8000 (32%)]	Loss: 5.224563                         LR: 0.0001  Feat: 28.841 Epoch Time: 8.020 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 21.0 | [5120/8000 (65%)]	Loss: 5.224932                         LR: 0.0001  Feat: 28.864 Epoch Time: 9.520 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 21.0 | [7680/8000 (97%)]	Loss: 5.166063                         LR: 0.0001  Feat: 28.791 Epoch Time: 11.022 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 22.0 | [0/8000 (0%)]	Loss: 5.253137                         LR: 0.0001  Feat: 28.867 Epoch Time: 11.987 Model Time: 0.056 Data Time: 0.752 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 22.0 | [2560/8000 (32%)]	Loss: 5.245400                         LR: 0.0001  Feat: 28.796 Epoch Time: 13.489 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 22.0 | [5120/8000 (65%)]	Loss: 5.205117                         LR: 0.0001  Feat: 28.840 Epoch Time: 14.997 Model Time: 0.066 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 22.0 | [7680/8000 (97%)]	Loss: 5.152796                         LR: 0.0001  Feat: 28.808 Epoch Time: 16.504 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 23.0 | [0/8000 (0%)]	Loss: 5.166534                         LR: 0.0001  Feat: 28.762 Epoch Time: 17.506 Model Time: 0.059 Data Time: 0.792 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 23.0 | [2560/8000 (32%)]	Loss: 5.289396                         LR: 0.0001  Feat: 28.780 Epoch Time: 19.010 Model Time: 0.054 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 23.0 | [5120/8000 (65%)]	Loss: 5.210063                         LR: 0.0001  Feat: 28.743 Epoch Time: 20.510 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 23.0 | [7680/8000 (97%)]	Loss: 5.207251                         LR: 0.0001  Feat: 28.781 Epoch Time: 22.008 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 24.0 | [0/8000 (0%)]	Loss: 5.158480                         LR: 0.0001  Feat: 28.768 Epoch Time: 23.047 Model Time: 0.067 Data Time: 0.822 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 24.0 | [2560/8000 (32%)]	Loss: 5.118537                         LR: 0.0001  Feat: 28.812 Epoch Time: 24.545 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 24.0 | [5120/8000 (65%)]	Loss: 5.162978                         LR: 0.0001  Feat: 28.757 Epoch Time: 26.044 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 4 | Local Epoch : 24.0 | [7680/8000 (97%)]	Loss: 5.181574                         LR: 0.0001  Feat: 28.857 Epoch Time: 27.545 Model Time: 0.051 Data Time: 0.099 Model: 05-17_20:09_2267728
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  1
Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 20.0 | [0/8000 (0%)]	Loss: 5.342268                         LR: 0.0001  Feat: 49.343 Epoch Time: 0.887 Model Time: 0.057 Data Time: 0.735 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 20.0 | [2560/8000 (32%)]	Loss: 5.282365                         LR: 0.0001  Feat: 49.296 Epoch Time: 2.389 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 20.0 | [5120/8000 (65%)]	Loss: 5.277613                         LR: 0.0001  Feat: 49.353 Epoch Time: 3.893 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 20.0 | [7680/8000 (97%)]	Loss: 5.205606                         LR: 0.0001  Feat: 49.269 Epoch Time: 5.405 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 21.0 | [0/8000 (0%)]	Loss: 5.240868                         LR: 0.0001  Feat: 49.324 Epoch Time: 6.462 Model Time: 0.058 Data Time: 0.845 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 21.0 | [2560/8000 (32%)]	Loss: 5.159700                         LR: 0.0001  Feat: 49.316 Epoch Time: 7.981 Model Time: 0.055 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 21.0 | [5120/8000 (65%)]	Loss: 5.236354                         LR: 0.0001  Feat: 49.331 Epoch Time: 9.490 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 21.0 | [7680/8000 (97%)]	Loss: 5.165071                         LR: 0.0001  Feat: 49.266 Epoch Time: 11.005 Model Time: 0.060 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 22.0 | [0/8000 (0%)]	Loss: 5.284945                         LR: 0.0001  Feat: 49.249 Epoch Time: 12.060 Model Time: 0.059 Data Time: 0.837 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 22.0 | [2560/8000 (32%)]	Loss: 5.237276                         LR: 0.0001  Feat: 49.351 Epoch Time: 13.564 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 22.0 | [5120/8000 (65%)]	Loss: 5.233308                         LR: 0.0001  Feat: 49.245 Epoch Time: 15.063 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 22.0 | [7680/8000 (97%)]	Loss: 5.248281                         LR: 0.0001  Feat: 49.234 Epoch Time: 16.563 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 23.0 | [0/8000 (0%)]	Loss: 5.180412                         LR: 0.0001  Feat: 49.328 Epoch Time: 17.572 Model Time: 0.056 Data Time: 0.799 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 23.0 | [2560/8000 (32%)]	Loss: 5.232783                         LR: 0.0001  Feat: 49.315 Epoch Time: 19.075 Model Time: 0.065 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 23.0 | [5120/8000 (65%)]	Loss: 5.201588                         LR: 0.0001  Feat: 49.243 Epoch Time: 20.576 Model Time: 0.056 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 23.0 | [7680/8000 (97%)]	Loss: 5.228453                         LR: 0.0001  Feat: 49.236 Epoch Time: 22.085 Model Time: 0.053 Data Time: 0.094 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 24.0 | [0/8000 (0%)]	Loss: 5.157069                         LR: 0.0001  Feat: 49.362 Epoch Time: 23.186 Model Time: 0.069 Data Time: 0.874 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 24.0 | [2560/8000 (32%)]	Loss: 5.187900                         LR: 0.0001  Feat: 49.214 Epoch Time: 24.694 Model Time: 0.058 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 24.0 | [5120/8000 (65%)]	Loss: 5.198867                         LR: 0.0001  Feat: 49.357 Epoch Time: 26.207 Model Time: 0.054 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 4 | Local Epoch : 24.0 | [7680/8000 (97%)]	Loss: 5.180697                         LR: 0.0001  Feat: 49.254 Epoch Time: 27.717 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  4
Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 20.0 | [0/8000 (0%)]	Loss: 5.287869                         LR: 0.0001  Feat: 40.861 Epoch Time: 0.941 Model Time: 0.060 Data Time: 0.789 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 20.0 | [2560/8000 (32%)]	Loss: 5.311240                         LR: 0.0001  Feat: 40.758 Epoch Time: 2.444 Model Time: 0.052 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 20.0 | [5120/8000 (65%)]	Loss: 5.285636                         LR: 0.0001  Feat: 40.807 Epoch Time: 3.940 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 20.0 | [7680/8000 (97%)]	Loss: 5.295280                         LR: 0.0001  Feat: 40.787 Epoch Time: 5.436 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 21.0 | [0/8000 (0%)]	Loss: 5.246785                         LR: 0.0001  Feat: 40.782 Epoch Time: 6.376 Model Time: 0.057 Data Time: 0.736 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 21.0 | [2560/8000 (32%)]	Loss: 5.302950                         LR: 0.0001  Feat: 40.745 Epoch Time: 7.877 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 21.0 | [5120/8000 (65%)]	Loss: 5.273314                         LR: 0.0001  Feat: 40.754 Epoch Time: 9.374 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 21.0 | [7680/8000 (97%)]	Loss: 5.316070                         LR: 0.0001  Feat: 40.726 Epoch Time: 10.981 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 22.0 | [0/8000 (0%)]	Loss: 5.291173                         LR: 0.0001  Feat: 40.753 Epoch Time: 12.156 Model Time: 0.063 Data Time: 0.965 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 22.0 | [2560/8000 (32%)]	Loss: 5.340868                         LR: 0.0001  Feat: 40.743 Epoch Time: 13.665 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 22.0 | [5120/8000 (65%)]	Loss: 5.270792                         LR: 0.0001  Feat: 40.750 Epoch Time: 15.172 Model Time: 0.055 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 22.0 | [7680/8000 (97%)]	Loss: 5.285522                         LR: 0.0001  Feat: 40.716 Epoch Time: 16.681 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 23.0 | [0/8000 (0%)]	Loss: 5.298082                         LR: 0.0001  Feat: 40.689 Epoch Time: 17.668 Model Time: 0.062 Data Time: 0.766 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 23.0 | [2560/8000 (32%)]	Loss: 5.289148                         LR: 0.0001  Feat: 40.690 Epoch Time: 19.179 Model Time: 0.054 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 23.0 | [5120/8000 (65%)]	Loss: 5.329705                         LR: 0.0001  Feat: 40.805 Epoch Time: 20.684 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 23.0 | [7680/8000 (97%)]	Loss: 5.237885                         LR: 0.0001  Feat: 40.714 Epoch Time: 22.187 Model Time: 0.053 Data Time: 0.099 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 24.0 | [0/8000 (0%)]	Loss: 5.272407                         LR: 0.0001  Feat: 40.710 Epoch Time: 23.117 Model Time: 0.057 Data Time: 0.726 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 24.0 | [2560/8000 (32%)]	Loss: 5.275880                         LR: 0.0001  Feat: 40.707 Epoch Time: 24.624 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 24.0 | [5120/8000 (65%)]	Loss: 5.238583                         LR: 0.0001  Feat: 40.622 Epoch Time: 26.125 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 4 | Local Epoch : 24.0 | [7680/8000 (97%)]	Loss: 5.231351                         LR: 0.0001  Feat: 40.701 Epoch Time: 27.632 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  3
Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 20.0 | [0/8000 (0%)]	Loss: 5.206360                         LR: 0.0001  Feat: 24.241 Epoch Time: 0.958 Model Time: 0.059 Data Time: 0.807 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 20.0 | [2560/8000 (32%)]	Loss: 5.254381                         LR: 0.0001  Feat: 24.271 Epoch Time: 2.457 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 20.0 | [5120/8000 (65%)]	Loss: 5.176186                         LR: 0.0001  Feat: 24.200 Epoch Time: 3.958 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 20.0 | [7680/8000 (97%)]	Loss: 5.156879                         LR: 0.0001  Feat: 24.227 Epoch Time: 5.451 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 21.0 | [0/8000 (0%)]	Loss: 5.209709                         LR: 0.0001  Feat: 24.211 Epoch Time: 6.475 Model Time: 0.056 Data Time: 0.810 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 21.0 | [2560/8000 (32%)]	Loss: 5.186846                         LR: 0.0001  Feat: 24.242 Epoch Time: 7.985 Model Time: 0.055 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 21.0 | [5120/8000 (65%)]	Loss: 5.189228                         LR: 0.0001  Feat: 24.190 Epoch Time: 9.498 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 21.0 | [7680/8000 (97%)]	Loss: 5.197095                         LR: 0.0001  Feat: 24.191 Epoch Time: 11.000 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 22.0 | [0/8000 (0%)]	Loss: 5.180960                         LR: 0.0001  Feat: 24.170 Epoch Time: 11.944 Model Time: 0.064 Data Time: 0.739 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 22.0 | [2560/8000 (32%)]	Loss: 5.179136                         LR: 0.0001  Feat: 24.222 Epoch Time: 13.451 Model Time: 0.057 Data Time: 0.094 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 22.0 | [5120/8000 (65%)]	Loss: 5.144912                         LR: 0.0001  Feat: 24.221 Epoch Time: 14.958 Model Time: 0.052 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 22.0 | [7680/8000 (97%)]	Loss: 5.174206                         LR: 0.0001  Feat: 24.244 Epoch Time: 16.463 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 23.0 | [0/8000 (0%)]	Loss: 5.133188                         LR: 0.0001  Feat: 24.145 Epoch Time: 17.411 Model Time: 0.058 Data Time: 0.744 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 23.0 | [2560/8000 (32%)]	Loss: 5.146621                         LR: 0.0001  Feat: 24.185 Epoch Time: 18.911 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 23.0 | [5120/8000 (65%)]	Loss: 5.172595                         LR: 0.0001  Feat: 24.156 Epoch Time: 20.412 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 23.0 | [7680/8000 (97%)]	Loss: 5.154857                         LR: 0.0001  Feat: 24.211 Epoch Time: 21.914 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 24.0 | [0/8000 (0%)]	Loss: 5.160449                         LR: 0.0001  Feat: 24.221 Epoch Time: 22.922 Model Time: 0.062 Data Time: 0.797 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 24.0 | [2560/8000 (32%)]	Loss: 5.191080                         LR: 0.0001  Feat: 24.137 Epoch Time: 24.429 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 24.0 | [5120/8000 (65%)]	Loss: 5.101808                         LR: 0.0001  Feat: 24.181 Epoch Time: 25.933 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 4 | Local Epoch : 24.0 | [7680/8000 (97%)]	Loss: 5.199048                         LR: 0.0001  Feat: 24.185 Epoch Time: 27.434 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  0
Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 20.0 | [0/8000 (0%)]	Loss: 5.255762                         LR: 0.0001  Feat: 34.391 Epoch Time: 0.896 Model Time: 0.061 Data Time: 0.745 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 20.0 | [2560/8000 (32%)]	Loss: 5.205592                         LR: 0.0001  Feat: 34.403 Epoch Time: 2.394 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 20.0 | [5120/8000 (65%)]	Loss: 5.237994                         LR: 0.0001  Feat: 34.344 Epoch Time: 3.891 Model Time: 0.052 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 20.0 | [7680/8000 (97%)]	Loss: 5.269369                         LR: 0.0001  Feat: 34.346 Epoch Time: 5.389 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 21.0 | [0/8000 (0%)]	Loss: 5.316381                         LR: 0.0001  Feat: 34.363 Epoch Time: 6.347 Model Time: 0.059 Data Time: 0.755 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 21.0 | [2560/8000 (32%)]	Loss: 5.211093                         LR: 0.0001  Feat: 34.337 Epoch Time: 7.847 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 21.0 | [5120/8000 (65%)]	Loss: 5.225958                         LR: 0.0001  Feat: 34.332 Epoch Time: 9.355 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 21.0 | [7680/8000 (97%)]	Loss: 5.252807                         LR: 0.0001  Feat: 34.248 Epoch Time: 10.858 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 22.0 | [0/8000 (0%)]	Loss: 5.237074                         LR: 0.0001  Feat: 34.365 Epoch Time: 11.839 Model Time: 0.058 Data Time: 0.769 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 22.0 | [2560/8000 (32%)]	Loss: 5.240748                         LR: 0.0001  Feat: 34.342 Epoch Time: 13.349 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 22.0 | [5120/8000 (65%)]	Loss: 5.246227                         LR: 0.0001  Feat: 34.259 Epoch Time: 14.851 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 22.0 | [7680/8000 (97%)]	Loss: 5.242587                         LR: 0.0001  Feat: 34.346 Epoch Time: 16.354 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 23.0 | [0/8000 (0%)]	Loss: 5.204357                         LR: 0.0001  Feat: 34.277 Epoch Time: 17.351 Model Time: 0.060 Data Time: 0.784 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 23.0 | [2560/8000 (32%)]	Loss: 5.206546                         LR: 0.0001  Feat: 34.372 Epoch Time: 18.850 Model Time: 0.052 Data Time: 0.099 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 23.0 | [5120/8000 (65%)]	Loss: 5.302388                         LR: 0.0001  Feat: 34.295 Epoch Time: 20.349 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 23.0 | [7680/8000 (97%)]	Loss: 5.281081                         LR: 0.0001  Feat: 34.289 Epoch Time: 21.847 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 24.0 | [0/8000 (0%)]	Loss: 5.350222                         LR: 0.0001  Feat: 34.318 Epoch Time: 22.889 Model Time: 0.056 Data Time: 0.837 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 24.0 | [2560/8000 (32%)]	Loss: 5.231907                         LR: 0.0001  Feat: 34.272 Epoch Time: 24.396 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 24.0 | [5120/8000 (65%)]	Loss: 5.244762                         LR: 0.0001  Feat: 34.264 Epoch Time: 25.901 Model Time: 0.060 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 4 | Local Epoch : 24.0 | [7680/8000 (97%)]	Loss: 5.283842                         LR: 0.0001  Feat: 34.240 Epoch Time: 27.408 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
learning rate fed to local model:  8.999999999999999e-05
Find_phi_psi for agent:  2
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked

 | Global Training Round : 6 | Model : 05-17_20:09_2267728

Updating local model for agent:  2
Updating local model for agent:  2
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 25.0 | [0/8000 (0%)]	Loss: 5.269683                         LR: 0.0000  Feat: 85.128 Epoch Time: 1.040 Model Time: 0.065 Data Time: 0.888 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 25.0 | [2560/8000 (32%)]	Loss: 5.318784                         LR: 0.0000  Feat: 85.150 Epoch Time: 2.547 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 25.0 | [5120/8000 (65%)]	Loss: 5.262359                         LR: 0.0000  Feat: 85.278 Epoch Time: 4.063 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 25.0 | [7680/8000 (97%)]	Loss: 5.320635                         LR: 0.0000  Feat: 85.143 Epoch Time: 5.572 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 26.0 | [0/8000 (0%)]	Loss: 5.352609                         LR: 0.0000  Feat: 85.131 Epoch Time: 6.556 Model Time: 0.057 Data Time: 0.765 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 26.0 | [2560/8000 (32%)]	Loss: 5.227807                         LR: 0.0000  Feat: 85.125 Epoch Time: 8.059 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 26.0 | [5120/8000 (65%)]	Loss: 5.225492                         LR: 0.0000  Feat: 85.275 Epoch Time: 9.560 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 26.0 | [7680/8000 (97%)]	Loss: 5.280068                         LR: 0.0000  Feat: 85.148 Epoch Time: 11.060 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 27.0 | [0/8000 (0%)]	Loss: 5.190261                         LR: 0.0000  Feat: 85.126 Epoch Time: 12.038 Model Time: 0.056 Data Time: 0.771 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 27.0 | [2560/8000 (32%)]	Loss: 5.271419                         LR: 0.0000  Feat: 85.173 Epoch Time: 13.537 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 27.0 | [5120/8000 (65%)]	Loss: 5.332728                         LR: 0.0000  Feat: 84.949 Epoch Time: 15.039 Model Time: 0.060 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 27.0 | [7680/8000 (97%)]	Loss: 5.224096                         LR: 0.0000  Feat: 85.398 Epoch Time: 16.550 Model Time: 0.053 Data Time: 0.091 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 28.0 | [0/8000 (0%)]	Loss: 5.250566                         LR: 0.0000  Feat: 85.318 Epoch Time: 17.572 Model Time: 0.061 Data Time: 0.803 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 28.0 | [2560/8000 (32%)]	Loss: 5.311405                         LR: 0.0000  Feat: 85.118 Epoch Time: 19.087 Model Time: 0.062 Data Time: 0.091 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 28.0 | [5120/8000 (65%)]	Loss: 5.328136                         LR: 0.0000  Feat: 85.122 Epoch Time: 20.594 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 28.0 | [7680/8000 (97%)]	Loss: 5.232983                         LR: 0.0000  Feat: 85.131 Epoch Time: 22.098 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 29.0 | [0/8000 (0%)]	Loss: 5.248028                         LR: 0.0000  Feat: 85.201 Epoch Time: 23.092 Model Time: 0.067 Data Time: 0.779 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 29.0 | [2560/8000 (32%)]	Loss: 5.234104                         LR: 0.0000  Feat: 85.067 Epoch Time: 24.602 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 29.0 | [5120/8000 (65%)]	Loss: 5.259070                         LR: 0.0000  Feat: 85.433 Epoch Time: 26.100 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 2 | Global Round : 5 | Local Epoch : 29.0 | [7680/8000 (97%)]	Loss: 5.239051                         LR: 0.0000  Feat: 85.175 Epoch Time: 27.600 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  2.6999999999999996e-05
Find_phi_psi for agent:  2
Updating local model for agent:  4
Updating local model for agent:  4
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 25.0 | [0/8000 (0%)]	Loss: 5.255828                         LR: 0.0000  Feat: 122.706 Epoch Time: 0.891 Model Time: 0.063 Data Time: 0.737 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 25.0 | [2560/8000 (32%)]	Loss: 5.285474                         LR: 0.0000  Feat: 123.000 Epoch Time: 2.394 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 25.0 | [5120/8000 (65%)]	Loss: 5.289732                         LR: 0.0000  Feat: 122.926 Epoch Time: 3.895 Model Time: 0.056 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 25.0 | [7680/8000 (97%)]	Loss: 5.244990                         LR: 0.0000  Feat: 122.938 Epoch Time: 5.401 Model Time: 0.059 Data Time: 0.090 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 26.0 | [0/8000 (0%)]	Loss: 5.329813                         LR: 0.0000  Feat: 122.836 Epoch Time: 6.416 Model Time: 0.060 Data Time: 0.808 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 26.0 | [2560/8000 (32%)]	Loss: 5.266937                         LR: 0.0000  Feat: 123.138 Epoch Time: 7.934 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 26.0 | [5120/8000 (65%)]	Loss: 5.248541                         LR: 0.0000  Feat: 123.066 Epoch Time: 9.451 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 26.0 | [7680/8000 (97%)]	Loss: 5.234198                         LR: 0.0000  Feat: 122.880 Epoch Time: 10.959 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 27.0 | [0/8000 (0%)]	Loss: 5.291969                         LR: 0.0000  Feat: 122.956 Epoch Time: 12.026 Model Time: 0.056 Data Time: 0.851 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 27.0 | [2560/8000 (32%)]	Loss: 5.300635                         LR: 0.0000  Feat: 122.938 Epoch Time: 13.531 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 27.0 | [5120/8000 (65%)]	Loss: 5.281243                         LR: 0.0000  Feat: 122.701 Epoch Time: 15.025 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 27.0 | [7680/8000 (97%)]	Loss: 5.239677                         LR: 0.0000  Feat: 122.916 Epoch Time: 16.522 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 28.0 | [0/8000 (0%)]	Loss: 5.281500                         LR: 0.0000  Feat: 122.882 Epoch Time: 17.510 Model Time: 0.056 Data Time: 0.780 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 28.0 | [2560/8000 (32%)]	Loss: 5.258470                         LR: 0.0000  Feat: 122.956 Epoch Time: 19.006 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 28.0 | [5120/8000 (65%)]	Loss: 5.244325                         LR: 0.0000  Feat: 122.934 Epoch Time: 20.504 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 28.0 | [7680/8000 (97%)]	Loss: 5.251239                         LR: 0.0000  Feat: 122.869 Epoch Time: 22.004 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 29.0 | [0/8000 (0%)]	Loss: 5.217487                         LR: 0.0000  Feat: 122.860 Epoch Time: 23.172 Model Time: 0.065 Data Time: 0.952 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 29.0 | [2560/8000 (32%)]	Loss: 5.204067                         LR: 0.0000  Feat: 122.901 Epoch Time: 24.677 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 29.0 | [5120/8000 (65%)]	Loss: 5.276292                         LR: 0.0000  Feat: 122.841 Epoch Time: 26.184 Model Time: 0.058 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 4 | Global Round : 5 | Local Epoch : 29.0 | [7680/8000 (97%)]	Loss: 5.250290                         LR: 0.0000  Feat: 123.087 Epoch Time: 27.689 Model Time: 0.060 Data Time: 0.098 Model: 05-17_20:09_2267728
learning rate fed to local model:  2.6999999999999996e-05
Find_phi_psi for agent:  4
Updating local model for agent:  3
Updating local model for agent:  3
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 25.0 | [0/8000 (0%)]	Loss: 5.277752                         LR: 0.0000  Feat: 101.580 Epoch Time: 0.961 Model Time: 0.069 Data Time: 0.806 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 25.0 | [2560/8000 (32%)]	Loss: 5.328392                         LR: 0.0000  Feat: 101.795 Epoch Time: 2.463 Model Time: 0.053 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 25.0 | [5120/8000 (65%)]	Loss: 5.248096                         LR: 0.0000  Feat: 101.854 Epoch Time: 3.964 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 25.0 | [7680/8000 (97%)]	Loss: 5.278069                         LR: 0.0000  Feat: 101.556 Epoch Time: 5.467 Model Time: 0.053 Data Time: 0.099 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 26.0 | [0/8000 (0%)]	Loss: 5.268924                         LR: 0.0000  Feat: 101.634 Epoch Time: 6.433 Model Time: 0.057 Data Time: 0.757 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 26.0 | [2560/8000 (32%)]	Loss: 5.324596                         LR: 0.0000  Feat: 101.870 Epoch Time: 7.935 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 26.0 | [5120/8000 (65%)]	Loss: 5.314477                         LR: 0.0000  Feat: 101.659 Epoch Time: 9.434 Model Time: 0.054 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 26.0 | [7680/8000 (97%)]	Loss: 5.298937                         LR: 0.0000  Feat: 101.508 Epoch Time: 10.929 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 27.0 | [0/8000 (0%)]	Loss: 5.309697                         LR: 0.0000  Feat: 101.828 Epoch Time: 11.929 Model Time: 0.059 Data Time: 0.793 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 27.0 | [2560/8000 (32%)]	Loss: 5.319507                         LR: 0.0000  Feat: 101.490 Epoch Time: 13.445 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 27.0 | [5120/8000 (65%)]	Loss: 5.257164                         LR: 0.0000  Feat: 101.735 Epoch Time: 14.954 Model Time: 0.061 Data Time: 0.095 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 27.0 | [7680/8000 (97%)]	Loss: 5.328726                         LR: 0.0000  Feat: 101.504 Epoch Time: 16.470 Model Time: 0.054 Data Time: 0.092 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 28.0 | [0/8000 (0%)]	Loss: 5.328968                         LR: 0.0000  Feat: 101.642 Epoch Time: 17.508 Model Time: 0.060 Data Time: 0.830 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 28.0 | [2560/8000 (32%)]	Loss: 5.272454                         LR: 0.0000  Feat: 101.818 Epoch Time: 19.009 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 28.0 | [5120/8000 (65%)]	Loss: 5.307383                         LR: 0.0000  Feat: 101.618 Epoch Time: 20.523 Model Time: 0.055 Data Time: 0.090 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 28.0 | [7680/8000 (97%)]	Loss: 5.345421                         LR: 0.0000  Feat: 101.669 Epoch Time: 22.028 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 29.0 | [0/8000 (0%)]	Loss: 5.310250                         LR: 0.0000  Feat: 101.683 Epoch Time: 23.074 Model Time: 0.059 Data Time: 0.840 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 29.0 | [2560/8000 (32%)]	Loss: 5.265654                         LR: 0.0000  Feat: 101.693 Epoch Time: 24.584 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 29.0 | [5120/8000 (65%)]	Loss: 5.263432                         LR: 0.0000  Feat: 101.674 Epoch Time: 26.098 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 3 | Global Round : 5 | Local Epoch : 29.0 | [7680/8000 (97%)]	Loss: 5.257619                         LR: 0.0000  Feat: 101.554 Epoch Time: 27.606 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  2.6999999999999996e-05
Find_phi_psi for agent:  3
Updating local model for agent:  0
Updating local model for agent:  0
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 25.0 | [0/8000 (0%)]	Loss: 5.218535                         LR: 0.0000  Feat: 59.744 Epoch Time: 0.938 Model Time: 0.062 Data Time: 0.786 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 25.0 | [2560/8000 (32%)]	Loss: 5.259057                         LR: 0.0000  Feat: 59.768 Epoch Time: 2.453 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 25.0 | [5120/8000 (65%)]	Loss: 5.217959                         LR: 0.0000  Feat: 59.709 Epoch Time: 3.964 Model Time: 0.055 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 25.0 | [7680/8000 (97%)]	Loss: 5.208891                         LR: 0.0000  Feat: 59.654 Epoch Time: 5.478 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 26.0 | [0/8000 (0%)]	Loss: 5.197356                         LR: 0.0000  Feat: 59.677 Epoch Time: 6.586 Model Time: 0.062 Data Time: 0.895 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 26.0 | [2560/8000 (32%)]	Loss: 5.197562                         LR: 0.0000  Feat: 59.692 Epoch Time: 8.100 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 26.0 | [5120/8000 (65%)]	Loss: 5.185326                         LR: 0.0000  Feat: 59.645 Epoch Time: 9.614 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 26.0 | [7680/8000 (97%)]	Loss: 5.197159                         LR: 0.0000  Feat: 59.601 Epoch Time: 11.120 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 27.0 | [0/8000 (0%)]	Loss: 5.184147                         LR: 0.0000  Feat: 59.754 Epoch Time: 12.075 Model Time: 0.066 Data Time: 0.743 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 27.0 | [2560/8000 (32%)]	Loss: 5.193908                         LR: 0.0000  Feat: 59.690 Epoch Time: 13.572 Model Time: 0.051 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 27.0 | [5120/8000 (65%)]	Loss: 5.217814                         LR: 0.0000  Feat: 59.640 Epoch Time: 15.069 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 27.0 | [7680/8000 (97%)]	Loss: 5.187520                         LR: 0.0000  Feat: 59.699 Epoch Time: 16.572 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 28.0 | [0/8000 (0%)]	Loss: 5.179321                         LR: 0.0000  Feat: 59.724 Epoch Time: 17.541 Model Time: 0.056 Data Time: 0.758 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 28.0 | [2560/8000 (32%)]	Loss: 5.280302                         LR: 0.0000  Feat: 59.670 Epoch Time: 19.049 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 28.0 | [5120/8000 (65%)]	Loss: 5.203469                         LR: 0.0000  Feat: 59.665 Epoch Time: 20.559 Model Time: 0.053 Data Time: 0.094 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 28.0 | [7680/8000 (97%)]	Loss: 5.173765                         LR: 0.0000  Feat: 59.595 Epoch Time: 22.063 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 29.0 | [0/8000 (0%)]	Loss: 5.187807                         LR: 0.0000  Feat: 59.610 Epoch Time: 23.070 Model Time: 0.057 Data Time: 0.793 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 29.0 | [2560/8000 (32%)]	Loss: 5.170062                         LR: 0.0000  Feat: 59.781 Epoch Time: 24.581 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 29.0 | [5120/8000 (65%)]	Loss: 5.231412                         LR: 0.0000  Feat: 59.672 Epoch Time: 26.095 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 0 | Global Round : 5 | Local Epoch : 29.0 | [7680/8000 (97%)]	Loss: 5.260151                         LR: 0.0000  Feat: 59.769 Epoch Time: 27.601 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
learning rate fed to local model:  2.6999999999999996e-05
Find_phi_psi for agent:  0
Updating local model for agent:  1
Updating local model for agent:  1
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 25.0 | [0/8000 (0%)]	Loss: 5.249446                         LR: 0.0000  Feat: 71.270 Epoch Time: 0.944 Model Time: 0.057 Data Time: 0.792 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 25.0 | [2560/8000 (32%)]	Loss: 5.225492                         LR: 0.0000  Feat: 71.171 Epoch Time: 2.447 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 25.0 | [5120/8000 (65%)]	Loss: 5.206855                         LR: 0.0000  Feat: 71.395 Epoch Time: 3.952 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 25.0 | [7680/8000 (97%)]	Loss: 5.232738                         LR: 0.0000  Feat: 71.296 Epoch Time: 5.454 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 26.0 | [0/8000 (0%)]	Loss: 5.225024                         LR: 0.0000  Feat: 71.219 Epoch Time: 6.484 Model Time: 0.056 Data Time: 0.824 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 26.0 | [2560/8000 (32%)]	Loss: 5.186916                         LR: 0.0000  Feat: 71.395 Epoch Time: 7.986 Model Time: 0.052 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 26.0 | [5120/8000 (65%)]	Loss: 5.164642                         LR: 0.0000  Feat: 71.263 Epoch Time: 9.500 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 26.0 | [7680/8000 (97%)]	Loss: 5.204923                         LR: 0.0000  Feat: 71.355 Epoch Time: 11.015 Model Time: 0.053 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 27.0 | [0/8000 (0%)]	Loss: 5.205302                         LR: 0.0000  Feat: 71.338 Epoch Time: 12.025 Model Time: 0.070 Data Time: 0.788 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 27.0 | [2560/8000 (32%)]	Loss: 5.238115                         LR: 0.0000  Feat: 71.297 Epoch Time: 13.539 Model Time: 0.056 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 27.0 | [5120/8000 (65%)]	Loss: 5.206845                         LR: 0.0000  Feat: 71.346 Epoch Time: 15.220 Model Time: 0.055 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 27.0 | [7680/8000 (97%)]	Loss: 5.150188                         LR: 0.0000  Feat: 71.423 Epoch Time: 16.733 Model Time: 0.054 Data Time: 0.094 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 28.0 | [0/8000 (0%)]	Loss: 5.172242                         LR: 0.0000  Feat: 71.287 Epoch Time: 17.755 Model Time: 0.067 Data Time: 0.805 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 28.0 | [2560/8000 (32%)]	Loss: 5.238896                         LR: 0.0000  Feat: 71.283 Epoch Time: 19.256 Model Time: 0.052 Data Time: 0.099 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 28.0 | [5120/8000 (65%)]	Loss: 5.203946                         LR: 0.0000  Feat: 71.339 Epoch Time: 20.751 Model Time: 0.052 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 28.0 | [7680/8000 (97%)]	Loss: 5.168145                         LR: 0.0000  Feat: 71.256 Epoch Time: 22.247 Model Time: 0.051 Data Time: 0.098 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 29.0 | [0/8000 (0%)]	Loss: 5.228892                         LR: 0.0000  Feat: 71.354 Epoch Time: 23.207 Model Time: 0.062 Data Time: 0.755 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 29.0 | [2560/8000 (32%)]	Loss: 5.255216                         LR: 0.0000  Feat: 71.212 Epoch Time: 24.707 Model Time: 0.054 Data Time: 0.099 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 29.0 | [5120/8000 (65%)]	Loss: 5.283887                         LR: 0.0000  Feat: 71.258 Epoch Time: 26.470 Model Time: 0.054 Data Time: 0.097 Model: 05-17_20:09_2267728
Update SSL || User : 1 | Global Round : 5 | Local Epoch : 29.0 | [7680/8000 (97%)]	Loss: 5.229160                         LR: 0.0000  Feat: 71.234 Epoch Time: 27.986 Model Time: 0.053 Data Time: 0.096 Model: 05-17_20:09_2267728
learning rate fed to local model:  2.6999999999999996e-05
Find_phi_psi for agent:  1
Exact Diffusion
exact_diffusion_averaging
combine_to_state_dict between 5 agents
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.1.running_mean
key not in phi or gradients, remains the same:  f.1.running_var
key not in phi or gradients, remains the same:  f.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn1.running_var
key not in phi or gradients, remains the same:  f.3.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.0.bn2.running_var
key not in phi or gradients, remains the same:  f.3.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn1.running_var
key not in phi or gradients, remains the same:  f.3.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.3.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.3.1.bn2.running_var
key not in phi or gradients, remains the same:  f.3.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn1.running_var
key not in phi or gradients, remains the same:  f.4.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.0.bn2.running_var
key not in phi or gradients, remains the same:  f.4.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.4.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.4.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn1.running_var
key not in phi or gradients, remains the same:  f.4.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.4.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.4.1.bn2.running_var
key not in phi or gradients, remains the same:  f.4.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn1.running_var
key not in phi or gradients, remains the same:  f.5.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.0.bn2.running_var
key not in phi or gradients, remains the same:  f.5.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.5.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.5.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn1.running_var
key not in phi or gradients, remains the same:  f.5.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.5.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.5.1.bn2.running_var
key not in phi or gradients, remains the same:  f.5.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn1.running_var
key not in phi or gradients, remains the same:  f.6.0.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.0.bn2.running_var
key not in phi or gradients, remains the same:  f.6.0.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_mean
key not in phi or gradients, remains the same:  f.6.0.downsample.1.running_var
key not in phi or gradients, remains the same:  f.6.0.downsample.1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn1.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn1.running_var
key not in phi or gradients, remains the same:  f.6.1.bn1.num_batches_tracked
key not in phi or gradients, remains the same:  f.6.1.bn2.running_mean
key not in phi or gradients, remains the same:  f.6.1.bn2.running_var
key not in phi or gradients, remains the same:  f.6.1.bn2.num_batches_tracked
key not in phi or gradients, remains the same:  g.layer1.1.running_mean
key not in phi or gradients, remains the same:  g.layer1.1.running_var
key not in phi or gradients, remains the same:  g.layer1.1.num_batches_tracked
evaluating representations:  save/05-17_20:09_2267728iid_dec-True_ED-True_pe1.0_a5_e30_le5.0
Training a classifier on each of the local models and averaging the accuracy result
Start tarining Classifier for user 0
Training classifier
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 2.787
Y partition skewness sampling
partition skew: 5 1.0 
10000 10000 0
len of skewed: 50000 len of unskewed: 0 data_num_per_user_skew: 10000
10000 5000 10000
partition skew: 5 1.0 
2000 2000 0
len of skewed: 10000 len of unskewed: 0 data_num_per_user_skew: 2000
2000 1000 2000
sample dataset time: 0.007
user data samples: [10000, 10000, 10000, 10000, 10000]
begin training classifier...
Downstream Train Epoch: 1 [0/50000 (0%)]	Loss: 150.522797
Downstream Train Epoch: 1 [12800/50000 (26%)]	Loss: 22.614841
Downstream Train Epoch: 1 [25600/50000 (51%)]	Loss: 23.249422
Downstream Train Epoch: 1 [38400/50000 (77%)]	Loss: 17.826059

 Downstream Train loss: 25.93407810950766 Acc: 0.2916
Downstream Train Epoch: 2 [0/50000 (0%)]	Loss: 16.400555
Downstream Train Epoch: 2 [12800/50000 (26%)]	Loss: 15.231133
Downstream Train Epoch: 2 [25600/50000 (51%)]	Loss: 13.158860
Downstream Train Epoch: 2 [38400/50000 (77%)]	Loss: 14.872409

 Downstream Train loss: 15.099069215813461 Acc: 0.2916
Downstream Train Epoch: 3 [0/50000 (0%)]	Loss: 15.573344
Downstream Train Epoch: 3 [12800/50000 (26%)]	Loss: 15.205285
Downstream Train Epoch: 3 [25600/50000 (51%)]	Loss: 15.791731
Downstream Train Epoch: 3 [38400/50000 (77%)]	Loss: 12.278004

 Downstream Train loss: 13.74493594072303 Acc: 0.2953
Downstream Train Epoch: 4 [0/50000 (0%)]	Loss: 13.753741
Downstream Train Epoch: 4 [12800/50000 (26%)]	Loss: 10.996325
Downstream Train Epoch: 4 [25600/50000 (51%)]	Loss: 12.132740
Downstream Train Epoch: 4 [38400/50000 (77%)]	Loss: 13.331943

 Downstream Train loss: 12.679734517116936 Acc: 0.2953
Downstream Train Epoch: 5 [0/50000 (0%)]	Loss: 12.926779
Downstream Train Epoch: 5 [12800/50000 (26%)]	Loss: 14.086464
Downstream Train Epoch: 5 [25600/50000 (51%)]	Loss: 14.122931
Downstream Train Epoch: 5 [38400/50000 (77%)]	Loss: 10.463938

 Downstream Train loss: 12.024730662910306 Acc: 0.3221
Downstream Train Epoch: 6 [0/50000 (0%)]	Loss: 11.559502
Downstream Train Epoch: 6 [12800/50000 (26%)]	Loss: 15.795884
Downstream Train Epoch: 6 [25600/50000 (51%)]	Loss: 11.499811
Downstream Train Epoch: 6 [38400/50000 (77%)]	Loss: 14.723105

 Downstream Train loss: 11.445979665736763 Acc: 0.3221
Downstream Train Epoch: 7 [0/50000 (0%)]	Loss: 11.334029
Downstream Train Epoch: 7 [12800/50000 (26%)]	Loss: 12.279654
Downstream Train Epoch: 7 [25600/50000 (51%)]	Loss: 11.430959
Downstream Train Epoch: 7 [38400/50000 (77%)]	Loss: 15.108541

 Downstream Train loss: 11.427240722033442 Acc: 0.3221
Downstream Train Epoch: 8 [0/50000 (0%)]	Loss: 11.805644
Downstream Train Epoch: 8 [12800/50000 (26%)]	Loss: 11.583724
Downstream Train Epoch: 8 [25600/50000 (51%)]	Loss: 9.690398
Downstream Train Epoch: 8 [38400/50000 (77%)]	Loss: 10.122546

 Downstream Train loss: 10.49985082052192 Acc: 0.3483
Downstream Train Epoch: 9 [0/50000 (0%)]	Loss: 11.631261
Downstream Train Epoch: 9 [12800/50000 (26%)]	Loss: 13.449736
Downstream Train Epoch: 9 [25600/50000 (51%)]	Loss: 13.826601
Downstream Train Epoch: 9 [38400/50000 (77%)]	Loss: 11.107294

 Downstream Train loss: 11.452112224637245 Acc: 0.3483
Downstream Train Epoch: 10 [0/50000 (0%)]	Loss: 13.320892
Downstream Train Epoch: 10 [12800/50000 (26%)]	Loss: 10.007601
Downstream Train Epoch: 10 [25600/50000 (51%)]	Loss: 12.090281
Downstream Train Epoch: 10 [38400/50000 (77%)]	Loss: 12.813988

 Downstream Train loss: 10.560584024507172 Acc: 0.3483
Downstream Train Epoch: 11 [0/50000 (0%)]	Loss: 8.119821
Downstream Train Epoch: 11 [12800/50000 (26%)]	Loss: 11.954440
Downstream Train Epoch: 11 [25600/50000 (51%)]	Loss: 9.021702
Downstream Train Epoch: 11 [38400/50000 (77%)]	Loss: 11.024863

 Downstream Train loss: 9.6807871083824 Acc: 0.3483
Downstream Train Epoch: 12 [0/50000 (0%)]	Loss: 9.165150
Downstream Train Epoch: 12 [12800/50000 (26%)]	Loss: 12.617141
Downstream Train Epoch: 12 [25600/50000 (51%)]	Loss: 7.094327
Downstream Train Epoch: 12 [38400/50000 (77%)]	Loss: 8.406845

 Downstream Train loss: 10.535702435337768 Acc: 0.3483
Downstream Train Epoch: 13 [0/50000 (0%)]	Loss: 9.586323
Downstream Train Epoch: 13 [12800/50000 (26%)]	Loss: 8.658923
Downstream Train Epoch: 13 [25600/50000 (51%)]	Loss: 8.785790
Downstream Train Epoch: 13 [38400/50000 (77%)]	Loss: 14.233272

 Downstream Train loss: 10.439419683145017 Acc: 0.36
Downstream Train Epoch: 14 [0/50000 (0%)]	Loss: 8.130942
Downstream Train Epoch: 14 [12800/50000 (26%)]	Loss: 6.780268
Downstream Train Epoch: 14 [25600/50000 (51%)]	Loss: 11.605543
Downstream Train Epoch: 14 [38400/50000 (77%)]	Loss: 10.486744

 Downstream Train loss: 10.193983905169429 Acc: 0.36
Downstream Train Epoch: 15 [0/50000 (0%)]	Loss: 7.734023
Downstream Train Epoch: 15 [12800/50000 (26%)]	Loss: 8.400725
Downstream Train Epoch: 15 [25600/50000 (51%)]	Loss: 6.450185
Downstream Train Epoch: 15 [38400/50000 (77%)]	Loss: 10.113927

 Downstream Train loss: 9.06618831595596 Acc: 0.3767
Downstream Train Epoch: 16 [0/50000 (0%)]	Loss: 7.215742
Downstream Train Epoch: 16 [12800/50000 (26%)]	Loss: 9.324052
Downstream Train Epoch: 16 [25600/50000 (51%)]	Loss: 6.910663
Downstream Train Epoch: 16 [38400/50000 (77%)]	Loss: 9.627095

 Downstream Train loss: 9.063686893910777 Acc: 0.3767
Downstream Train Epoch: 17 [0/50000 (0%)]	Loss: 8.424408
Downstream Train Epoch: 17 [12800/50000 (26%)]	Loss: 11.677595
Downstream Train Epoch: 17 [25600/50000 (51%)]	Loss: 9.507081
Downstream Train Epoch: 17 [38400/50000 (77%)]	Loss: 10.050124

 Downstream Train loss: 11.29154524997789 Acc: 0.3767
Downstream Train Epoch: 18 [0/50000 (0%)]	Loss: 7.607409
Downstream Train Epoch: 18 [12800/50000 (26%)]	Loss: 8.249549
Downstream Train Epoch: 18 [25600/50000 (51%)]	Loss: 9.649132
Downstream Train Epoch: 18 [38400/50000 (77%)]	Loss: 10.051457

 Downstream Train loss: 9.748672336948161 Acc: 0.3767
Downstream Train Epoch: 19 [0/50000 (0%)]	Loss: 7.306019
Downstream Train Epoch: 19 [12800/50000 (26%)]	Loss: 11.595526
Downstream Train Epoch: 19 [25600/50000 (51%)]	Loss: 11.676089
Downstream Train Epoch: 19 [38400/50000 (77%)]	Loss: 13.483732

 Downstream Train loss: 10.415083349967489 Acc: 0.3767
Downstream Train Epoch: 20 [0/50000 (0%)]	Loss: 14.838115
Downstream Train Epoch: 20 [12800/50000 (26%)]	Loss: 6.623894
Downstream Train Epoch: 20 [25600/50000 (51%)]	Loss: 10.138294
Downstream Train Epoch: 20 [38400/50000 (77%)]	Loss: 12.065976

 Downstream Train loss: 10.121280130074949 Acc: 0.3767
Downstream Train Epoch: 21 [0/50000 (0%)]	Loss: 9.414447
Downstream Train Epoch: 21 [12800/50000 (26%)]	Loss: 10.017323
Downstream Train Epoch: 21 [25600/50000 (51%)]	Loss: 6.271005
Downstream Train Epoch: 21 [38400/50000 (77%)]	Loss: 12.141040

 Downstream Train loss: 9.468161524558553 Acc: 0.3767
Downstream Train Epoch: 22 [0/50000 (0%)]	Loss: 9.960232
Downstream Train Epoch: 22 [12800/50000 (26%)]	Loss: 9.990620
Downstream Train Epoch: 22 [25600/50000 (51%)]	Loss: 9.927103
Downstream Train Epoch: 22 [38400/50000 (77%)]	Loss: 11.034819

 Downstream Train loss: 10.897434005931933 Acc: 0.3767
Downstream Train Epoch: 23 [0/50000 (0%)]	Loss: 7.932532
Downstream Train Epoch: 23 [12800/50000 (26%)]	Loss: 9.420727
Downstream Train Epoch: 23 [25600/50000 (51%)]	Loss: 9.015950
Downstream Train Epoch: 23 [38400/50000 (77%)]	Loss: 8.286999

 Downstream Train loss: 8.628132688755892 Acc: 0.3767
Downstream Train Epoch: 24 [0/50000 (0%)]	Loss: 12.000625
Downstream Train Epoch: 24 [12800/50000 (26%)]	Loss: 10.791350
Downstream Train Epoch: 24 [25600/50000 (51%)]	Loss: 6.895043
Downstream Train Epoch: 24 [38400/50000 (77%)]	Loss: 15.354499

 Downstream Train loss: 10.31253096278833 Acc: 0.3776
Downstream Train Epoch: 25 [0/50000 (0%)]	Loss: 5.872588
Downstream Train Epoch: 25 [12800/50000 (26%)]	Loss: 8.000113
Downstream Train Epoch: 25 [25600/50000 (51%)]	Loss: 17.099451
Downstream Train Epoch: 25 [38400/50000 (77%)]	Loss: 11.046487

 Downstream Train loss: 8.92513480964972 Acc: 0.3776
Downstream Train Epoch: 26 [0/50000 (0%)]	Loss: 9.268756
Downstream Train Epoch: 26 [12800/50000 (26%)]	Loss: 10.581921
Downstream Train Epoch: 26 [25600/50000 (51%)]	Loss: 12.160675
Downstream Train Epoch: 26 [38400/50000 (77%)]	Loss: 9.993063

 Downstream Train loss: 10.408093664110924 Acc: 0.3776
Downstream Train Epoch: 27 [0/50000 (0%)]	Loss: 9.563205
Downstream Train Epoch: 27 [12800/50000 (26%)]	Loss: 7.814794
Downstream Train Epoch: 27 [25600/50000 (51%)]	Loss: 9.713567
Downstream Train Epoch: 27 [38400/50000 (77%)]	Loss: 10.287174

 Downstream Train loss: 8.658639404238487 Acc: 0.3776
Downstream Train Epoch: 28 [0/50000 (0%)]	Loss: 8.304846
Downstream Train Epoch: 28 [12800/50000 (26%)]	Loss: 9.112838
Downstream Train Epoch: 28 [25600/50000 (51%)]	Loss: 7.527947
Downstream Train Epoch: 28 [38400/50000 (77%)]	Loss: 6.209350

 Downstream Train loss: 9.335253445469604 Acc: 0.3776
Downstream Train Epoch: 29 [0/50000 (0%)]	Loss: 8.688371
Downstream Train Epoch: 29 [12800/50000 (26%)]	Loss: 11.322211
Downstream Train Epoch: 29 [25600/50000 (51%)]	Loss: 6.845536
Downstream Train Epoch: 29 [38400/50000 (77%)]	Loss: 7.763849

 Downstream Train loss: 9.344003614114255 Acc: 0.3776
Downstream Train Epoch: 30 [0/50000 (0%)]	Loss: 8.496465
Downstream Train Epoch: 30 [12800/50000 (26%)]	Loss: 7.769105
Downstream Train Epoch: 30 [25600/50000 (51%)]	Loss: 10.472905
Downstream Train Epoch: 30 [38400/50000 (77%)]	Loss: 13.837469

 Downstream Train loss: 8.977792627957403 Acc: 0.3776
Downstream Train Epoch: 31 [0/50000 (0%)]	Loss: 13.637967
Downstream Train Epoch: 31 [12800/50000 (26%)]	Loss: 14.796286
Downstream Train Epoch: 31 [25600/50000 (51%)]	Loss: 6.828123
Downstream Train Epoch: 31 [38400/50000 (77%)]	Loss: 9.226334

 Downstream Train loss: 9.925678958698194 Acc: 0.3812
Downstream Train Epoch: 32 [0/50000 (0%)]	Loss: 9.228061
Downstream Train Epoch: 32 [12800/50000 (26%)]	Loss: 9.667649
Downstream Train Epoch: 32 [25600/50000 (51%)]	Loss: 7.271938
Downstream Train Epoch: 32 [38400/50000 (77%)]	Loss: 10.254047

 Downstream Train loss: 10.353079883419738 Acc: 0.3812
Downstream Train Epoch: 33 [0/50000 (0%)]	Loss: 11.512972
Downstream Train Epoch: 33 [12800/50000 (26%)]	Loss: 6.701482
Downstream Train Epoch: 33 [25600/50000 (51%)]	Loss: 11.667177
Downstream Train Epoch: 33 [38400/50000 (77%)]	Loss: 6.297762

 Downstream Train loss: 9.494377566843617 Acc: 0.3812
Downstream Train Epoch: 34 [0/50000 (0%)]	Loss: 7.652827
Downstream Train Epoch: 34 [12800/50000 (26%)]	Loss: 10.178103
Downstream Train Epoch: 34 [25600/50000 (51%)]	Loss: 10.946017
Downstream Train Epoch: 34 [38400/50000 (77%)]	Loss: 9.279351

 Downstream Train loss: 9.778923496908071 Acc: 0.3812
Downstream Train Epoch: 35 [0/50000 (0%)]	Loss: 14.412328
Downstream Train Epoch: 35 [12800/50000 (26%)]	Loss: 6.588429
Downstream Train Epoch: 35 [25600/50000 (51%)]	Loss: 7.406052
Downstream Train Epoch: 35 [38400/50000 (77%)]	Loss: 8.986112

 Downstream Train loss: 10.708866133981822 Acc: 0.3812
Downstream Train Epoch: 36 [0/50000 (0%)]	Loss: 9.164742
Downstream Train Epoch: 36 [12800/50000 (26%)]	Loss: 7.298624
Downstream Train Epoch: 36 [25600/50000 (51%)]	Loss: 9.150283
Downstream Train Epoch: 36 [38400/50000 (77%)]	Loss: 6.848989

 Downstream Train loss: 9.804111030637001 Acc: 0.3812
Downstream Train Epoch: 37 [0/50000 (0%)]	Loss: 14.484447
Downstream Train Epoch: 37 [12800/50000 (26%)]	Loss: 10.833592
Downstream Train Epoch: 37 [25600/50000 (51%)]	Loss: 12.135010
Downstream Train Epoch: 37 [38400/50000 (77%)]	Loss: 8.378747

 Downstream Train loss: 9.750850838057849 Acc: 0.3812
Downstream Train Epoch: 38 [0/50000 (0%)]	Loss: 11.540531
Downstream Train Epoch: 38 [12800/50000 (26%)]	Loss: 9.674006
Downstream Train Epoch: 38 [25600/50000 (51%)]	Loss: 11.136113
Downstream Train Epoch: 38 [38400/50000 (77%)]	Loss: 8.804089

 Downstream Train loss: 10.05624299876544 Acc: 0.3812
Downstream Train Epoch: 39 [0/50000 (0%)]	Loss: 17.303976
Downstream Train Epoch: 39 [12800/50000 (26%)]	Loss: 9.505428
Downstream Train Epoch: 39 [25600/50000 (51%)]	Loss: 12.104510
Downstream Train Epoch: 39 [38400/50000 (77%)]	Loss: 8.833740

 Downstream Train loss: 9.470386857889137 Acc: 0.3812
Downstream Train Epoch: 40 [0/50000 (0%)]	Loss: 9.638550
Downstream Train Epoch: 40 [12800/50000 (26%)]	Loss: 17.814690
Downstream Train Epoch: 40 [25600/50000 (51%)]	Loss: 11.459316
Downstream Train Epoch: 40 [38400/50000 (77%)]	Loss: 9.642298

 Downstream Train loss: 9.621877560810168 Acc: 0.3812
Downstream Train Epoch: 41 [0/50000 (0%)]	Loss: 20.176432
Downstream Train Epoch: 41 [12800/50000 (26%)]	Loss: 6.572196
Downstream Train Epoch: 41 [25600/50000 (51%)]	Loss: 7.734875
Downstream Train Epoch: 41 [38400/50000 (77%)]	Loss: 12.173558

 Downstream Train loss: 10.284950545855931 Acc: 0.3812
Downstream Train Epoch: 42 [0/50000 (0%)]	Loss: 7.355118
Downstream Train Epoch: 42 [12800/50000 (26%)]	Loss: 9.865825
Downstream Train Epoch: 42 [25600/50000 (51%)]	Loss: 9.962762
Downstream Train Epoch: 42 [38400/50000 (77%)]	Loss: 13.200664

 Downstream Train loss: 8.99668004804728 Acc: 0.3812
Downstream Train Epoch: 43 [0/50000 (0%)]	Loss: 9.719063
Downstream Train Epoch: 43 [12800/50000 (26%)]	Loss: 10.550612
Downstream Train Epoch: 43 [25600/50000 (51%)]	Loss: 8.888014
Downstream Train Epoch: 43 [38400/50000 (77%)]	Loss: 12.489849

 Downstream Train loss: 8.893884108991038 Acc: 0.3812
Downstream Train Epoch: 44 [0/50000 (0%)]	Loss: 10.214468
Downstream Train Epoch: 44 [12800/50000 (26%)]	Loss: 5.600134
Downstream Train Epoch: 44 [25600/50000 (51%)]	Loss: 9.451077
Downstream Train Epoch: 44 [38400/50000 (77%)]	Loss: 9.043454

 Downstream Train loss: 9.145263574561294 Acc: 0.3812
Downstream Train Epoch: 45 [0/50000 (0%)]	Loss: 14.116764
Downstream Train Epoch: 45 [12800/50000 (26%)]	Loss: 6.090770
Downstream Train Epoch: 45 [25600/50000 (51%)]	Loss: 12.851862
Downstream Train Epoch: 45 [38400/50000 (77%)]	Loss: 6.262472

 Downstream Train loss: 9.28204465398983 Acc: 0.3812
Downstream Train Epoch: 46 [0/50000 (0%)]	Loss: 9.219928
Downstream Train Epoch: 46 [12800/50000 (26%)]	Loss: 10.239299
Downstream Train Epoch: 46 [25600/50000 (51%)]	Loss: 8.299163
Downstream Train Epoch: 46 [38400/50000 (77%)]	Loss: 8.310873

 Downstream Train loss: 8.819903894346588 Acc: 0.3812
Downstream Train Epoch: 47 [0/50000 (0%)]	Loss: 8.834137
Downstream Train Epoch: 47 [12800/50000 (26%)]	Loss: 9.550756
Downstream Train Epoch: 47 [25600/50000 (51%)]	Loss: 8.861923
Downstream Train Epoch: 47 [38400/50000 (77%)]	Loss: 6.906050

 Downstream Train loss: 9.443560320503858 Acc: 0.3812
Downstream Train Epoch: 48 [0/50000 (0%)]	Loss: 10.082121
Downstream Train Epoch: 48 [12800/50000 (26%)]	Loss: 7.132880
Downstream Train Epoch: 48 [25600/50000 (51%)]	Loss: 6.849436
Downstream Train Epoch: 48 [38400/50000 (77%)]	Loss: 8.486774

 Downstream Train loss: 9.782683065959386 Acc: 0.3812
Downstream Train Epoch: 49 [0/50000 (0%)]	Loss: 17.048283
Downstream Train Epoch: 49 [12800/50000 (26%)]	Loss: 7.556250
Downstream Train Epoch: 49 [25600/50000 (51%)]	Loss: 5.930674
Downstream Train Epoch: 49 [38400/50000 (77%)]	Loss: 10.763815

 Downstream Train loss: 8.826501651686065 Acc: 0.3812
Downstream Train Epoch: 50 [0/50000 (0%)]	Loss: 8.418407
Downstream Train Epoch: 50 [12800/50000 (26%)]	Loss: 14.475901
Downstream Train Epoch: 50 [25600/50000 (51%)]	Loss: 11.576365
Downstream Train Epoch: 50 [38400/50000 (77%)]	Loss: 27.001076

 Downstream Train loss: 10.764893320142006 Acc: 0.3894
Downstream Train Epoch: 51 [0/50000 (0%)]	Loss: 6.305471
Downstream Train Epoch: 51 [12800/50000 (26%)]	Loss: 8.169298
Downstream Train Epoch: 51 [25600/50000 (51%)]	Loss: 8.619684
Downstream Train Epoch: 51 [38400/50000 (77%)]	Loss: 7.374681

 Downstream Train loss: 9.127515114083582 Acc: 0.3894
Downstream Train Epoch: 52 [0/50000 (0%)]	Loss: 8.046622
Downstream Train Epoch: 52 [12800/50000 (26%)]	Loss: 8.159205
Downstream Train Epoch: 52 [25600/50000 (51%)]	Loss: 6.103975
Downstream Train Epoch: 52 [38400/50000 (77%)]	Loss: 13.408587

 Downstream Train loss: 8.44187890753454 Acc: 0.3894
Downstream Train Epoch: 53 [0/50000 (0%)]	Loss: 8.301331
Downstream Train Epoch: 53 [12800/50000 (26%)]	Loss: 5.554335
Downstream Train Epoch: 53 [25600/50000 (51%)]	Loss: 8.069170
Downstream Train Epoch: 53 [38400/50000 (77%)]	Loss: 8.236937

 Downstream Train loss: 9.114320784198995 Acc: 0.3894
Downstream Train Epoch: 54 [0/50000 (0%)]	Loss: 12.815843
Downstream Train Epoch: 54 [12800/50000 (26%)]	Loss: 10.357703
Downstream Train Epoch: 54 [25600/50000 (51%)]	Loss: 6.321057
Downstream Train Epoch: 54 [38400/50000 (77%)]	Loss: 10.869332

 Downstream Train loss: 9.97911803576411 Acc: 0.3894
Downstream Train Epoch: 55 [0/50000 (0%)]	Loss: 8.692535
Downstream Train Epoch: 55 [12800/50000 (26%)]	Loss: 12.565154
Downstream Train Epoch: 55 [25600/50000 (51%)]	Loss: 6.916826
Downstream Train Epoch: 55 [38400/50000 (77%)]	Loss: 7.401742

 Downstream Train loss: 10.653108548144905 Acc: 0.3894
Downstream Train Epoch: 56 [0/50000 (0%)]	Loss: 7.835061
Downstream Train Epoch: 56 [12800/50000 (26%)]	Loss: 8.957150
Downstream Train Epoch: 56 [25600/50000 (51%)]	Loss: 5.481841
Downstream Train Epoch: 56 [38400/50000 (77%)]	Loss: 7.647156

 Downstream Train loss: 9.118405113414843 Acc: 0.3894
Downstream Train Epoch: 57 [0/50000 (0%)]	Loss: 19.080765
Downstream Train Epoch: 57 [12800/50000 (26%)]	Loss: 6.781640
Downstream Train Epoch: 57 [25600/50000 (51%)]	Loss: 6.932315
Downstream Train Epoch: 57 [38400/50000 (77%)]	Loss: 8.062301

 Downstream Train loss: 9.563712883968742 Acc: 0.3894
Downstream Train Epoch: 58 [0/50000 (0%)]	Loss: 11.883958
Downstream Train Epoch: 58 [12800/50000 (26%)]	Loss: 7.782126
Downstream Train Epoch: 58 [25600/50000 (51%)]	Loss: 10.849465
Downstream Train Epoch: 58 [38400/50000 (77%)]	Loss: 7.736431

 Downstream Train loss: 9.031574134923973 Acc: 0.3894
Downstream Train Epoch: 59 [0/50000 (0%)]	Loss: 11.077417
Downstream Train Epoch: 59 [12800/50000 (26%)]	Loss: 11.821301
Downstream Train Epoch: 59 [25600/50000 (51%)]	Loss: 7.984631
Downstream Train Epoch: 59 [38400/50000 (77%)]	Loss: 8.013080

 Downstream Train loss: 10.093475127706723 Acc: 0.3894
Downstream Train Epoch: 60 [0/50000 (0%)]	Loss: 11.347815
Downstream Train Epoch: 60 [12800/50000 (26%)]	Loss: 7.206073
Downstream Train Epoch: 60 [25600/50000 (51%)]	Loss: 6.710361
Downstream Train Epoch: 60 [38400/50000 (77%)]	Loss: 11.212915

 Downstream Train loss: 9.252186390818382 Acc: 0.3894
Classifier Accuracy for user 0 is 0.3894
Start tarining Classifier for user 1
Training classifier
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 4.538
Y partition skewness sampling
partition skew: 5 1.0 
10000 10000 0
len of skewed: 50000 len of unskewed: 0 data_num_per_user_skew: 10000
10000 5000 10000
partition skew: 5 1.0 
2000 2000 0
len of skewed: 10000 len of unskewed: 0 data_num_per_user_skew: 2000
2000 1000 2000
sample dataset time: 0.006
user data samples: [10000, 10000, 10000, 10000, 10000]
begin training classifier...
Downstream Train Epoch: 1 [0/50000 (0%)]	Loss: 217.928406
Downstream Train Epoch: 1 [12800/50000 (26%)]	Loss: 28.151548
Downstream Train Epoch: 1 [25600/50000 (51%)]	Loss: 25.561144
Downstream Train Epoch: 1 [38400/50000 (77%)]	Loss: 23.305389

 Downstream Train loss: 32.58566623804521 Acc: 0.2684
Downstream Train Epoch: 2 [0/50000 (0%)]	Loss: 24.825994
Downstream Train Epoch: 2 [12800/50000 (26%)]	Loss: 18.047468
Downstream Train Epoch: 2 [25600/50000 (51%)]	Loss: 17.589575
Downstream Train Epoch: 2 [38400/50000 (77%)]	Loss: 16.560272

 Downstream Train loss: 18.85757507596697 Acc: 0.3111
Downstream Train Epoch: 3 [0/50000 (0%)]	Loss: 19.078289
Downstream Train Epoch: 3 [12800/50000 (26%)]	Loss: 16.598932
Downstream Train Epoch: 3 [25600/50000 (51%)]	Loss: 19.727013
Downstream Train Epoch: 3 [38400/50000 (77%)]	Loss: 13.869768

 Downstream Train loss: 16.686874506424886 Acc: 0.3166
Downstream Train Epoch: 4 [0/50000 (0%)]	Loss: 17.605885
Downstream Train Epoch: 4 [12800/50000 (26%)]	Loss: 16.112055
Downstream Train Epoch: 4 [25600/50000 (51%)]	Loss: 14.656096
Downstream Train Epoch: 4 [38400/50000 (77%)]	Loss: 15.612507

 Downstream Train loss: 14.844083080486376 Acc: 0.3214
Downstream Train Epoch: 5 [0/50000 (0%)]	Loss: 15.121382
Downstream Train Epoch: 5 [12800/50000 (26%)]	Loss: 16.646313
Downstream Train Epoch: 5 [25600/50000 (51%)]	Loss: 14.835752
Downstream Train Epoch: 5 [38400/50000 (77%)]	Loss: 10.914947

 Downstream Train loss: 14.876872344892853 Acc: 0.3214
Downstream Train Epoch: 6 [0/50000 (0%)]	Loss: 14.804866
Downstream Train Epoch: 6 [12800/50000 (26%)]	Loss: 14.137927
Downstream Train Epoch: 6 [25600/50000 (51%)]	Loss: 13.088612
Downstream Train Epoch: 6 [38400/50000 (77%)]	Loss: 11.723671

 Downstream Train loss: 14.25707669160804 Acc: 0.3214
Downstream Train Epoch: 7 [0/50000 (0%)]	Loss: 13.612176
Downstream Train Epoch: 7 [12800/50000 (26%)]	Loss: 11.730216
Downstream Train Epoch: 7 [25600/50000 (51%)]	Loss: 19.919273
Downstream Train Epoch: 7 [38400/50000 (77%)]	Loss: 11.818533

 Downstream Train loss: 13.61696261775737 Acc: 0.3459
Downstream Train Epoch: 8 [0/50000 (0%)]	Loss: 10.491835
Downstream Train Epoch: 8 [12800/50000 (26%)]	Loss: 10.003669
Downstream Train Epoch: 8 [25600/50000 (51%)]	Loss: 13.738173
Downstream Train Epoch: 8 [38400/50000 (77%)]	Loss: 13.088056

 Downstream Train loss: 12.883187741649394 Acc: 0.3459
Downstream Train Epoch: 9 [0/50000 (0%)]	Loss: 13.829563
Downstream Train Epoch: 9 [12800/50000 (26%)]	Loss: 12.268987
Downstream Train Epoch: 9 [25600/50000 (51%)]	Loss: 13.060909
Downstream Train Epoch: 9 [38400/50000 (77%)]	Loss: 10.403359

 Downstream Train loss: 12.733579728068138 Acc: 0.3459
Downstream Train Epoch: 10 [0/50000 (0%)]	Loss: 15.614625
Downstream Train Epoch: 10 [12800/50000 (26%)]	Loss: 11.037384
Downstream Train Epoch: 10 [25600/50000 (51%)]	Loss: 13.441059
Downstream Train Epoch: 10 [38400/50000 (77%)]	Loss: 12.941460

 Downstream Train loss: 13.41843655887915 Acc: 0.3459
Downstream Train Epoch: 11 [0/50000 (0%)]	Loss: 17.098726
Downstream Train Epoch: 11 [12800/50000 (26%)]	Loss: 13.617846
Downstream Train Epoch: 11 [25600/50000 (51%)]	Loss: 16.781202
Downstream Train Epoch: 11 [38400/50000 (77%)]	Loss: 12.315407

 Downstream Train loss: 12.303706113173037 Acc: 0.3459
Downstream Train Epoch: 12 [0/50000 (0%)]	Loss: 10.427897
Downstream Train Epoch: 12 [12800/50000 (26%)]	Loss: 16.547094
Downstream Train Epoch: 12 [25600/50000 (51%)]	Loss: 13.139820
Downstream Train Epoch: 12 [38400/50000 (77%)]	Loss: 14.817912

 Downstream Train loss: 12.092494217716919 Acc: 0.358
Downstream Train Epoch: 13 [0/50000 (0%)]	Loss: 12.841919
Downstream Train Epoch: 13 [12800/50000 (26%)]	Loss: 10.394144
Downstream Train Epoch: 13 [25600/50000 (51%)]	Loss: 12.371713
Downstream Train Epoch: 13 [38400/50000 (77%)]	Loss: 9.801739

 Downstream Train loss: 12.563395488018893 Acc: 0.358
Downstream Train Epoch: 14 [0/50000 (0%)]	Loss: 13.147470
Downstream Train Epoch: 14 [12800/50000 (26%)]	Loss: 11.676311
Downstream Train Epoch: 14 [25600/50000 (51%)]	Loss: 7.645571
Downstream Train Epoch: 14 [38400/50000 (77%)]	Loss: 12.541951

 Downstream Train loss: 11.931091578639283 Acc: 0.358
Downstream Train Epoch: 15 [0/50000 (0%)]	Loss: 17.188698
Downstream Train Epoch: 15 [12800/50000 (26%)]	Loss: 8.466512
Downstream Train Epoch: 15 [25600/50000 (51%)]	Loss: 8.090708
Downstream Train Epoch: 15 [38400/50000 (77%)]	Loss: 6.706391

 Downstream Train loss: 10.667337137825635 Acc: 0.358
Downstream Train Epoch: 16 [0/50000 (0%)]	Loss: 17.772938
Downstream Train Epoch: 16 [12800/50000 (26%)]	Loss: 14.399247
Downstream Train Epoch: 16 [25600/50000 (51%)]	Loss: 16.013857
Downstream Train Epoch: 16 [38400/50000 (77%)]	Loss: 14.077895

 Downstream Train loss: 13.827344381079381 Acc: 0.358
Downstream Train Epoch: 17 [0/50000 (0%)]	Loss: 13.147467
Downstream Train Epoch: 17 [12800/50000 (26%)]	Loss: 8.564551
Downstream Train Epoch: 17 [25600/50000 (51%)]	Loss: 9.531984
Downstream Train Epoch: 17 [38400/50000 (77%)]	Loss: 8.601207

 Downstream Train loss: 10.867035289199984 Acc: 0.358
Downstream Train Epoch: 18 [0/50000 (0%)]	Loss: 14.131686
Downstream Train Epoch: 18 [12800/50000 (26%)]	Loss: 7.925330
Downstream Train Epoch: 18 [25600/50000 (51%)]	Loss: 11.987267
Downstream Train Epoch: 18 [38400/50000 (77%)]	Loss: 8.821867

 Downstream Train loss: 10.657102351285973 Acc: 0.3795
Downstream Train Epoch: 19 [0/50000 (0%)]	Loss: 6.373715
Downstream Train Epoch: 19 [12800/50000 (26%)]	Loss: 12.340589
Downstream Train Epoch: 19 [25600/50000 (51%)]	Loss: 14.379089
Downstream Train Epoch: 19 [38400/50000 (77%)]	Loss: 13.167339

 Downstream Train loss: 13.168229696701983 Acc: 0.4067
Downstream Train Epoch: 20 [0/50000 (0%)]	Loss: 10.877636
Downstream Train Epoch: 20 [12800/50000 (26%)]	Loss: 8.841948
Downstream Train Epoch: 20 [25600/50000 (51%)]	Loss: 11.124154
Downstream Train Epoch: 20 [38400/50000 (77%)]	Loss: 9.267946

 Downstream Train loss: 11.209023300482302 Acc: 0.4067
Downstream Train Epoch: 21 [0/50000 (0%)]	Loss: 12.275923
Downstream Train Epoch: 21 [12800/50000 (26%)]	Loss: 10.626214
Downstream Train Epoch: 21 [25600/50000 (51%)]	Loss: 15.585456
Downstream Train Epoch: 21 [38400/50000 (77%)]	Loss: 10.273379

 Downstream Train loss: 10.84497019709373 Acc: 0.4067
Downstream Train Epoch: 22 [0/50000 (0%)]	Loss: 9.355240
Downstream Train Epoch: 22 [12800/50000 (26%)]	Loss: 12.587361
Downstream Train Epoch: 22 [25600/50000 (51%)]	Loss: 10.088923
Downstream Train Epoch: 22 [38400/50000 (77%)]	Loss: 12.100030

 Downstream Train loss: 11.27722951100797 Acc: 0.4067
Downstream Train Epoch: 23 [0/50000 (0%)]	Loss: 11.925175
Downstream Train Epoch: 23 [12800/50000 (26%)]	Loss: 9.990794
Downstream Train Epoch: 23 [25600/50000 (51%)]	Loss: 15.006476
Downstream Train Epoch: 23 [38400/50000 (77%)]	Loss: 10.816569

 Downstream Train loss: 11.358550918345548 Acc: 0.4067
Downstream Train Epoch: 24 [0/50000 (0%)]	Loss: 11.142727
Downstream Train Epoch: 24 [12800/50000 (26%)]	Loss: 10.339970
Downstream Train Epoch: 24 [25600/50000 (51%)]	Loss: 12.565052
Downstream Train Epoch: 24 [38400/50000 (77%)]	Loss: 14.617738

 Downstream Train loss: 11.227947621929403 Acc: 0.4067
Downstream Train Epoch: 25 [0/50000 (0%)]	Loss: 9.436628
Downstream Train Epoch: 25 [12800/50000 (26%)]	Loss: 8.297701
Downstream Train Epoch: 25 [25600/50000 (51%)]	Loss: 10.441064
Downstream Train Epoch: 25 [38400/50000 (77%)]	Loss: 8.675219

 Downstream Train loss: 10.94986320271784 Acc: 0.4067
Downstream Train Epoch: 26 [0/50000 (0%)]	Loss: 17.415188
Downstream Train Epoch: 26 [12800/50000 (26%)]	Loss: 12.419275
Downstream Train Epoch: 26 [25600/50000 (51%)]	Loss: 15.925610
Downstream Train Epoch: 26 [38400/50000 (77%)]	Loss: 16.182055

 Downstream Train loss: 12.300733634403773 Acc: 0.4067
Downstream Train Epoch: 27 [0/50000 (0%)]	Loss: 17.374004
Downstream Train Epoch: 27 [12800/50000 (26%)]	Loss: 15.310078
Downstream Train Epoch: 27 [25600/50000 (51%)]	Loss: 14.583478
Downstream Train Epoch: 27 [38400/50000 (77%)]	Loss: 10.326166

 Downstream Train loss: 12.18381531871095 Acc: 0.4067
Downstream Train Epoch: 28 [0/50000 (0%)]	Loss: 10.075203
Downstream Train Epoch: 28 [12800/50000 (26%)]	Loss: 11.396505
Downstream Train Epoch: 28 [25600/50000 (51%)]	Loss: 8.180338
Downstream Train Epoch: 28 [38400/50000 (77%)]	Loss: 9.739110

 Downstream Train loss: 12.26175832748413 Acc: 0.4067
Downstream Train Epoch: 29 [0/50000 (0%)]	Loss: 14.084393
Downstream Train Epoch: 29 [12800/50000 (26%)]	Loss: 8.473762
Downstream Train Epoch: 29 [25600/50000 (51%)]	Loss: 12.111894
Downstream Train Epoch: 29 [38400/50000 (77%)]	Loss: 11.005473

 Downstream Train loss: 10.882595989168907 Acc: 0.4067
Downstream Train Epoch: 30 [0/50000 (0%)]	Loss: 14.364600
Downstream Train Epoch: 30 [12800/50000 (26%)]	Loss: 7.010047
Downstream Train Epoch: 30 [25600/50000 (51%)]	Loss: 11.352438
Downstream Train Epoch: 30 [38400/50000 (77%)]	Loss: 12.315659

 Downstream Train loss: 12.28319805495593 Acc: 0.4067
Downstream Train Epoch: 31 [0/50000 (0%)]	Loss: 16.414557
Downstream Train Epoch: 31 [12800/50000 (26%)]	Loss: 11.950760
Downstream Train Epoch: 31 [25600/50000 (51%)]	Loss: 8.979573
Downstream Train Epoch: 31 [38400/50000 (77%)]	Loss: 9.824339

 Downstream Train loss: 10.653728363465289 Acc: 0.4067
Downstream Train Epoch: 32 [0/50000 (0%)]	Loss: 12.027724
Downstream Train Epoch: 32 [12800/50000 (26%)]	Loss: 11.872219
Downstream Train Epoch: 32 [25600/50000 (51%)]	Loss: 14.371096
Downstream Train Epoch: 32 [38400/50000 (77%)]	Loss: 8.929916

 Downstream Train loss: 10.558619903058421 Acc: 0.4067
Downstream Train Epoch: 33 [0/50000 (0%)]	Loss: 8.680180
Downstream Train Epoch: 33 [12800/50000 (26%)]	Loss: 8.919925
Downstream Train Epoch: 33 [25600/50000 (51%)]	Loss: 10.101883
Downstream Train Epoch: 33 [38400/50000 (77%)]	Loss: 12.215151

 Downstream Train loss: 11.447274952518697 Acc: 0.4067
Downstream Train Epoch: 34 [0/50000 (0%)]	Loss: 8.120071
Downstream Train Epoch: 34 [12800/50000 (26%)]	Loss: 9.632539
Downstream Train Epoch: 34 [25600/50000 (51%)]	Loss: 14.231231
Downstream Train Epoch: 34 [38400/50000 (77%)]	Loss: 7.123439

 Downstream Train loss: 10.62813220948589 Acc: 0.4067
Downstream Train Epoch: 35 [0/50000 (0%)]	Loss: 10.833332
Downstream Train Epoch: 35 [12800/50000 (26%)]	Loss: 12.515696
Downstream Train Epoch: 35 [25600/50000 (51%)]	Loss: 7.758090
Downstream Train Epoch: 35 [38400/50000 (77%)]	Loss: 6.700445

 Downstream Train loss: 11.434309509335732 Acc: 0.4067
Downstream Train Epoch: 36 [0/50000 (0%)]	Loss: 20.020090
Downstream Train Epoch: 36 [12800/50000 (26%)]	Loss: 9.537758
Downstream Train Epoch: 36 [25600/50000 (51%)]	Loss: 14.904119
Downstream Train Epoch: 36 [38400/50000 (77%)]	Loss: 14.054913

 Downstream Train loss: 12.357639731193075 Acc: 0.4067
Downstream Train Epoch: 37 [0/50000 (0%)]	Loss: 12.079954
Downstream Train Epoch: 37 [12800/50000 (26%)]	Loss: 17.431583
Downstream Train Epoch: 37 [25600/50000 (51%)]	Loss: 7.187300
Downstream Train Epoch: 37 [38400/50000 (77%)]	Loss: 10.723692

 Downstream Train loss: 10.839440085449997 Acc: 0.4067
Downstream Train Epoch: 38 [0/50000 (0%)]	Loss: 9.358260
Downstream Train Epoch: 38 [12800/50000 (26%)]	Loss: 7.044330
Downstream Train Epoch: 38 [25600/50000 (51%)]	Loss: 10.888930
Downstream Train Epoch: 38 [38400/50000 (77%)]	Loss: 8.537694

 Downstream Train loss: 10.423535028282476 Acc: 0.4067
Downstream Train Epoch: 39 [0/50000 (0%)]	Loss: 11.377551
Downstream Train Epoch: 39 [12800/50000 (26%)]	Loss: 13.921674
Downstream Train Epoch: 39 [25600/50000 (51%)]	Loss: 8.941051
Downstream Train Epoch: 39 [38400/50000 (77%)]	Loss: 7.140465

 Downstream Train loss: 11.909757057014776 Acc: 0.4067
Downstream Train Epoch: 40 [0/50000 (0%)]	Loss: 8.404897
Downstream Train Epoch: 40 [12800/50000 (26%)]	Loss: 10.819953
Downstream Train Epoch: 40 [25600/50000 (51%)]	Loss: 12.001642
Downstream Train Epoch: 40 [38400/50000 (77%)]	Loss: 8.243521

 Downstream Train loss: 11.201573447305329 Acc: 0.4067
Downstream Train Epoch: 41 [0/50000 (0%)]	Loss: 11.543057
Downstream Train Epoch: 41 [12800/50000 (26%)]	Loss: 13.621519
Downstream Train Epoch: 41 [25600/50000 (51%)]	Loss: 9.635542
Downstream Train Epoch: 41 [38400/50000 (77%)]	Loss: 8.112277

 Downstream Train loss: 11.159792600845805 Acc: 0.4067
Downstream Train Epoch: 42 [0/50000 (0%)]	Loss: 15.188588
Downstream Train Epoch: 42 [12800/50000 (26%)]	Loss: 6.864702
Downstream Train Epoch: 42 [25600/50000 (51%)]	Loss: 9.397671
Downstream Train Epoch: 42 [38400/50000 (77%)]	Loss: 8.185219

 Downstream Train loss: 10.578950059657194 Acc: 0.4067
Downstream Train Epoch: 43 [0/50000 (0%)]	Loss: 13.992795
Downstream Train Epoch: 43 [12800/50000 (26%)]	Loss: 12.618561
Downstream Train Epoch: 43 [25600/50000 (51%)]	Loss: 21.563429
Downstream Train Epoch: 43 [38400/50000 (77%)]	Loss: 12.553567

 Downstream Train loss: 12.586929627827235 Acc: 0.4067
Downstream Train Epoch: 44 [0/50000 (0%)]	Loss: 13.590523
Downstream Train Epoch: 44 [12800/50000 (26%)]	Loss: 14.268360
Downstream Train Epoch: 44 [25600/50000 (51%)]	Loss: 13.760082
Downstream Train Epoch: 44 [38400/50000 (77%)]	Loss: 14.953611

 Downstream Train loss: 11.283526333010926 Acc: 0.4067
Downstream Train Epoch: 45 [0/50000 (0%)]	Loss: 8.591496
Downstream Train Epoch: 45 [12800/50000 (26%)]	Loss: 16.911528
Downstream Train Epoch: 45 [25600/50000 (51%)]	Loss: 8.724184
Downstream Train Epoch: 45 [38400/50000 (77%)]	Loss: 13.033657

 Downstream Train loss: 11.76463072397271 Acc: 0.4067
Downstream Train Epoch: 46 [0/50000 (0%)]	Loss: 19.563437
Downstream Train Epoch: 46 [12800/50000 (26%)]	Loss: 12.066850
Downstream Train Epoch: 46 [25600/50000 (51%)]	Loss: 9.880363
Downstream Train Epoch: 46 [38400/50000 (77%)]	Loss: 12.569386

 Downstream Train loss: 11.483434355988795 Acc: 0.4067
Downstream Train Epoch: 47 [0/50000 (0%)]	Loss: 13.410584
Downstream Train Epoch: 47 [12800/50000 (26%)]	Loss: 12.651596
Downstream Train Epoch: 47 [25600/50000 (51%)]	Loss: 11.203195
Downstream Train Epoch: 47 [38400/50000 (77%)]	Loss: 8.488769

 Downstream Train loss: 11.50605240889958 Acc: 0.4067
Downstream Train Epoch: 48 [0/50000 (0%)]	Loss: 9.701601
Downstream Train Epoch: 48 [12800/50000 (26%)]	Loss: 13.396945
Downstream Train Epoch: 48 [25600/50000 (51%)]	Loss: 11.990385
Downstream Train Epoch: 48 [38400/50000 (77%)]	Loss: 11.792230

 Downstream Train loss: 11.509708261003299 Acc: 0.4067
Downstream Train Epoch: 49 [0/50000 (0%)]	Loss: 12.242827
Downstream Train Epoch: 49 [12800/50000 (26%)]	Loss: 13.682187
Downstream Train Epoch: 49 [25600/50000 (51%)]	Loss: 10.177217
Downstream Train Epoch: 49 [38400/50000 (77%)]	Loss: 10.433689

 Downstream Train loss: 11.591037253944242 Acc: 0.4067
Downstream Train Epoch: 50 [0/50000 (0%)]	Loss: 9.325935
Downstream Train Epoch: 50 [12800/50000 (26%)]	Loss: 11.214801
Downstream Train Epoch: 50 [25600/50000 (51%)]	Loss: 24.057190
Downstream Train Epoch: 50 [38400/50000 (77%)]	Loss: 11.988653

 Downstream Train loss: 11.538624291517296 Acc: 0.4067
Downstream Train Epoch: 51 [0/50000 (0%)]	Loss: 7.869634
Downstream Train Epoch: 51 [12800/50000 (26%)]	Loss: 10.896385
Downstream Train Epoch: 51 [25600/50000 (51%)]	Loss: 11.540883
Downstream Train Epoch: 51 [38400/50000 (77%)]	Loss: 16.031071

 Downstream Train loss: 11.112425210524579 Acc: 0.4067
Downstream Train Epoch: 52 [0/50000 (0%)]	Loss: 9.569229
Downstream Train Epoch: 52 [12800/50000 (26%)]	Loss: 11.117022
Downstream Train Epoch: 52 [25600/50000 (51%)]	Loss: 12.890663
Downstream Train Epoch: 52 [38400/50000 (77%)]	Loss: 9.811029

 Downstream Train loss: 11.142932558546262 Acc: 0.4067
Downstream Train Epoch: 53 [0/50000 (0%)]	Loss: 20.754103
Downstream Train Epoch: 53 [12800/50000 (26%)]	Loss: 9.554338
Downstream Train Epoch: 53 [25600/50000 (51%)]	Loss: 7.841595
Downstream Train Epoch: 53 [38400/50000 (77%)]	Loss: 13.690664

 Downstream Train loss: 11.76240914695117 Acc: 0.4067
Downstream Train Epoch: 54 [0/50000 (0%)]	Loss: 11.008781
Downstream Train Epoch: 54 [12800/50000 (26%)]	Loss: 8.170920
Downstream Train Epoch: 54 [25600/50000 (51%)]	Loss: 11.908230
Downstream Train Epoch: 54 [38400/50000 (77%)]	Loss: 10.321805

 Downstream Train loss: 10.397191266624295 Acc: 0.4067
Downstream Train Epoch: 55 [0/50000 (0%)]	Loss: 11.064902
Downstream Train Epoch: 55 [12800/50000 (26%)]	Loss: 9.103711
Downstream Train Epoch: 55 [25600/50000 (51%)]	Loss: 14.220719
Downstream Train Epoch: 55 [38400/50000 (77%)]	Loss: 10.226611

 Downstream Train loss: 12.26050011722409 Acc: 0.4067
Downstream Train Epoch: 56 [0/50000 (0%)]	Loss: 12.661866
Downstream Train Epoch: 56 [12800/50000 (26%)]	Loss: 9.130543
Downstream Train Epoch: 56 [25600/50000 (51%)]	Loss: 8.643729
Downstream Train Epoch: 56 [38400/50000 (77%)]	Loss: 19.929415

 Downstream Train loss: 11.959381390591057 Acc: 0.4067
Downstream Train Epoch: 57 [0/50000 (0%)]	Loss: 11.433498
Downstream Train Epoch: 57 [12800/50000 (26%)]	Loss: 12.238765
Downstream Train Epoch: 57 [25600/50000 (51%)]	Loss: 10.376558
Downstream Train Epoch: 57 [38400/50000 (77%)]	Loss: 6.722814

 Downstream Train loss: 10.667591014686895 Acc: 0.4067
Downstream Train Epoch: 58 [0/50000 (0%)]	Loss: 7.010750
Downstream Train Epoch: 58 [12800/50000 (26%)]	Loss: 20.288754
Downstream Train Epoch: 58 [25600/50000 (51%)]	Loss: 7.377209
Downstream Train Epoch: 58 [38400/50000 (77%)]	Loss: 11.989516

 Downstream Train loss: 12.016269859002561 Acc: 0.4067
Downstream Train Epoch: 59 [0/50000 (0%)]	Loss: 16.541426
Downstream Train Epoch: 59 [12800/50000 (26%)]	Loss: 7.943828
Downstream Train Epoch: 59 [25600/50000 (51%)]	Loss: 8.643916
Downstream Train Epoch: 59 [38400/50000 (77%)]	Loss: 6.215995

 Downstream Train loss: 10.556796626168854 Acc: 0.4067
Downstream Train Epoch: 60 [0/50000 (0%)]	Loss: 7.820566
Downstream Train Epoch: 60 [12800/50000 (26%)]	Loss: 13.964274
Downstream Train Epoch: 60 [25600/50000 (51%)]	Loss: 13.485079
Downstream Train Epoch: 60 [38400/50000 (77%)]	Loss: 9.710356

 Downstream Train loss: 11.35027270171107 Acc: 0.4067
Classifier Accuracy for user 1 is 0.4067
Start tarining Classifier for user 2
Training classifier
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 4.723
Y partition skewness sampling
partition skew: 5 1.0 
10000 10000 0
len of skewed: 50000 len of unskewed: 0 data_num_per_user_skew: 10000
10000 5000 10000
partition skew: 5 1.0 
2000 2000 0
len of skewed: 10000 len of unskewed: 0 data_num_per_user_skew: 2000
2000 1000 2000
sample dataset time: 0.007
user data samples: [10000, 10000, 10000, 10000, 10000]
begin training classifier...
Downstream Train Epoch: 1 [0/50000 (0%)]	Loss: 261.155884
Downstream Train Epoch: 1 [12800/50000 (26%)]	Loss: 40.050072
Downstream Train Epoch: 1 [25600/50000 (51%)]	Loss: 27.427263
Downstream Train Epoch: 1 [38400/50000 (77%)]	Loss: 28.223227

 Downstream Train loss: 38.41672021515515 Acc: 0.3061
Downstream Train Epoch: 2 [0/50000 (0%)]	Loss: 23.968168
Downstream Train Epoch: 2 [12800/50000 (26%)]	Loss: 20.459414
Downstream Train Epoch: 2 [25600/50000 (51%)]	Loss: 18.792860
Downstream Train Epoch: 2 [38400/50000 (77%)]	Loss: 20.960125

 Downstream Train loss: 22.054467488308344 Acc: 0.3061
Downstream Train Epoch: 3 [0/50000 (0%)]	Loss: 22.710384
Downstream Train Epoch: 3 [12800/50000 (26%)]	Loss: 19.895859
Downstream Train Epoch: 3 [25600/50000 (51%)]	Loss: 17.755611
Downstream Train Epoch: 3 [38400/50000 (77%)]	Loss: 16.407228

 Downstream Train loss: 19.89057253331554 Acc: 0.3081
Downstream Train Epoch: 4 [0/50000 (0%)]	Loss: 20.084251
Downstream Train Epoch: 4 [12800/50000 (26%)]	Loss: 19.006336
Downstream Train Epoch: 4 [25600/50000 (51%)]	Loss: 16.833918
Downstream Train Epoch: 4 [38400/50000 (77%)]	Loss: 15.678024

 Downstream Train loss: 17.950987397408 Acc: 0.3081
Downstream Train Epoch: 5 [0/50000 (0%)]	Loss: 20.106615
Downstream Train Epoch: 5 [12800/50000 (26%)]	Loss: 21.661867
Downstream Train Epoch: 5 [25600/50000 (51%)]	Loss: 22.327887
Downstream Train Epoch: 5 [38400/50000 (77%)]	Loss: 13.156786

 Downstream Train loss: 17.416243694266495 Acc: 0.3081
Downstream Train Epoch: 6 [0/50000 (0%)]	Loss: 19.593300
Downstream Train Epoch: 6 [12800/50000 (26%)]	Loss: 19.666115
Downstream Train Epoch: 6 [25600/50000 (51%)]	Loss: 18.358442
Downstream Train Epoch: 6 [38400/50000 (77%)]	Loss: 18.197540

 Downstream Train loss: 17.227258035114833 Acc: 0.3174
Downstream Train Epoch: 7 [0/50000 (0%)]	Loss: 17.628048
Downstream Train Epoch: 7 [12800/50000 (26%)]	Loss: 17.305355
Downstream Train Epoch: 7 [25600/50000 (51%)]	Loss: 13.765614
Downstream Train Epoch: 7 [38400/50000 (77%)]	Loss: 16.421383

 Downstream Train loss: 15.381726678536863 Acc: 0.3174
Downstream Train Epoch: 8 [0/50000 (0%)]	Loss: 19.125475
Downstream Train Epoch: 8 [12800/50000 (26%)]	Loss: 13.923334
Downstream Train Epoch: 8 [25600/50000 (51%)]	Loss: 15.404346
Downstream Train Epoch: 8 [38400/50000 (77%)]	Loss: 20.164402

 Downstream Train loss: 14.542556164216021 Acc: 0.3174
Downstream Train Epoch: 9 [0/50000 (0%)]	Loss: 18.944235
Downstream Train Epoch: 9 [12800/50000 (26%)]	Loss: 11.075982
Downstream Train Epoch: 9 [25600/50000 (51%)]	Loss: 16.596539
Downstream Train Epoch: 9 [38400/50000 (77%)]	Loss: 15.413864

 Downstream Train loss: 15.806617775741888 Acc: 0.3174
Downstream Train Epoch: 10 [0/50000 (0%)]	Loss: 16.777184
Downstream Train Epoch: 10 [12800/50000 (26%)]	Loss: 18.247559
Downstream Train Epoch: 10 [25600/50000 (51%)]	Loss: 15.996465
Downstream Train Epoch: 10 [38400/50000 (77%)]	Loss: 34.764923

 Downstream Train loss: 16.82578108748611 Acc: 0.3668
Downstream Train Epoch: 11 [0/50000 (0%)]	Loss: 13.437387
Downstream Train Epoch: 11 [12800/50000 (26%)]	Loss: 13.927352
Downstream Train Epoch: 11 [25600/50000 (51%)]	Loss: 13.055700
Downstream Train Epoch: 11 [38400/50000 (77%)]	Loss: 14.131696

 Downstream Train loss: 15.697905156077171 Acc: 0.3707
Downstream Train Epoch: 12 [0/50000 (0%)]	Loss: 11.423730
Downstream Train Epoch: 12 [12800/50000 (26%)]	Loss: 21.775146
Downstream Train Epoch: 12 [25600/50000 (51%)]	Loss: 10.933434
Downstream Train Epoch: 12 [38400/50000 (77%)]	Loss: 14.048236

 Downstream Train loss: 14.334633754224193 Acc: 0.3951
Downstream Train Epoch: 13 [0/50000 (0%)]	Loss: 9.647713
Downstream Train Epoch: 13 [12800/50000 (26%)]	Loss: 12.338349
Downstream Train Epoch: 13 [25600/50000 (51%)]	Loss: 15.307285
Downstream Train Epoch: 13 [38400/50000 (77%)]	Loss: 12.044160

 Downstream Train loss: 13.811869144439697 Acc: 0.3951
Downstream Train Epoch: 14 [0/50000 (0%)]	Loss: 12.708611
Downstream Train Epoch: 14 [12800/50000 (26%)]	Loss: 17.727919
Downstream Train Epoch: 14 [25600/50000 (51%)]	Loss: 13.460768
Downstream Train Epoch: 14 [38400/50000 (77%)]	Loss: 11.802180

 Downstream Train loss: 13.169876047543116 Acc: 0.3951
Downstream Train Epoch: 15 [0/50000 (0%)]	Loss: 11.351107
Downstream Train Epoch: 15 [12800/50000 (26%)]	Loss: 14.121271
Downstream Train Epoch: 15 [25600/50000 (51%)]	Loss: 14.663922
Downstream Train Epoch: 15 [38400/50000 (77%)]	Loss: 18.069878

 Downstream Train loss: 15.934427387860357 Acc: 0.3951
Downstream Train Epoch: 16 [0/50000 (0%)]	Loss: 15.034121
Downstream Train Epoch: 16 [12800/50000 (26%)]	Loss: 13.030545
Downstream Train Epoch: 16 [25600/50000 (51%)]	Loss: 9.827847
Downstream Train Epoch: 16 [38400/50000 (77%)]	Loss: 21.495993

 Downstream Train loss: 14.460389200521975 Acc: 0.3951
Downstream Train Epoch: 17 [0/50000 (0%)]	Loss: 13.571868
Downstream Train Epoch: 17 [12800/50000 (26%)]	Loss: 13.502580
Downstream Train Epoch: 17 [25600/50000 (51%)]	Loss: 12.806800
Downstream Train Epoch: 17 [38400/50000 (77%)]	Loss: 11.633986

 Downstream Train loss: 13.163205613895338 Acc: 0.3951
Downstream Train Epoch: 18 [0/50000 (0%)]	Loss: 17.233641
Downstream Train Epoch: 18 [12800/50000 (26%)]	Loss: 13.564899
Downstream Train Epoch: 18 [25600/50000 (51%)]	Loss: 11.559453
Downstream Train Epoch: 18 [38400/50000 (77%)]	Loss: 10.751322

 Downstream Train loss: 14.486765715540672 Acc: 0.3951
Downstream Train Epoch: 19 [0/50000 (0%)]	Loss: 14.045877
Downstream Train Epoch: 19 [12800/50000 (26%)]	Loss: 8.257648
Downstream Train Epoch: 19 [25600/50000 (51%)]	Loss: 10.096794
Downstream Train Epoch: 19 [38400/50000 (77%)]	Loss: 9.295637

 Downstream Train loss: 13.465479505305387 Acc: 0.3951
Downstream Train Epoch: 20 [0/50000 (0%)]	Loss: 11.962914
Downstream Train Epoch: 20 [12800/50000 (26%)]	Loss: 15.922344
Downstream Train Epoch: 20 [25600/50000 (51%)]	Loss: 17.220415
Downstream Train Epoch: 20 [38400/50000 (77%)]	Loss: 21.162613

 Downstream Train loss: 14.907425792849793 Acc: 0.3951
Downstream Train Epoch: 21 [0/50000 (0%)]	Loss: 9.902736
Downstream Train Epoch: 21 [12800/50000 (26%)]	Loss: 10.487875
Downstream Train Epoch: 21 [25600/50000 (51%)]	Loss: 11.916252
Downstream Train Epoch: 21 [38400/50000 (77%)]	Loss: 11.245338

 Downstream Train loss: 13.22898041472143 Acc: 0.3951
Downstream Train Epoch: 22 [0/50000 (0%)]	Loss: 8.756401
Downstream Train Epoch: 22 [12800/50000 (26%)]	Loss: 16.357967
Downstream Train Epoch: 22 [25600/50000 (51%)]	Loss: 16.916321
Downstream Train Epoch: 22 [38400/50000 (77%)]	Loss: 11.124831

 Downstream Train loss: 13.298142036613154 Acc: 0.3951
Downstream Train Epoch: 23 [0/50000 (0%)]	Loss: 13.532921
Downstream Train Epoch: 23 [12800/50000 (26%)]	Loss: 12.483027
Downstream Train Epoch: 23 [25600/50000 (51%)]	Loss: 14.987633
Downstream Train Epoch: 23 [38400/50000 (77%)]	Loss: 10.167221

 Downstream Train loss: 14.866609495513293 Acc: 0.3951
Downstream Train Epoch: 24 [0/50000 (0%)]	Loss: 10.979814
Downstream Train Epoch: 24 [12800/50000 (26%)]	Loss: 19.784269
Downstream Train Epoch: 24 [25600/50000 (51%)]	Loss: 12.001968
Downstream Train Epoch: 24 [38400/50000 (77%)]	Loss: 19.935453

 Downstream Train loss: 13.571733489328501 Acc: 0.3951
Downstream Train Epoch: 25 [0/50000 (0%)]	Loss: 18.056799
Downstream Train Epoch: 25 [12800/50000 (26%)]	Loss: 11.467260
Downstream Train Epoch: 25 [25600/50000 (51%)]	Loss: 14.425015
Downstream Train Epoch: 25 [38400/50000 (77%)]	Loss: 10.945581

 Downstream Train loss: 14.163913031013644 Acc: 0.3951
Downstream Train Epoch: 26 [0/50000 (0%)]	Loss: 12.256426
Downstream Train Epoch: 26 [12800/50000 (26%)]	Loss: 15.505237
Downstream Train Epoch: 26 [25600/50000 (51%)]	Loss: 14.370452
Downstream Train Epoch: 26 [38400/50000 (77%)]	Loss: 9.892334

 Downstream Train loss: 14.201359060345863 Acc: 0.3951
Downstream Train Epoch: 27 [0/50000 (0%)]	Loss: 18.603477
Downstream Train Epoch: 27 [12800/50000 (26%)]	Loss: 11.096281
Downstream Train Epoch: 27 [25600/50000 (51%)]	Loss: 8.401527
Downstream Train Epoch: 27 [38400/50000 (77%)]	Loss: 13.974780

 Downstream Train loss: 13.881878906366776 Acc: 0.3951
Downstream Train Epoch: 28 [0/50000 (0%)]	Loss: 15.062370
Downstream Train Epoch: 28 [12800/50000 (26%)]	Loss: 18.882845
Downstream Train Epoch: 28 [25600/50000 (51%)]	Loss: 19.197956
Downstream Train Epoch: 28 [38400/50000 (77%)]	Loss: 10.755916

 Downstream Train loss: 13.515953903295555 Acc: 0.3951
Downstream Train Epoch: 29 [0/50000 (0%)]	Loss: 20.199110
Downstream Train Epoch: 29 [12800/50000 (26%)]	Loss: 10.924417
Downstream Train Epoch: 29 [25600/50000 (51%)]	Loss: 14.077274
Downstream Train Epoch: 29 [38400/50000 (77%)]	Loss: 16.591970

 Downstream Train loss: 14.760858209765686 Acc: 0.3951
Downstream Train Epoch: 30 [0/50000 (0%)]	Loss: 14.972791
Downstream Train Epoch: 30 [12800/50000 (26%)]	Loss: 15.252118
Downstream Train Epoch: 30 [25600/50000 (51%)]	Loss: 9.529633
Downstream Train Epoch: 30 [38400/50000 (77%)]	Loss: 9.126205

 Downstream Train loss: 13.883187050722084 Acc: 0.3951
Downstream Train Epoch: 31 [0/50000 (0%)]	Loss: 12.231198
Downstream Train Epoch: 31 [12800/50000 (26%)]	Loss: 12.374805
Downstream Train Epoch: 31 [25600/50000 (51%)]	Loss: 17.041498
Downstream Train Epoch: 31 [38400/50000 (77%)]	Loss: 11.851894

 Downstream Train loss: 13.441076989076576 Acc: 0.3951
Downstream Train Epoch: 32 [0/50000 (0%)]	Loss: 10.602420
Downstream Train Epoch: 32 [12800/50000 (26%)]	Loss: 12.158807
Downstream Train Epoch: 32 [25600/50000 (51%)]	Loss: 9.668923
Downstream Train Epoch: 32 [38400/50000 (77%)]	Loss: 6.990084

 Downstream Train loss: 14.5792316198349 Acc: 0.3951
Downstream Train Epoch: 33 [0/50000 (0%)]	Loss: 13.866881
Downstream Train Epoch: 33 [12800/50000 (26%)]	Loss: 14.966962
Downstream Train Epoch: 33 [25600/50000 (51%)]	Loss: 11.951178
Downstream Train Epoch: 33 [38400/50000 (77%)]	Loss: 8.469469

 Downstream Train loss: 14.342675121463074 Acc: 0.3951
Downstream Train Epoch: 34 [0/50000 (0%)]	Loss: 19.663000
Downstream Train Epoch: 34 [12800/50000 (26%)]	Loss: 11.694914
Downstream Train Epoch: 34 [25600/50000 (51%)]	Loss: 17.056082
Downstream Train Epoch: 34 [38400/50000 (77%)]	Loss: 15.204132

 Downstream Train loss: 13.912531641064858 Acc: 0.3951
Downstream Train Epoch: 35 [0/50000 (0%)]	Loss: 16.668589
Downstream Train Epoch: 35 [12800/50000 (26%)]	Loss: 8.386213
Downstream Train Epoch: 35 [25600/50000 (51%)]	Loss: 17.100147
Downstream Train Epoch: 35 [38400/50000 (77%)]	Loss: 12.376289

 Downstream Train loss: 14.229891438873446 Acc: 0.3951
Downstream Train Epoch: 36 [0/50000 (0%)]	Loss: 14.152715
Downstream Train Epoch: 36 [12800/50000 (26%)]	Loss: 13.393068
Downstream Train Epoch: 36 [25600/50000 (51%)]	Loss: 12.081068
Downstream Train Epoch: 36 [38400/50000 (77%)]	Loss: 10.601692

 Downstream Train loss: 13.073217598759399 Acc: 0.3951
Downstream Train Epoch: 37 [0/50000 (0%)]	Loss: 22.228201
Downstream Train Epoch: 37 [12800/50000 (26%)]	Loss: 11.172189
Downstream Train Epoch: 37 [25600/50000 (51%)]	Loss: 17.975861
Downstream Train Epoch: 37 [38400/50000 (77%)]	Loss: 20.341501

 Downstream Train loss: 14.615403301861821 Acc: 0.3951
Downstream Train Epoch: 38 [0/50000 (0%)]	Loss: 12.049255
Downstream Train Epoch: 38 [12800/50000 (26%)]	Loss: 9.670816
Downstream Train Epoch: 38 [25600/50000 (51%)]	Loss: 8.360989
Downstream Train Epoch: 38 [38400/50000 (77%)]	Loss: 21.655941

 Downstream Train loss: 14.24927806854248 Acc: 0.3951
Downstream Train Epoch: 39 [0/50000 (0%)]	Loss: 14.661316
Downstream Train Epoch: 39 [12800/50000 (26%)]	Loss: 17.264013
Downstream Train Epoch: 39 [25600/50000 (51%)]	Loss: 14.459265
Downstream Train Epoch: 39 [38400/50000 (77%)]	Loss: 17.559645

 Downstream Train loss: 15.638336524671438 Acc: 0.4242
Downstream Train Epoch: 40 [0/50000 (0%)]	Loss: 6.737427
Downstream Train Epoch: 40 [12800/50000 (26%)]	Loss: 11.383707
Downstream Train Epoch: 40 [25600/50000 (51%)]	Loss: 17.359562
Downstream Train Epoch: 40 [38400/50000 (77%)]	Loss: 11.977325

 Downstream Train loss: 14.440228812548579 Acc: 0.4242
Downstream Train Epoch: 41 [0/50000 (0%)]	Loss: 27.779766
Downstream Train Epoch: 41 [12800/50000 (26%)]	Loss: 21.970181
Downstream Train Epoch: 41 [25600/50000 (51%)]	Loss: 7.418753
Downstream Train Epoch: 41 [38400/50000 (77%)]	Loss: 14.002570

 Downstream Train loss: 14.844731756619044 Acc: 0.4242
Downstream Train Epoch: 42 [0/50000 (0%)]	Loss: 15.397552
Downstream Train Epoch: 42 [12800/50000 (26%)]	Loss: 8.331531
Downstream Train Epoch: 42 [25600/50000 (51%)]	Loss: 14.252121
Downstream Train Epoch: 42 [38400/50000 (77%)]	Loss: 16.944016

 Downstream Train loss: 13.076447253324547 Acc: 0.4242
Downstream Train Epoch: 43 [0/50000 (0%)]	Loss: 11.736244
Downstream Train Epoch: 43 [12800/50000 (26%)]	Loss: 8.825033
Downstream Train Epoch: 43 [25600/50000 (51%)]	Loss: 26.570297
Downstream Train Epoch: 43 [38400/50000 (77%)]	Loss: 10.601793

 Downstream Train loss: 13.192255489680232 Acc: 0.4242
Downstream Train Epoch: 44 [0/50000 (0%)]	Loss: 15.637414
Downstream Train Epoch: 44 [12800/50000 (26%)]	Loss: 20.124605
Downstream Train Epoch: 44 [25600/50000 (51%)]	Loss: 15.162351
Downstream Train Epoch: 44 [38400/50000 (77%)]	Loss: 8.156192

 Downstream Train loss: 14.198242681367057 Acc: 0.4242
Downstream Train Epoch: 45 [0/50000 (0%)]	Loss: 14.390321
Downstream Train Epoch: 45 [12800/50000 (26%)]	Loss: 6.585006
Downstream Train Epoch: 45 [25600/50000 (51%)]	Loss: 15.595972
Downstream Train Epoch: 45 [38400/50000 (77%)]	Loss: 17.475191

 Downstream Train loss: 12.69611439656238 Acc: 0.4242
Downstream Train Epoch: 46 [0/50000 (0%)]	Loss: 19.167942
Downstream Train Epoch: 46 [12800/50000 (26%)]	Loss: 10.832482
Downstream Train Epoch: 46 [25600/50000 (51%)]	Loss: 12.008842
Downstream Train Epoch: 46 [38400/50000 (77%)]	Loss: 16.909920

 Downstream Train loss: 13.39938957593879 Acc: 0.4242
Downstream Train Epoch: 47 [0/50000 (0%)]	Loss: 9.272821
Downstream Train Epoch: 47 [12800/50000 (26%)]	Loss: 10.710061
Downstream Train Epoch: 47 [25600/50000 (51%)]	Loss: 16.378944
Downstream Train Epoch: 47 [38400/50000 (77%)]	Loss: 16.016893

 Downstream Train loss: 13.197689126948921 Acc: 0.4242
Downstream Train Epoch: 48 [0/50000 (0%)]	Loss: 12.538489
Downstream Train Epoch: 48 [12800/50000 (26%)]	Loss: 12.007236
Downstream Train Epoch: 48 [25600/50000 (51%)]	Loss: 18.672279
Downstream Train Epoch: 48 [38400/50000 (77%)]	Loss: 12.979443

 Downstream Train loss: 12.959024001140984 Acc: 0.4242
Downstream Train Epoch: 49 [0/50000 (0%)]	Loss: 16.038960
Downstream Train Epoch: 49 [12800/50000 (26%)]	Loss: 10.526101
Downstream Train Epoch: 49 [25600/50000 (51%)]	Loss: 18.662231
Downstream Train Epoch: 49 [38400/50000 (77%)]	Loss: 16.944029

 Downstream Train loss: 13.93985559015858 Acc: 0.4242
Downstream Train Epoch: 50 [0/50000 (0%)]	Loss: 19.557692
Downstream Train Epoch: 50 [12800/50000 (26%)]	Loss: 11.722864
Downstream Train Epoch: 50 [25600/50000 (51%)]	Loss: 12.905520
Downstream Train Epoch: 50 [38400/50000 (77%)]	Loss: 7.324543

 Downstream Train loss: 12.60182591847011 Acc: 0.4242
Downstream Train Epoch: 51 [0/50000 (0%)]	Loss: 11.604558
Downstream Train Epoch: 51 [12800/50000 (26%)]	Loss: 11.338369
Downstream Train Epoch: 51 [25600/50000 (51%)]	Loss: 17.405628
Downstream Train Epoch: 51 [38400/50000 (77%)]	Loss: 28.711454

 Downstream Train loss: 14.708380468037664 Acc: 0.4242
Downstream Train Epoch: 52 [0/50000 (0%)]	Loss: 19.133766
Downstream Train Epoch: 52 [12800/50000 (26%)]	Loss: 16.634199
Downstream Train Epoch: 52 [25600/50000 (51%)]	Loss: 10.632192
Downstream Train Epoch: 52 [38400/50000 (77%)]	Loss: 17.501202

 Downstream Train loss: 13.47577183100642 Acc: 0.4242
Downstream Train Epoch: 53 [0/50000 (0%)]	Loss: 14.787077
Downstream Train Epoch: 53 [12800/50000 (26%)]	Loss: 14.190227
Downstream Train Epoch: 53 [25600/50000 (51%)]	Loss: 14.956464
Downstream Train Epoch: 53 [38400/50000 (77%)]	Loss: 10.483126

 Downstream Train loss: 13.111247631968284 Acc: 0.4242
Downstream Train Epoch: 54 [0/50000 (0%)]	Loss: 9.860762
Downstream Train Epoch: 54 [12800/50000 (26%)]	Loss: 12.338593
Downstream Train Epoch: 54 [25600/50000 (51%)]	Loss: 15.861083
Downstream Train Epoch: 54 [38400/50000 (77%)]	Loss: 19.603193

 Downstream Train loss: 14.403852251111244 Acc: 0.4242
Downstream Train Epoch: 55 [0/50000 (0%)]	Loss: 8.706952
Downstream Train Epoch: 55 [12800/50000 (26%)]	Loss: 9.308538
Downstream Train Epoch: 55 [25600/50000 (51%)]	Loss: 12.641100
Downstream Train Epoch: 55 [38400/50000 (77%)]	Loss: 11.676712

 Downstream Train loss: 12.856481994901385 Acc: 0.4242
Downstream Train Epoch: 56 [0/50000 (0%)]	Loss: 11.880321
Downstream Train Epoch: 56 [12800/50000 (26%)]	Loss: 11.748099
Downstream Train Epoch: 56 [25600/50000 (51%)]	Loss: 13.710422
Downstream Train Epoch: 56 [38400/50000 (77%)]	Loss: 13.404740

 Downstream Train loss: 14.200287152309807 Acc: 0.4242
Downstream Train Epoch: 57 [0/50000 (0%)]	Loss: 12.977032
Downstream Train Epoch: 57 [12800/50000 (26%)]	Loss: 21.286116
Downstream Train Epoch: 57 [25600/50000 (51%)]	Loss: 14.307076
Downstream Train Epoch: 57 [38400/50000 (77%)]	Loss: 10.259959

 Downstream Train loss: 13.71461822548691 Acc: 0.4242
Downstream Train Epoch: 58 [0/50000 (0%)]	Loss: 11.785569
Downstream Train Epoch: 58 [12800/50000 (26%)]	Loss: 10.398495
Downstream Train Epoch: 58 [25600/50000 (51%)]	Loss: 12.134119
Downstream Train Epoch: 58 [38400/50000 (77%)]	Loss: 8.025499

 Downstream Train loss: 13.422649018618525 Acc: 0.4242
Downstream Train Epoch: 59 [0/50000 (0%)]	Loss: 19.620733
Downstream Train Epoch: 59 [12800/50000 (26%)]	Loss: 10.690585
Downstream Train Epoch: 59 [25600/50000 (51%)]	Loss: 16.476421
Downstream Train Epoch: 59 [38400/50000 (77%)]	Loss: 9.910769

 Downstream Train loss: 13.23514400696268 Acc: 0.4242
Downstream Train Epoch: 60 [0/50000 (0%)]	Loss: 10.115191
Downstream Train Epoch: 60 [12800/50000 (26%)]	Loss: 15.648840
Downstream Train Epoch: 60 [25600/50000 (51%)]	Loss: 8.337442
Downstream Train Epoch: 60 [38400/50000 (77%)]	Loss: 16.710785

 Downstream Train loss: 12.750343558739642 Acc: 0.4242
Classifier Accuracy for user 2 is 0.4242
Start tarining Classifier for user 3
Training classifier
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 3.430
Y partition skewness sampling
partition skew: 5 1.0 
10000 10000 0
len of skewed: 50000 len of unskewed: 0 data_num_per_user_skew: 10000
10000 5000 10000
partition skew: 5 1.0 
2000 2000 0
len of skewed: 10000 len of unskewed: 0 data_num_per_user_skew: 2000
2000 1000 2000
sample dataset time: 0.007
user data samples: [10000, 10000, 10000, 10000, 10000]
begin training classifier...
Downstream Train Epoch: 1 [0/50000 (0%)]	Loss: 245.515778
Downstream Train Epoch: 1 [12800/50000 (26%)]	Loss: 48.131496
Downstream Train Epoch: 1 [25600/50000 (51%)]	Loss: 35.196373
Downstream Train Epoch: 1 [38400/50000 (77%)]	Loss: 29.021097

 Downstream Train loss: 44.198209626334055 Acc: 0.2731
Downstream Train Epoch: 2 [0/50000 (0%)]	Loss: 35.276237
Downstream Train Epoch: 2 [12800/50000 (26%)]	Loss: 27.497532
Downstream Train Epoch: 2 [25600/50000 (51%)]	Loss: 25.522989
Downstream Train Epoch: 2 [38400/50000 (77%)]	Loss: 23.549738

 Downstream Train loss: 26.71634022070437 Acc: 0.3258
Downstream Train Epoch: 3 [0/50000 (0%)]	Loss: 30.992146
Downstream Train Epoch: 3 [12800/50000 (26%)]	Loss: 22.298388
Downstream Train Epoch: 3 [25600/50000 (51%)]	Loss: 21.658220
Downstream Train Epoch: 3 [38400/50000 (77%)]	Loss: 23.502201

 Downstream Train loss: 23.559162256669026 Acc: 0.3258
Downstream Train Epoch: 4 [0/50000 (0%)]	Loss: 20.999657
Downstream Train Epoch: 4 [12800/50000 (26%)]	Loss: 22.813948
Downstream Train Epoch: 4 [25600/50000 (51%)]	Loss: 24.490246
Downstream Train Epoch: 4 [38400/50000 (77%)]	Loss: 19.404310

 Downstream Train loss: 22.44859799073667 Acc: 0.3258
Downstream Train Epoch: 5 [0/50000 (0%)]	Loss: 16.424089
Downstream Train Epoch: 5 [12800/50000 (26%)]	Loss: 21.995266
Downstream Train Epoch: 5 [25600/50000 (51%)]	Loss: 21.738735
Downstream Train Epoch: 5 [38400/50000 (77%)]	Loss: 19.809628

 Downstream Train loss: 20.451838235465846 Acc: 0.3258
Downstream Train Epoch: 6 [0/50000 (0%)]	Loss: 21.005642
Downstream Train Epoch: 6 [12800/50000 (26%)]	Loss: 22.188850
Downstream Train Epoch: 6 [25600/50000 (51%)]	Loss: 18.181273
Downstream Train Epoch: 6 [38400/50000 (77%)]	Loss: 17.716806

 Downstream Train loss: 20.02733298223846 Acc: 0.3578
Downstream Train Epoch: 7 [0/50000 (0%)]	Loss: 16.317173
Downstream Train Epoch: 7 [12800/50000 (26%)]	Loss: 15.884455
Downstream Train Epoch: 7 [25600/50000 (51%)]	Loss: 18.970020
Downstream Train Epoch: 7 [38400/50000 (77%)]	Loss: 15.538224

 Downstream Train loss: 18.606132215383102 Acc: 0.3578
Downstream Train Epoch: 8 [0/50000 (0%)]	Loss: 15.314068
Downstream Train Epoch: 8 [12800/50000 (26%)]	Loss: 16.251863
Downstream Train Epoch: 8 [25600/50000 (51%)]	Loss: 27.947456
Downstream Train Epoch: 8 [38400/50000 (77%)]	Loss: 20.451210

 Downstream Train loss: 20.2131282504724 Acc: 0.3578
Downstream Train Epoch: 9 [0/50000 (0%)]	Loss: 22.977808
Downstream Train Epoch: 9 [12800/50000 (26%)]	Loss: 14.095796
Downstream Train Epoch: 9 [25600/50000 (51%)]	Loss: 16.752626
Downstream Train Epoch: 9 [38400/50000 (77%)]	Loss: 17.757072

 Downstream Train loss: 18.084796063754023 Acc: 0.3578
Downstream Train Epoch: 10 [0/50000 (0%)]	Loss: 22.789413
Downstream Train Epoch: 10 [12800/50000 (26%)]	Loss: 13.896857
Downstream Train Epoch: 10 [25600/50000 (51%)]	Loss: 18.967932
Downstream Train Epoch: 10 [38400/50000 (77%)]	Loss: 13.302803

 Downstream Train loss: 17.71298434296433 Acc: 0.3584
Downstream Train Epoch: 11 [0/50000 (0%)]	Loss: 12.188263
Downstream Train Epoch: 11 [12800/50000 (26%)]	Loss: 16.577572
Downstream Train Epoch: 11 [25600/50000 (51%)]	Loss: 14.466580
Downstream Train Epoch: 11 [38400/50000 (77%)]	Loss: 20.967279

 Downstream Train loss: 16.741203089149632 Acc: 0.3584
Downstream Train Epoch: 12 [0/50000 (0%)]	Loss: 18.478788
Downstream Train Epoch: 12 [12800/50000 (26%)]	Loss: 21.301592
Downstream Train Epoch: 12 [25600/50000 (51%)]	Loss: 21.673178
Downstream Train Epoch: 12 [38400/50000 (77%)]	Loss: 18.405138

 Downstream Train loss: 18.989143157491878 Acc: 0.3584
Downstream Train Epoch: 13 [0/50000 (0%)]	Loss: 21.200727
Downstream Train Epoch: 13 [12800/50000 (26%)]	Loss: 19.446360
Downstream Train Epoch: 13 [25600/50000 (51%)]	Loss: 11.431751
Downstream Train Epoch: 13 [38400/50000 (77%)]	Loss: 14.809919

 Downstream Train loss: 17.16681897396944 Acc: 0.3838
Downstream Train Epoch: 14 [0/50000 (0%)]	Loss: 11.458495
Downstream Train Epoch: 14 [12800/50000 (26%)]	Loss: 12.338458
Downstream Train Epoch: 14 [25600/50000 (51%)]	Loss: 16.607475
Downstream Train Epoch: 14 [38400/50000 (77%)]	Loss: 20.528355

 Downstream Train loss: 16.89976974896022 Acc: 0.3838
Downstream Train Epoch: 15 [0/50000 (0%)]	Loss: 19.954769
Downstream Train Epoch: 15 [12800/50000 (26%)]	Loss: 16.686897
Downstream Train Epoch: 15 [25600/50000 (51%)]	Loss: 21.825756
Downstream Train Epoch: 15 [38400/50000 (77%)]	Loss: 17.140440

 Downstream Train loss: 18.152420199647242 Acc: 0.3838
Downstream Train Epoch: 16 [0/50000 (0%)]	Loss: 15.106451
Downstream Train Epoch: 16 [12800/50000 (26%)]	Loss: 14.758489
Downstream Train Epoch: 16 [25600/50000 (51%)]	Loss: 26.102919
Downstream Train Epoch: 16 [38400/50000 (77%)]	Loss: 10.364754

 Downstream Train loss: 17.768045493534633 Acc: 0.3838
Downstream Train Epoch: 17 [0/50000 (0%)]	Loss: 27.318588
Downstream Train Epoch: 17 [12800/50000 (26%)]	Loss: 14.326428
Downstream Train Epoch: 17 [25600/50000 (51%)]	Loss: 28.983175
Downstream Train Epoch: 17 [38400/50000 (77%)]	Loss: 17.896332

 Downstream Train loss: 17.257368209410686 Acc: 0.3838
Downstream Train Epoch: 18 [0/50000 (0%)]	Loss: 17.536766
Downstream Train Epoch: 18 [12800/50000 (26%)]	Loss: 19.284225
Downstream Train Epoch: 18 [25600/50000 (51%)]	Loss: 16.739388
Downstream Train Epoch: 18 [38400/50000 (77%)]	Loss: 19.504177

 Downstream Train loss: 18.438704587975327 Acc: 0.3924
Downstream Train Epoch: 19 [0/50000 (0%)]	Loss: 13.900031
Downstream Train Epoch: 19 [12800/50000 (26%)]	Loss: 21.651682
Downstream Train Epoch: 19 [25600/50000 (51%)]	Loss: 15.500793
Downstream Train Epoch: 19 [38400/50000 (77%)]	Loss: 13.486777

 Downstream Train loss: 16.618347192297175 Acc: 0.3924
Downstream Train Epoch: 20 [0/50000 (0%)]	Loss: 20.563005
Downstream Train Epoch: 20 [12800/50000 (26%)]	Loss: 12.102604
Downstream Train Epoch: 20 [25600/50000 (51%)]	Loss: 21.901739
Downstream Train Epoch: 20 [38400/50000 (77%)]	Loss: 17.176842

 Downstream Train loss: 18.382312327015157 Acc: 0.3924
Downstream Train Epoch: 21 [0/50000 (0%)]	Loss: 11.251766
Downstream Train Epoch: 21 [12800/50000 (26%)]	Loss: 10.118935
Downstream Train Epoch: 21 [25600/50000 (51%)]	Loss: 13.746334
Downstream Train Epoch: 21 [38400/50000 (77%)]	Loss: 11.970736

 Downstream Train loss: 15.462794196848966 Acc: 0.3924
Downstream Train Epoch: 22 [0/50000 (0%)]	Loss: 17.780401
Downstream Train Epoch: 22 [12800/50000 (26%)]	Loss: 15.653478
Downstream Train Epoch: 22 [25600/50000 (51%)]	Loss: 24.813486
Downstream Train Epoch: 22 [38400/50000 (77%)]	Loss: 13.484661

 Downstream Train loss: 16.18658311026437 Acc: 0.3924
Downstream Train Epoch: 23 [0/50000 (0%)]	Loss: 12.022207
Downstream Train Epoch: 23 [12800/50000 (26%)]	Loss: 16.495665
Downstream Train Epoch: 23 [25600/50000 (51%)]	Loss: 15.561507
Downstream Train Epoch: 23 [38400/50000 (77%)]	Loss: 13.171850

 Downstream Train loss: 17.26761998449053 Acc: 0.3924
Downstream Train Epoch: 24 [0/50000 (0%)]	Loss: 33.788181
Downstream Train Epoch: 24 [12800/50000 (26%)]	Loss: 17.286058
Downstream Train Epoch: 24 [25600/50000 (51%)]	Loss: 12.912426
Downstream Train Epoch: 24 [38400/50000 (77%)]	Loss: 14.734243

 Downstream Train loss: 15.464962667348434 Acc: 0.3924
Downstream Train Epoch: 25 [0/50000 (0%)]	Loss: 34.796791
Downstream Train Epoch: 25 [12800/50000 (26%)]	Loss: 18.865381
Downstream Train Epoch: 25 [25600/50000 (51%)]	Loss: 10.938393
Downstream Train Epoch: 25 [38400/50000 (77%)]	Loss: 15.761363

 Downstream Train loss: 16.23187671875467 Acc: 0.3924
Downstream Train Epoch: 26 [0/50000 (0%)]	Loss: 26.119806
Downstream Train Epoch: 26 [12800/50000 (26%)]	Loss: 14.866537
Downstream Train Epoch: 26 [25600/50000 (51%)]	Loss: 17.516644
Downstream Train Epoch: 26 [38400/50000 (77%)]	Loss: 18.137119

 Downstream Train loss: 15.773014856844533 Acc: 0.3924
Downstream Train Epoch: 27 [0/50000 (0%)]	Loss: 14.842235
Downstream Train Epoch: 27 [12800/50000 (26%)]	Loss: 21.929445
Downstream Train Epoch: 27 [25600/50000 (51%)]	Loss: 35.339905
Downstream Train Epoch: 27 [38400/50000 (77%)]	Loss: 12.318127

 Downstream Train loss: 17.24450200431201 Acc: 0.3924
Downstream Train Epoch: 28 [0/50000 (0%)]	Loss: 20.252882
Downstream Train Epoch: 28 [12800/50000 (26%)]	Loss: 12.479436
Downstream Train Epoch: 28 [25600/50000 (51%)]	Loss: 23.473797
Downstream Train Epoch: 28 [38400/50000 (77%)]	Loss: 12.356114

 Downstream Train loss: 18.239480763065572 Acc: 0.3924
Downstream Train Epoch: 29 [0/50000 (0%)]	Loss: 12.210369
Downstream Train Epoch: 29 [12800/50000 (26%)]	Loss: 12.714006
Downstream Train Epoch: 29 [25600/50000 (51%)]	Loss: 17.633041
Downstream Train Epoch: 29 [38400/50000 (77%)]	Loss: 16.484045

 Downstream Train loss: 15.302687109733114 Acc: 0.3924
Downstream Train Epoch: 30 [0/50000 (0%)]	Loss: 26.306976
Downstream Train Epoch: 30 [12800/50000 (26%)]	Loss: 29.977140
Downstream Train Epoch: 30 [25600/50000 (51%)]	Loss: 11.510703
Downstream Train Epoch: 30 [38400/50000 (77%)]	Loss: 11.535563

 Downstream Train loss: 17.02294037779983 Acc: 0.3924
Downstream Train Epoch: 31 [0/50000 (0%)]	Loss: 31.682808
Downstream Train Epoch: 31 [12800/50000 (26%)]	Loss: 12.808289
Downstream Train Epoch: 31 [25600/50000 (51%)]	Loss: 12.641839
Downstream Train Epoch: 31 [38400/50000 (77%)]	Loss: 14.849899

 Downstream Train loss: 18.58446959086827 Acc: 0.3924
Downstream Train Epoch: 32 [0/50000 (0%)]	Loss: 20.380894
Downstream Train Epoch: 32 [12800/50000 (26%)]	Loss: 15.171419
Downstream Train Epoch: 32 [25600/50000 (51%)]	Loss: 19.445896
Downstream Train Epoch: 32 [38400/50000 (77%)]	Loss: 12.597264

 Downstream Train loss: 17.29110324626066 Acc: 0.3924
Downstream Train Epoch: 33 [0/50000 (0%)]	Loss: 16.515512
Downstream Train Epoch: 33 [12800/50000 (26%)]	Loss: 14.379436
Downstream Train Epoch: 33 [25600/50000 (51%)]	Loss: 11.341679
Downstream Train Epoch: 33 [38400/50000 (77%)]	Loss: 13.618490

 Downstream Train loss: 16.414012879741435 Acc: 0.3924
Downstream Train Epoch: 34 [0/50000 (0%)]	Loss: 19.315973
Downstream Train Epoch: 34 [12800/50000 (26%)]	Loss: 20.909496
Downstream Train Epoch: 34 [25600/50000 (51%)]	Loss: 22.388111
Downstream Train Epoch: 34 [38400/50000 (77%)]	Loss: 10.558038

 Downstream Train loss: 16.55953901641223 Acc: 0.3924
Downstream Train Epoch: 35 [0/50000 (0%)]	Loss: 17.246916
Downstream Train Epoch: 35 [12800/50000 (26%)]	Loss: 19.119095
Downstream Train Epoch: 35 [25600/50000 (51%)]	Loss: 12.493473
Downstream Train Epoch: 35 [38400/50000 (77%)]	Loss: 17.409487

 Downstream Train loss: 15.232396850780566 Acc: 0.3924
Downstream Train Epoch: 36 [0/50000 (0%)]	Loss: 14.736314
Downstream Train Epoch: 36 [12800/50000 (26%)]	Loss: 18.222607
Downstream Train Epoch: 36 [25600/50000 (51%)]	Loss: 11.557918
Downstream Train Epoch: 36 [38400/50000 (77%)]	Loss: 10.195985

 Downstream Train loss: 15.846312026588285 Acc: 0.3924
Downstream Train Epoch: 37 [0/50000 (0%)]	Loss: 13.860491
Downstream Train Epoch: 37 [12800/50000 (26%)]	Loss: 15.083082
Downstream Train Epoch: 37 [25600/50000 (51%)]	Loss: 25.365738
Downstream Train Epoch: 37 [38400/50000 (77%)]	Loss: 13.210161

 Downstream Train loss: 17.0194029954015 Acc: 0.3924
Downstream Train Epoch: 38 [0/50000 (0%)]	Loss: 24.028257
Downstream Train Epoch: 38 [12800/50000 (26%)]	Loss: 22.276096
Downstream Train Epoch: 38 [25600/50000 (51%)]	Loss: 26.632681
Downstream Train Epoch: 38 [38400/50000 (77%)]	Loss: 16.281775

 Downstream Train loss: 17.88890729145128 Acc: 0.3924
Downstream Train Epoch: 39 [0/50000 (0%)]	Loss: 11.334407
Downstream Train Epoch: 39 [12800/50000 (26%)]	Loss: 11.151081
Downstream Train Epoch: 39 [25600/50000 (51%)]	Loss: 12.045627
Downstream Train Epoch: 39 [38400/50000 (77%)]	Loss: 33.215019

 Downstream Train loss: 18.156661009301946 Acc: 0.3924
Downstream Train Epoch: 40 [0/50000 (0%)]	Loss: 12.731277
Downstream Train Epoch: 40 [12800/50000 (26%)]	Loss: 21.334263
Downstream Train Epoch: 40 [25600/50000 (51%)]	Loss: 21.610094
Downstream Train Epoch: 40 [38400/50000 (77%)]	Loss: 21.020094

 Downstream Train loss: 16.942312157883936 Acc: 0.3924
Downstream Train Epoch: 41 [0/50000 (0%)]	Loss: 16.515635
Downstream Train Epoch: 41 [12800/50000 (26%)]	Loss: 13.305837
Downstream Train Epoch: 41 [25600/50000 (51%)]	Loss: 14.849184
Downstream Train Epoch: 41 [38400/50000 (77%)]	Loss: 13.601442

 Downstream Train loss: 16.476974034795955 Acc: 0.3924
Downstream Train Epoch: 42 [0/50000 (0%)]	Loss: 20.664169
Downstream Train Epoch: 42 [12800/50000 (26%)]	Loss: 11.479045
Downstream Train Epoch: 42 [25600/50000 (51%)]	Loss: 17.691301
Downstream Train Epoch: 42 [38400/50000 (77%)]	Loss: 9.609011

 Downstream Train loss: 14.968686332508009 Acc: 0.3924
Downstream Train Epoch: 43 [0/50000 (0%)]	Loss: 13.792130
Downstream Train Epoch: 43 [12800/50000 (26%)]	Loss: 17.070135
Downstream Train Epoch: 43 [25600/50000 (51%)]	Loss: 27.512024
Downstream Train Epoch: 43 [38400/50000 (77%)]	Loss: 12.120970

 Downstream Train loss: 17.268432485813996 Acc: 0.3924
Downstream Train Epoch: 44 [0/50000 (0%)]	Loss: 24.801273
Downstream Train Epoch: 44 [12800/50000 (26%)]	Loss: 12.514001
Downstream Train Epoch: 44 [25600/50000 (51%)]	Loss: 15.974983
Downstream Train Epoch: 44 [38400/50000 (77%)]	Loss: 12.123986

 Downstream Train loss: 17.236027381858047 Acc: 0.3924
Downstream Train Epoch: 45 [0/50000 (0%)]	Loss: 17.187937
Downstream Train Epoch: 45 [12800/50000 (26%)]	Loss: 18.816025
Downstream Train Epoch: 45 [25600/50000 (51%)]	Loss: 8.443455
Downstream Train Epoch: 45 [38400/50000 (77%)]	Loss: 18.801073

 Downstream Train loss: 15.456038981067891 Acc: 0.3924
Downstream Train Epoch: 46 [0/50000 (0%)]	Loss: 24.726748
Downstream Train Epoch: 46 [12800/50000 (26%)]	Loss: 17.547314
Downstream Train Epoch: 46 [25600/50000 (51%)]	Loss: 19.870493
Downstream Train Epoch: 46 [38400/50000 (77%)]	Loss: 11.455335

 Downstream Train loss: 18.13203639886817 Acc: 0.3924
Downstream Train Epoch: 47 [0/50000 (0%)]	Loss: 15.939259
Downstream Train Epoch: 47 [12800/50000 (26%)]	Loss: 15.414700
Downstream Train Epoch: 47 [25600/50000 (51%)]	Loss: 13.518114
Downstream Train Epoch: 47 [38400/50000 (77%)]	Loss: 27.927231

 Downstream Train loss: 17.73472348038031 Acc: 0.3924
Downstream Train Epoch: 48 [0/50000 (0%)]	Loss: 18.653429
Downstream Train Epoch: 48 [12800/50000 (26%)]	Loss: 19.279491
Downstream Train Epoch: 48 [25600/50000 (51%)]	Loss: 14.495537
Downstream Train Epoch: 48 [38400/50000 (77%)]	Loss: 11.689047

 Downstream Train loss: 16.369605589886103 Acc: 0.3924
Downstream Train Epoch: 49 [0/50000 (0%)]	Loss: 15.604428
Downstream Train Epoch: 49 [12800/50000 (26%)]	Loss: 22.014412
Downstream Train Epoch: 49 [25600/50000 (51%)]	Loss: 16.780664
Downstream Train Epoch: 49 [38400/50000 (77%)]	Loss: 22.807508

 Downstream Train loss: 17.819944065444325 Acc: 0.3924
Downstream Train Epoch: 50 [0/50000 (0%)]	Loss: 16.575113
Downstream Train Epoch: 50 [12800/50000 (26%)]	Loss: 16.894115
Downstream Train Epoch: 50 [25600/50000 (51%)]	Loss: 17.668446
Downstream Train Epoch: 50 [38400/50000 (77%)]	Loss: 9.773443

 Downstream Train loss: 18.174297240315653 Acc: 0.3924
Downstream Train Epoch: 51 [0/50000 (0%)]	Loss: 13.764219
Downstream Train Epoch: 51 [12800/50000 (26%)]	Loss: 14.437654
Downstream Train Epoch: 51 [25600/50000 (51%)]	Loss: 25.368553
Downstream Train Epoch: 51 [38400/50000 (77%)]	Loss: 23.377741

 Downstream Train loss: 15.40147338594709 Acc: 0.3924
Downstream Train Epoch: 52 [0/50000 (0%)]	Loss: 13.206665
Downstream Train Epoch: 52 [12800/50000 (26%)]	Loss: 13.947926
Downstream Train Epoch: 52 [25600/50000 (51%)]	Loss: 12.740979
Downstream Train Epoch: 52 [38400/50000 (77%)]	Loss: 12.297117

 Downstream Train loss: 17.185147514148635 Acc: 0.3924
Downstream Train Epoch: 53 [0/50000 (0%)]	Loss: 13.213974
Downstream Train Epoch: 53 [12800/50000 (26%)]	Loss: 18.770796
Downstream Train Epoch: 53 [25600/50000 (51%)]	Loss: 14.965359
Downstream Train Epoch: 53 [38400/50000 (77%)]	Loss: 25.796707

 Downstream Train loss: 15.241466960128474 Acc: 0.3924
Downstream Train Epoch: 54 [0/50000 (0%)]	Loss: 15.873137
Downstream Train Epoch: 54 [12800/50000 (26%)]	Loss: 19.302368
Downstream Train Epoch: 54 [25600/50000 (51%)]	Loss: 16.200083
Downstream Train Epoch: 54 [38400/50000 (77%)]	Loss: 19.240385

 Downstream Train loss: 15.128320450685463 Acc: 0.3924
Downstream Train Epoch: 55 [0/50000 (0%)]	Loss: 13.795354
Downstream Train Epoch: 55 [12800/50000 (26%)]	Loss: 23.822685
Downstream Train Epoch: 55 [25600/50000 (51%)]	Loss: 15.698336
Downstream Train Epoch: 55 [38400/50000 (77%)]	Loss: 18.454391

 Downstream Train loss: 18.05671673404927 Acc: 0.3924
Downstream Train Epoch: 56 [0/50000 (0%)]	Loss: 13.547626
Downstream Train Epoch: 56 [12800/50000 (26%)]	Loss: 15.398753
Downstream Train Epoch: 56 [25600/50000 (51%)]	Loss: 11.329478
Downstream Train Epoch: 56 [38400/50000 (77%)]	Loss: 11.224632

 Downstream Train loss: 16.735058730962326 Acc: 0.4126
Downstream Train Epoch: 57 [0/50000 (0%)]	Loss: 11.538507
Downstream Train Epoch: 57 [12800/50000 (26%)]	Loss: 13.079960
Downstream Train Epoch: 57 [25600/50000 (51%)]	Loss: 9.414831
Downstream Train Epoch: 57 [38400/50000 (77%)]	Loss: 15.065424

 Downstream Train loss: 15.474770351332062 Acc: 0.4126
Downstream Train Epoch: 58 [0/50000 (0%)]	Loss: 9.410709
Downstream Train Epoch: 58 [12800/50000 (26%)]	Loss: 12.843361
Downstream Train Epoch: 58 [25600/50000 (51%)]	Loss: 17.901787
Downstream Train Epoch: 58 [38400/50000 (77%)]	Loss: 20.786558

 Downstream Train loss: 16.81860370052104 Acc: 0.4126
Downstream Train Epoch: 59 [0/50000 (0%)]	Loss: 8.738666
Downstream Train Epoch: 59 [12800/50000 (26%)]	Loss: 13.219138
Downstream Train Epoch: 59 [25600/50000 (51%)]	Loss: 14.572247
Downstream Train Epoch: 59 [38400/50000 (77%)]	Loss: 11.836150

 Downstream Train loss: 15.035429295228452 Acc: 0.4126
Downstream Train Epoch: 60 [0/50000 (0%)]	Loss: 12.992065
Downstream Train Epoch: 60 [12800/50000 (26%)]	Loss: 15.358736
Downstream Train Epoch: 60 [25600/50000 (51%)]	Loss: 11.614381
Downstream Train Epoch: 60 [38400/50000 (77%)]	Loss: 21.603292

 Downstream Train loss: 15.994541625587308 Acc: 0.4126
Classifier Accuracy for user 3 is 0.4126
Start tarining Classifier for user 4
Training classifier
sampling for dataset: mnist
Files already downloaded and verified
dataset sample num: (50000, 32, 32, 3)
Files already downloaded and verified
Files already downloaded and verified
get dataset time: 8.417
Y partition skewness sampling
partition skew: 5 1.0 
10000 10000 0
len of skewed: 50000 len of unskewed: 0 data_num_per_user_skew: 10000
10000 5000 10000
partition skew: 5 1.0 
2000 2000 0
len of skewed: 10000 len of unskewed: 0 data_num_per_user_skew: 2000
2000 1000 2000
sample dataset time: 0.007
user data samples: [10000, 10000, 10000, 10000, 10000]
begin training classifier...
Downstream Train Epoch: 1 [0/50000 (0%)]	Loss: 310.096283
Downstream Train Epoch: 1 [12800/50000 (26%)]	Loss: 49.407326
Downstream Train Epoch: 1 [25600/50000 (51%)]	Loss: 43.310024
Downstream Train Epoch: 1 [38400/50000 (77%)]	Loss: 36.857121

 Downstream Train loss: 54.58607830320086 Acc: 0.2555
Downstream Train Epoch: 2 [0/50000 (0%)]	Loss: 40.233509
Downstream Train Epoch: 2 [12800/50000 (26%)]	Loss: 36.061951
Downstream Train Epoch: 2 [25600/50000 (51%)]	Loss: 35.076077
Downstream Train Epoch: 2 [38400/50000 (77%)]	Loss: 37.158958

 Downstream Train loss: 33.16932616915022 Acc: 0.2694
Downstream Train Epoch: 3 [0/50000 (0%)]	Loss: 34.671867
Downstream Train Epoch: 3 [12800/50000 (26%)]	Loss: 27.144957
Downstream Train Epoch: 3 [25600/50000 (51%)]	Loss: 30.059258
Downstream Train Epoch: 3 [38400/50000 (77%)]	Loss: 27.637489

 Downstream Train loss: 28.24705900464739 Acc: 0.2961
Downstream Train Epoch: 4 [0/50000 (0%)]	Loss: 32.867981
Downstream Train Epoch: 4 [12800/50000 (26%)]	Loss: 28.267658
Downstream Train Epoch: 4 [25600/50000 (51%)]	Loss: 28.292925
Downstream Train Epoch: 4 [38400/50000 (77%)]	Loss: 28.494446

 Downstream Train loss: 27.452197026233282 Acc: 0.2961
Downstream Train Epoch: 5 [0/50000 (0%)]	Loss: 27.286957
Downstream Train Epoch: 5 [12800/50000 (26%)]	Loss: 23.171185
Downstream Train Epoch: 5 [25600/50000 (51%)]	Loss: 33.312279
Downstream Train Epoch: 5 [38400/50000 (77%)]	Loss: 20.870453

 Downstream Train loss: 24.846151731452164 Acc: 0.3085
Downstream Train Epoch: 6 [0/50000 (0%)]	Loss: 24.774096
Downstream Train Epoch: 6 [12800/50000 (26%)]	Loss: 24.676758
Downstream Train Epoch: 6 [25600/50000 (51%)]	Loss: 26.576782
Downstream Train Epoch: 6 [38400/50000 (77%)]	Loss: 42.220245

 Downstream Train loss: 25.97928543480075 Acc: 0.3085
Downstream Train Epoch: 7 [0/50000 (0%)]	Loss: 34.399448
Downstream Train Epoch: 7 [12800/50000 (26%)]	Loss: 24.680202
Downstream Train Epoch: 7 [25600/50000 (51%)]	Loss: 22.127050
Downstream Train Epoch: 7 [38400/50000 (77%)]	Loss: 22.646643

 Downstream Train loss: 22.998642245117498 Acc: 0.3085
Downstream Train Epoch: 8 [0/50000 (0%)]	Loss: 28.474724
Downstream Train Epoch: 8 [12800/50000 (26%)]	Loss: 19.345667
Downstream Train Epoch: 8 [25600/50000 (51%)]	Loss: 27.809412
Downstream Train Epoch: 8 [38400/50000 (77%)]	Loss: 21.139425

 Downstream Train loss: 23.299274259684037 Acc: 0.3093
Downstream Train Epoch: 9 [0/50000 (0%)]	Loss: 24.180044
Downstream Train Epoch: 9 [12800/50000 (26%)]	Loss: 23.260391
Downstream Train Epoch: 9 [25600/50000 (51%)]	Loss: 27.141813
Downstream Train Epoch: 9 [38400/50000 (77%)]	Loss: 17.751085

 Downstream Train loss: 21.428254526488637 Acc: 0.3399
Downstream Train Epoch: 10 [0/50000 (0%)]	Loss: 19.122307
Downstream Train Epoch: 10 [12800/50000 (26%)]	Loss: 23.213724
Downstream Train Epoch: 10 [25600/50000 (51%)]	Loss: 26.004444
Downstream Train Epoch: 10 [38400/50000 (77%)]	Loss: 17.987059

 Downstream Train loss: 21.352560067663386 Acc: 0.3399
Downstream Train Epoch: 11 [0/50000 (0%)]	Loss: 17.866919
Downstream Train Epoch: 11 [12800/50000 (26%)]	Loss: 24.946320
Downstream Train Epoch: 11 [25600/50000 (51%)]	Loss: 26.142059
Downstream Train Epoch: 11 [38400/50000 (77%)]	Loss: 21.194908

 Downstream Train loss: 21.908887702591564 Acc: 0.3399
Downstream Train Epoch: 12 [0/50000 (0%)]	Loss: 21.374470
Downstream Train Epoch: 12 [12800/50000 (26%)]	Loss: 22.137115
Downstream Train Epoch: 12 [25600/50000 (51%)]	Loss: 20.672461
Downstream Train Epoch: 12 [38400/50000 (77%)]	Loss: 21.238518

 Downstream Train loss: 22.35640118073444 Acc: 0.3399
Downstream Train Epoch: 13 [0/50000 (0%)]	Loss: 22.630072
Downstream Train Epoch: 13 [12800/50000 (26%)]	Loss: 20.861296
Downstream Train Epoch: 13 [25600/50000 (51%)]	Loss: 20.447273
Downstream Train Epoch: 13 [38400/50000 (77%)]	Loss: 16.332966

 Downstream Train loss: 19.96572349995983 Acc: 0.3399
Downstream Train Epoch: 14 [0/50000 (0%)]	Loss: 25.486313
Downstream Train Epoch: 14 [12800/50000 (26%)]	Loss: 19.493965
Downstream Train Epoch: 14 [25600/50000 (51%)]	Loss: 24.612030
Downstream Train Epoch: 14 [38400/50000 (77%)]	Loss: 17.636887

 Downstream Train loss: 22.66223017536864 Acc: 0.3399
Downstream Train Epoch: 15 [0/50000 (0%)]	Loss: 28.361736
Downstream Train Epoch: 15 [12800/50000 (26%)]	Loss: 23.576788
Downstream Train Epoch: 15 [25600/50000 (51%)]	Loss: 15.771882
Downstream Train Epoch: 15 [38400/50000 (77%)]	Loss: 21.063896

 Downstream Train loss: 21.643351584064717 Acc: 0.3399
Downstream Train Epoch: 16 [0/50000 (0%)]	Loss: 16.098539
Downstream Train Epoch: 16 [12800/50000 (26%)]	Loss: 17.659414
Downstream Train Epoch: 16 [25600/50000 (51%)]	Loss: 19.227232
Downstream Train Epoch: 16 [38400/50000 (77%)]	Loss: 19.484472

 Downstream Train loss: 21.75699623263612 Acc: 0.3498
Downstream Train Epoch: 17 [0/50000 (0%)]	Loss: 21.109241
Downstream Train Epoch: 17 [12800/50000 (26%)]	Loss: 21.019382
Downstream Train Epoch: 17 [25600/50000 (51%)]	Loss: 29.576012
Downstream Train Epoch: 17 [38400/50000 (77%)]	Loss: 22.280487

 Downstream Train loss: 20.70011477081143 Acc: 0.3498
Downstream Train Epoch: 18 [0/50000 (0%)]	Loss: 19.061613
Downstream Train Epoch: 18 [12800/50000 (26%)]	Loss: 22.830072
Downstream Train Epoch: 18 [25600/50000 (51%)]	Loss: 22.552134
Downstream Train Epoch: 18 [38400/50000 (77%)]	Loss: 24.321188

 Downstream Train loss: 22.39085712238234 Acc: 0.3498
Downstream Train Epoch: 19 [0/50000 (0%)]	Loss: 31.785706
Downstream Train Epoch: 19 [12800/50000 (26%)]	Loss: 26.422827
Downstream Train Epoch: 19 [25600/50000 (51%)]	Loss: 18.494984
Downstream Train Epoch: 19 [38400/50000 (77%)]	Loss: 22.967731

 Downstream Train loss: 20.599470800283004 Acc: 0.3498
Downstream Train Epoch: 20 [0/50000 (0%)]	Loss: 25.524315
Downstream Train Epoch: 20 [12800/50000 (26%)]	Loss: 24.717741
Downstream Train Epoch: 20 [25600/50000 (51%)]	Loss: 17.250191
Downstream Train Epoch: 20 [38400/50000 (77%)]	Loss: 16.124771

 Downstream Train loss: 18.94419182076746 Acc: 0.3836
Downstream Train Epoch: 21 [0/50000 (0%)]	Loss: 15.537203
Downstream Train Epoch: 21 [12800/50000 (26%)]	Loss: 20.569113
Downstream Train Epoch: 21 [25600/50000 (51%)]	Loss: 19.655399
Downstream Train Epoch: 21 [38400/50000 (77%)]	Loss: 26.006205

 Downstream Train loss: 21.57040994507926 Acc: 0.3836
Downstream Train Epoch: 22 [0/50000 (0%)]	Loss: 31.148705
Downstream Train Epoch: 22 [12800/50000 (26%)]	Loss: 18.368454
Downstream Train Epoch: 22 [25600/50000 (51%)]	Loss: 20.032772
Downstream Train Epoch: 22 [38400/50000 (77%)]	Loss: 19.321371

 Downstream Train loss: 18.34848174756887 Acc: 0.3836
Downstream Train Epoch: 23 [0/50000 (0%)]	Loss: 16.079926
Downstream Train Epoch: 23 [12800/50000 (26%)]	Loss: 13.989661
Downstream Train Epoch: 23 [25600/50000 (51%)]	Loss: 20.974815
Downstream Train Epoch: 23 [38400/50000 (77%)]	Loss: 23.894209

 Downstream Train loss: 21.024800300598145 Acc: 0.3836
Downstream Train Epoch: 24 [0/50000 (0%)]	Loss: 22.563559
Downstream Train Epoch: 24 [12800/50000 (26%)]	Loss: 12.939849
Downstream Train Epoch: 24 [25600/50000 (51%)]	Loss: 14.004193
Downstream Train Epoch: 24 [38400/50000 (77%)]	Loss: 20.102423

 Downstream Train loss: 20.587478545247293 Acc: 0.3836
Downstream Train Epoch: 25 [0/50000 (0%)]	Loss: 28.633137
Downstream Train Epoch: 25 [12800/50000 (26%)]	Loss: 16.215374
Downstream Train Epoch: 25 [25600/50000 (51%)]	Loss: 15.041096
Downstream Train Epoch: 25 [38400/50000 (77%)]	Loss: 17.291700

 Downstream Train loss: 19.1788352898189 Acc: 0.3836
Downstream Train Epoch: 26 [0/50000 (0%)]	Loss: 21.083595
Downstream Train Epoch: 26 [12800/50000 (26%)]	Loss: 13.136284
Downstream Train Epoch: 26 [25600/50000 (51%)]	Loss: 32.086311
Downstream Train Epoch: 26 [38400/50000 (77%)]	Loss: 12.976185

 Downstream Train loss: 18.517183483863363 Acc: 0.3836
Downstream Train Epoch: 27 [0/50000 (0%)]	Loss: 25.568310
Downstream Train Epoch: 27 [12800/50000 (26%)]	Loss: 17.161366
Downstream Train Epoch: 27 [25600/50000 (51%)]	Loss: 34.869839
Downstream Train Epoch: 27 [38400/50000 (77%)]	Loss: 25.253223

 Downstream Train loss: 21.837234248920364 Acc: 0.3836
Downstream Train Epoch: 28 [0/50000 (0%)]	Loss: 15.330490
Downstream Train Epoch: 28 [12800/50000 (26%)]	Loss: 12.567654
Downstream Train Epoch: 28 [25600/50000 (51%)]	Loss: 15.614003
Downstream Train Epoch: 28 [38400/50000 (77%)]	Loss: 19.424898

 Downstream Train loss: 19.021127228834192 Acc: 0.3836
Downstream Train Epoch: 29 [0/50000 (0%)]	Loss: 22.265570
Downstream Train Epoch: 29 [12800/50000 (26%)]	Loss: 13.920499
Downstream Train Epoch: 29 [25600/50000 (51%)]	Loss: 32.435837
Downstream Train Epoch: 29 [38400/50000 (77%)]	Loss: 18.138536

 Downstream Train loss: 18.572724838646092 Acc: 0.3836
Downstream Train Epoch: 30 [0/50000 (0%)]	Loss: 11.692943
Downstream Train Epoch: 30 [12800/50000 (26%)]	Loss: 16.886560
Downstream Train Epoch: 30 [25600/50000 (51%)]	Loss: 19.929939
Downstream Train Epoch: 30 [38400/50000 (77%)]	Loss: 19.963465

 Downstream Train loss: 19.760109575427308 Acc: 0.3836
Downstream Train Epoch: 31 [0/50000 (0%)]	Loss: 32.725941
Downstream Train Epoch: 31 [12800/50000 (26%)]	Loss: 17.351656
Downstream Train Epoch: 31 [25600/50000 (51%)]	Loss: 15.722232
Downstream Train Epoch: 31 [38400/50000 (77%)]	Loss: 18.192806

 Downstream Train loss: 20.067070815027975 Acc: 0.3836
Downstream Train Epoch: 32 [0/50000 (0%)]	Loss: 16.764957
Downstream Train Epoch: 32 [12800/50000 (26%)]	Loss: 18.818594
Downstream Train Epoch: 32 [25600/50000 (51%)]	Loss: 32.564159
Downstream Train Epoch: 32 [38400/50000 (77%)]	Loss: 17.063177

 Downstream Train loss: 20.943229646098857 Acc: 0.3836
Downstream Train Epoch: 33 [0/50000 (0%)]	Loss: 16.627800
Downstream Train Epoch: 33 [12800/50000 (26%)]	Loss: 22.449772
Downstream Train Epoch: 33 [25600/50000 (51%)]	Loss: 24.450136
Downstream Train Epoch: 33 [38400/50000 (77%)]	Loss: 18.621525

 Downstream Train loss: 21.2411353004222 Acc: 0.3836
Downstream Train Epoch: 34 [0/50000 (0%)]	Loss: 15.508138
Downstream Train Epoch: 34 [12800/50000 (26%)]	Loss: 23.050074
Downstream Train Epoch: 34 [25600/50000 (51%)]	Loss: 18.384155
Downstream Train Epoch: 34 [38400/50000 (77%)]	Loss: 9.334508

 Downstream Train loss: 18.934953567933064 Acc: 0.4127
Downstream Train Epoch: 35 [0/50000 (0%)]	Loss: 14.927354
Downstream Train Epoch: 35 [12800/50000 (26%)]	Loss: 18.662403
Downstream Train Epoch: 35 [25600/50000 (51%)]	Loss: 19.488884
Downstream Train Epoch: 35 [38400/50000 (77%)]	Loss: 15.205238

 Downstream Train loss: 19.74951163603335 Acc: 0.4127
Downstream Train Epoch: 36 [0/50000 (0%)]	Loss: 20.979303
Downstream Train Epoch: 36 [12800/50000 (26%)]	Loss: 15.361685
Downstream Train Epoch: 36 [25600/50000 (51%)]	Loss: 23.611132
Downstream Train Epoch: 36 [38400/50000 (77%)]	Loss: 20.202007

 Downstream Train loss: 20.327551184868327 Acc: 0.4127
Downstream Train Epoch: 37 [0/50000 (0%)]	Loss: 23.418982
Downstream Train Epoch: 37 [12800/50000 (26%)]	Loss: 18.196863
Downstream Train Epoch: 37 [25600/50000 (51%)]	Loss: 20.297367
Downstream Train Epoch: 37 [38400/50000 (77%)]	Loss: 19.226885

 Downstream Train loss: 20.238765809000753 Acc: 0.4127
Downstream Train Epoch: 38 [0/50000 (0%)]	Loss: 25.378067
Downstream Train Epoch: 38 [12800/50000 (26%)]	Loss: 24.306931
Downstream Train Epoch: 38 [25600/50000 (51%)]	Loss: 15.254826
Downstream Train Epoch: 38 [38400/50000 (77%)]	Loss: 23.490793

 Downstream Train loss: 20.037377902439662 Acc: 0.4127
Downstream Train Epoch: 39 [0/50000 (0%)]	Loss: 12.257453
Downstream Train Epoch: 39 [12800/50000 (26%)]	Loss: 29.834270
Downstream Train Epoch: 39 [25600/50000 (51%)]	Loss: 24.946579
Downstream Train Epoch: 39 [38400/50000 (77%)]	Loss: 24.480412

 Downstream Train loss: 19.8266136889555 Acc: 0.4127
Downstream Train Epoch: 40 [0/50000 (0%)]	Loss: 14.295210
Downstream Train Epoch: 40 [12800/50000 (26%)]	Loss: 18.628269
Downstream Train Epoch: 40 [25600/50000 (51%)]	Loss: 42.947601
Downstream Train Epoch: 40 [38400/50000 (77%)]	Loss: 36.437386

 Downstream Train loss: 20.399663535916076 Acc: 0.4127
Downstream Train Epoch: 41 [0/50000 (0%)]	Loss: 20.873186
Downstream Train Epoch: 41 [12800/50000 (26%)]	Loss: 26.456169
Downstream Train Epoch: 41 [25600/50000 (51%)]	Loss: 14.791332
Downstream Train Epoch: 41 [38400/50000 (77%)]	Loss: 24.016533

 Downstream Train loss: 19.991813545324366 Acc: 0.4127
Downstream Train Epoch: 42 [0/50000 (0%)]	Loss: 16.274164
Downstream Train Epoch: 42 [12800/50000 (26%)]	Loss: 30.554367
Downstream Train Epoch: 42 [25600/50000 (51%)]	Loss: 17.997604
Downstream Train Epoch: 42 [38400/50000 (77%)]	Loss: 28.080559

 Downstream Train loss: 20.446926408884476 Acc: 0.4127
Downstream Train Epoch: 43 [0/50000 (0%)]	Loss: 16.794909
Downstream Train Epoch: 43 [12800/50000 (26%)]	Loss: 27.769442
Downstream Train Epoch: 43 [25600/50000 (51%)]	Loss: 21.935198
Downstream Train Epoch: 43 [38400/50000 (77%)]	Loss: 12.330845

 Downstream Train loss: 20.577016085994487 Acc: 0.4127
Downstream Train Epoch: 44 [0/50000 (0%)]	Loss: 21.550146
Downstream Train Epoch: 44 [12800/50000 (26%)]	Loss: 23.907436
Downstream Train Epoch: 44 [25600/50000 (51%)]	Loss: 25.342701
Downstream Train Epoch: 44 [38400/50000 (77%)]	Loss: 16.391867

 Downstream Train loss: 19.475022661442658 Acc: 0.4127
Downstream Train Epoch: 45 [0/50000 (0%)]	Loss: 15.640974
Downstream Train Epoch: 45 [12800/50000 (26%)]	Loss: 20.384892
Downstream Train Epoch: 45 [25600/50000 (51%)]	Loss: 14.448384
Downstream Train Epoch: 45 [38400/50000 (77%)]	Loss: 23.359070

 Downstream Train loss: 19.618635756628855 Acc: 0.4127
Downstream Train Epoch: 46 [0/50000 (0%)]	Loss: 16.431898
Downstream Train Epoch: 46 [12800/50000 (26%)]	Loss: 17.781052
Downstream Train Epoch: 46 [25600/50000 (51%)]	Loss: 12.889443
Downstream Train Epoch: 46 [38400/50000 (77%)]	Loss: 18.491476

 Downstream Train loss: 19.95390137847589 Acc: 0.4127
Downstream Train Epoch: 47 [0/50000 (0%)]	Loss: 45.824665
Downstream Train Epoch: 47 [12800/50000 (26%)]	Loss: 11.898553
Downstream Train Epoch: 47 [25600/50000 (51%)]	Loss: 21.544699
Downstream Train Epoch: 47 [38400/50000 (77%)]	Loss: 26.402369

 Downstream Train loss: 22.547681754949142 Acc: 0.4127
Downstream Train Epoch: 48 [0/50000 (0%)]	Loss: 21.005213
Downstream Train Epoch: 48 [12800/50000 (26%)]	Loss: 23.875391
Downstream Train Epoch: 48 [25600/50000 (51%)]	Loss: 13.522406
Downstream Train Epoch: 48 [38400/50000 (77%)]	Loss: 21.101442

 Downstream Train loss: 21.421766203276967 Acc: 0.4127
Downstream Train Epoch: 49 [0/50000 (0%)]	Loss: 23.754787
Downstream Train Epoch: 49 [12800/50000 (26%)]	Loss: 22.411871
Downstream Train Epoch: 49 [25600/50000 (51%)]	Loss: 19.699625
Downstream Train Epoch: 49 [38400/50000 (77%)]	Loss: 16.531191

 Downstream Train loss: 20.33107714750329 Acc: 0.4127
Downstream Train Epoch: 50 [0/50000 (0%)]	Loss: 14.332579
Downstream Train Epoch: 50 [12800/50000 (26%)]	Loss: 21.219818
Downstream Train Epoch: 50 [25600/50000 (51%)]	Loss: 21.755224
Downstream Train Epoch: 50 [38400/50000 (77%)]	Loss: 18.118671

 Downstream Train loss: 18.158869568182496 Acc: 0.4127
Downstream Train Epoch: 51 [0/50000 (0%)]	Loss: 49.953640
Downstream Train Epoch: 51 [12800/50000 (26%)]	Loss: 12.642109
Downstream Train Epoch: 51 [25600/50000 (51%)]	Loss: 20.945679
Downstream Train Epoch: 51 [38400/50000 (77%)]	Loss: 13.506950

 Downstream Train loss: 20.183156728744507 Acc: 0.4127
Downstream Train Epoch: 52 [0/50000 (0%)]	Loss: 35.259731
Downstream Train Epoch: 52 [12800/50000 (26%)]	Loss: 27.001532
Downstream Train Epoch: 52 [25600/50000 (51%)]	Loss: 14.353985
Downstream Train Epoch: 52 [38400/50000 (77%)]	Loss: 17.366278

 Downstream Train loss: 20.83281119015752 Acc: 0.4127
Downstream Train Epoch: 53 [0/50000 (0%)]	Loss: 29.635662
Downstream Train Epoch: 53 [12800/50000 (26%)]	Loss: 14.168253
Downstream Train Epoch: 53 [25600/50000 (51%)]	Loss: 10.432092
Downstream Train Epoch: 53 [38400/50000 (77%)]	Loss: 32.248119

 Downstream Train loss: 18.46004339383573 Acc: 0.4127
Downstream Train Epoch: 54 [0/50000 (0%)]	Loss: 21.587095
Downstream Train Epoch: 54 [12800/50000 (26%)]	Loss: 27.161015
Downstream Train Epoch: 54 [25600/50000 (51%)]	Loss: 19.772066
Downstream Train Epoch: 54 [38400/50000 (77%)]	Loss: 26.682728

 Downstream Train loss: 21.073176768361307 Acc: 0.4127
Downstream Train Epoch: 55 [0/50000 (0%)]	Loss: 12.783463
Downstream Train Epoch: 55 [12800/50000 (26%)]	Loss: 27.384729
Downstream Train Epoch: 55 [25600/50000 (51%)]	Loss: 28.389633
Downstream Train Epoch: 55 [38400/50000 (77%)]	Loss: 22.521828

 Downstream Train loss: 20.104683345677902 Acc: 0.4127
Downstream Train Epoch: 56 [0/50000 (0%)]	Loss: 18.257357
Downstream Train Epoch: 56 [12800/50000 (26%)]	Loss: 18.363853
Downstream Train Epoch: 56 [25600/50000 (51%)]	Loss: 26.398767
Downstream Train Epoch: 56 [38400/50000 (77%)]	Loss: 22.548927

 Downstream Train loss: 20.51906986625827 Acc: 0.4127
Downstream Train Epoch: 57 [0/50000 (0%)]	Loss: 16.884813
Downstream Train Epoch: 57 [12800/50000 (26%)]	Loss: 20.642136
Downstream Train Epoch: 57 [25600/50000 (51%)]	Loss: 17.922382
Downstream Train Epoch: 57 [38400/50000 (77%)]	Loss: 20.192816

 Downstream Train loss: 18.000322609531636 Acc: 0.4127
Downstream Train Epoch: 58 [0/50000 (0%)]	Loss: 27.242947
Downstream Train Epoch: 58 [12800/50000 (26%)]	Loss: 22.059261
Downstream Train Epoch: 58 [25600/50000 (51%)]	Loss: 20.704062
Downstream Train Epoch: 58 [38400/50000 (77%)]	Loss: 20.597841

 Downstream Train loss: 19.99557868315249 Acc: 0.4127
Downstream Train Epoch: 59 [0/50000 (0%)]	Loss: 31.224697
Downstream Train Epoch: 59 [12800/50000 (26%)]	Loss: 29.472052
Downstream Train Epoch: 59 [25600/50000 (51%)]	Loss: 15.504558
Downstream Train Epoch: 59 [38400/50000 (77%)]	Loss: 12.356248

 Downstream Train loss: 20.67554750734446 Acc: 0.4127
Downstream Train Epoch: 60 [0/50000 (0%)]	Loss: 19.333038
Downstream Train Epoch: 60 [12800/50000 (26%)]	Loss: 38.566360
Downstream Train Epoch: 60 [25600/50000 (51%)]	Loss: 26.952736
Downstream Train Epoch: 60 [38400/50000 (77%)]	Loss: 22.220945

 Downstream Train loss: 21.555694896347667 Acc: 0.4127
Classifier Accuracy for user 4 is 0.4127
Training a classifier on the federated global model
 
 Results after 30 global rounds of training:
|----Average Classifier Test Accuracy for 5 agents is: 40.91%

 Total Run Time: 3124.1764
Namespace(exact_diffusion=True, decentralized=True, edge_prob=1.0, epochs=30, num_users=5, frac=1.0, local_ep=5.0, local_bs=256, lr=0.001, momentum=0.9, num_workers=16, model='resnet', batch_size=256, weight_decay=0.0005, dataset='mnist', backbone='resnet18', num_classes=10, gpu='0', optimizer='adam', save_name_suffix='', iid=0, verbose=0, seed=1, feature_dim=128, temperature=0.5, k=200, ssl_method='simclr', x_noniid=False, dirichlet=False, test_intermediate=False, dir_beta=0.5, imagenet_based_cluster=False, y_partition=False, log_file_name='results/05-17_20:08_testingphi_iid_dec-true_ED-true_ep1_e30_le5_a5/skew_ssl_comm', num_clusters=1, imagenet100=False, y_partition_skew=True, y_partition_ratio=0.0, x_shift_dirichlet=False, reg_scale=1, load_pretrained_path='', full_size=False, local_rank=0, distributed_training=False, log_directory='results/05-17_20:08_testingphi_iid_dec-true_ED-true_ep1_e30_le5_a5', emd=0, dist_url='env://', average_without_bn=False, model_continue_training=0, finetuning_epoch=60, script_name='', x_shift_skew=False, load_dataset_to_memory=False, model_time='05-17_20:09_2267728', start_time=datetime.datetime(2024, 5, 17, 20, 9, 37, 725259))
dec_True_ED_True_a_5_resnet_256_30__dec_ssl_simclr
